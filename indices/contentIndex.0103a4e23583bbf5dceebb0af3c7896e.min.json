{"/":{"title":"My Thesis Diary","content":"## About this website üìì\n\nThis website hosts the diary I am writing to keep track of the progress and manage all useful material in researching for my masters' thesis.\n\nI will create a page:\n* for each \"work session\", i.e. a period of time dedicated to specific readings, tasks, problems to be solved, goals, etc.\n* for each meeting with my supervisor\n* for each relevant reading\n* for single concepts, insights and ideas that seem to be particularly useful accross the whole process of preparing for the writing phase and for the writing phase itself\n\nThe notes (pages) are organized in a \"hybrid\" structure, sort of a mix between a classic diary, with its events in chronological order, and a graph-like [zettelkasten](https://en.wikipedia.org/wiki/Zettelkasten), that allows me to easily connect concepts, activities and events without being restricted to the sequential structure of the diary.\n\n\n## Index of Work Sessions and Meetings\n\nBelow, you can find an Index of **all the work sessions and the meetings**, which will often be related, at least partially, both temporally and content-wise. \n\n\n| **Sessions**                                     | **Meetings**                                     |\n| ------------------------------------------------ | ------------------------------------------------ |\n| ‚Ü™Ô∏è[session 001](notes/sessions/session%20001.md) | ‚Ü™Ô∏è[meeting 001](notes/meetings/meeting%20001.md) |\n| ‚Ü™Ô∏è[session 002](notes/sessions/session%20002.md) | ‚Ü™Ô∏è[meeting 002](notes/meetings/meeting%20002.md) |\n| ‚Ü™Ô∏è[session 003](notes/sessions/session%20003.md) | ‚Ü™Ô∏è[meeting 003](notes/meetings/meeting%20003.md) |\n| ‚Ü™Ô∏è[session 004](notes/sessions/session%20004.md) | ‚Ü™Ô∏è[meeting 004](notes/meetings/meeting%20004.md) |\n| ‚Ü™Ô∏è[session 005](notes/sessions/session%20005.md) | ‚Ü™Ô∏è[meeting 005](notes/meetings/meeting%20005.md) |\n| ‚Ü™Ô∏è[session 006](notes/sessions/session%20006.md) | ...                                              |\n| ‚Ü™Ô∏è[session 007](notes/sessions/session%20007.md) | ...                                              |\n| ‚Ü™Ô∏è[session 008](notes/sessions/session%20008.md) | ...                                              |\n| ‚Ü™Ô∏è[session 009](notes/sessions/session%20009.md) | ‚Ü™Ô∏è[meeting 009](notes/meetings/meeting%20009.md) |\n| ‚Ü™Ô∏è[session 010](notes/sessions/session%20010.md) | ‚Ü™Ô∏è[meeting 010](notes/meetings/meeting%20010.md) |\n| ‚Ü™Ô∏è[session 011](notes/sessions/session%20011.md) | ‚Ü™Ô∏è[meeting 011](notes/meetings/meeting%20011.md) |\n| ...                                              | ‚Ü™Ô∏è[meeting 012](notes/meetings/meeting%20012.md) |\n| ...                                              | ‚Ü™Ô∏è[meeting 013](notes/meetings/meeting%20013.md) |\n| ‚Ü™Ô∏è[session 014](notes/sessions/session%20014.md) | ‚Ü™Ô∏è[meeting 014](notes/meetings/meeting%20014.md) |\n|                                                  | ‚Ü™Ô∏è[meeting 015](notes/meetings/meeting%20015.md) |\n| ‚Ü™Ô∏è[session 016](notes/sessions/session%20016.md) | ‚Ü™Ô∏è[meeting 016](notes/meetings/meeting%20016.md) |\n## Readings\n\nIf you're interested in getting an overview of the **readings** I have collected so far, you can visit [this section](https://eliarizzetto.github.io/quartz/tags/reading) of the website. Each reading has its own dedicated page, containing simple bibliographic information and notes on the content of the document. The page is referenced via `citekey`, a unique, ready-to-use identifier relative to my bibliographic collection in Zotero, which I will use for the writing phase. \n\n\n\n","lastmodified":"2023-03-19T23:54:38.48457992Z","tags":null},"/notes/Errors-map":{"title":"Errors map","content":"\nüîó[Map on GitHub](https://github.com/eliarizzetto/thesis_resources/blob/b1e763e5d181ac445cfea73ecbaef215b565c949/errors_map.csv)\n\n\n|Error label            |Description                                                                                                                                |table|Corresponding validation function                |validation_level  |error_type|field                                                           |valid|located_in|message|Report example|notes        |\n|-----------------------|-------------------------------------------------------------------------------------------------------------------------------------------|-----|-------------------------------------------------|------------------|----------|----------------------------------------------------------------|-----|----------|-------|--------------|-------------|\n|duplicates             |a bibliographic record is expressed more than once inside the table                                                                        |both |?                                                |csv_wellformedness|warning   |                                                                |     |row       |       |              |multiple rows|\n|extra space in id field|inside the id field, spaces are found at the beginning of the string or at the end, or extra spaces are found between two single ids       |both |if item == '': (FORMERLY wellformedness_id_field)|csv_wellformedness|error     |citing_id', 'cited_id' or 'id'                                  |no   |item      |m1     |              |             |\n|wrong id syntax        |the single id (item) is not well-formed according to OC syntax (lowercase accepted prefix followed by colon and other non-space characters)|both |wellformedness_single_id                         |csv_wellformedness|error     |citing_id', 'cited_id' or 'id'                                  |no   |item      |m2     |              |             |\n|date                   |the date is badly formatted (does not match the one regex that defines any correct possibility)                                            |both |wellformedness_date                              |csv_wellformedness|error     |citing_publication_date', 'cited_publication_date' or 'pub_date'|no   |item      |m3     |              |             |\n","lastmodified":"2023-03-19T23:54:38.512579397Z","tags":null},"/notes/Managing-Wiki-Identifiers":{"title":"Managing Wiki Identifiers","content":"\n## MediaWiki Action API\nAll Wikimedia services (including Wikipedia and Wikidata) are accessible by means of **one** API, the [**MediaWiki Action API**](https://www.mediawiki.org/wiki/API:Main_page). \nAll Wikimedia wikis have endpoints that follow this pattern: `https://www.example.org/w/api.php`.\n\nThe **endpoints** of interest are the following (the links below, leading to the endpoint-specific documentation, are also the URLs to use when accessing the service-related API):\n- [Endpoint for **Wikipedia**](https://en.wikipedia.org/w/api.php)\n- [Endpoint for **Wikidata**](https://www.wikidata.org/w/api.php)\n\n## Accessing Wikidata and Wikipedia data\n### Wikidata\nIn order to access Wikidata's data, amongst other solutions, the [Wikidata:Data access](https://www.wikidata.org/wiki/Wikidata:Data_access/en#Using_Wikidata's_data) page suggests to use:\n- the **Linked Data Interface** [https://www.wikidata.org/wiki/Wikidata:Data_access/en#Linked_Data_Interface_(URI)](https://www.wikidata.org/wiki/Wikidata:Data_access/en#Linked_Data_Interface_(URI)) for \"when you need to obtain individual, complete entities that are already known to you\".\n- the **MediaWiki Action API** [https://www.wikidata.org/wiki/Wikidata:Data_access/en#MediaWiki_Action_API](https://www.wikidata.org/wiki/Wikidata:Data_access/en#MediaWiki_Action_API) when \"you need small groups of entities in JSON format (up to 50 entities per request)\"; this help page also mentions that \"the API is also poorly suited to situations in which you want to request the current state of entities in JSON. (For such cases consider using the¬†[Linked Data Interface](https://www.wikidata.org/wiki/Wikidata:Data_access/en#Linked_Data_Interface), which is likelier to provide faster responses.)\".\n\n### Wikipedia\nSimilarly, for Wikipedia one can use either the API or the the URI, provided, of course, that the correct URL has been specified accordingly:\n* for the English **Wikipedia Action API endpoint**: [https://en.wikipedia.org/w/api.php](https://en.wikipedia.org/w/api.php)\n* for the English Wikipedia namespace: *either* [https://en.wikipedia.org/wiki/](https://en.wikipedia.org/wiki/) (with redirection by the browser and without the possibility of specifying parameters) *or* [https://en.wikipedia.org/w/index.php](https://en.wikipedia.org/w/index.php/) (with the possibility of specifying some parameters and without being redirected by the browser).\n\n**NB**: Unlike Wikidata, which has a proper Linked Data Interface, \u003cu\u003ewhen accessing data via Wikipedia's *bare URLs* (i.e. not by means of the API)\u003c/u\u003e, even with the alternative URL (https://en.wikipedia.org/w/index.php), **many useful parameters cannot be specified** in the request: e.g., you cannot specifiy the output format in json! This means that, if you requested a resource via the URL instead of the API, you would have to resort to some scraping library (e.g. Beautiful Soup) to convert the retrieved resource into a useable format in Python. \u003cu\u003e**For Wikipedia, it seems more convenient to use the MediaWiki Action API!**\u003c/u\u003e\n\nBear in mind that, while the Wikidata has the same namespace for every language, **Wikipedia refers to a specific language**. Therefore, you'll have to choose the domain for the English Wikipedia, since it is the most \"international\" one.\n\n\n### [**Wikidata's Linked Data Interface (URI)**](https://www.wikidata.org/wiki/Wikidata:Data_access/en#Linked_Data_Interface_(URI))\n\n**url: [https://www.wikidata.org/wiki/Special:EntityData/](https://www.wikidata.org/wiki/Special:EntityData/)**\n\nEg:\n\n\u003eAs a human being with eyes and a browser, you will likely want to access data¬†_about_¬†Douglas Adams by using the concept URI as a¬†[URL](https://en.wiktionary.org/wiki/Uniform_Resource_Locator \"wikt:Uniform Resource Locator\"). Doing so triggers an HTTP redirect and forwards the client to the data URL that contains Wikidata's data¬†_about_¬†Douglas Adams: [https://www.wikidata.org/wiki/Special:EntityData/Q42](https://www.wikidata.org/wiki/Special:EntityData/Q42)\"\n\u003e\n\u003e from https://www.wikidata.org/wiki/Wikidata:Data_access/en#Linked_Data_Interface_(URI)\n\nEach Wikidata entity is identified by an¬†**entity ID**, which is a number prefixed by a letter.\n\n-   \u003cu\u003e[**items**](https://www.wikidata.org/wiki/Help:Items \"Help:Items\"), also known as Q-items, are prefixed with¬†`Q`¬†\u003c/u\u003e(e.g.¬†[Q12345](https://www.wikidata.org/wiki/Q12345 \"Q12345\")),\n-   [properties](https://www.wikidata.org/wiki/Help:Properties \"Help:Properties\")¬†are prefixed by¬†`P`¬†(e.g.¬†[P569](https://www.wikidata.org/wiki/Property:P569 \"Property:P569\")) and\n-   [lexemes](https://www.wikidata.org/wiki/Help:Lexemes \"Help:Lexemes\")¬†are prefixed by¬†`L`¬†(e.g.¬†[L1](https://www.wikidata.org/wiki/Lexeme:L1 \"Lexeme:L1\")).\n-  there also seem to be [Entity Schemas](https://www.wikidata.org/wiki/EntitySchema:E2), prefixed by ¬†`E`.\n\n\nThe only way to retrieve precisely a resource from Wikidata is the entity's ID (e.g. Q42); in other words, with aliases and labels in the URL there is no way of getting to the relevant URI.\nE.g. `https://www.wikidata.org/wiki/Special:EntityData/Q42` leads to Douglas Adams' page, but `https://www.wikidata.org/wiki/Special:EntityData/Douglas_Adams` doesn't!\n\n#### Sintactic validation: regex for Wikidata identifiers\nI have obtained the regex for Q-IDs, as described within wikidata itself, by looking for the property [`format as a regular expression`](https://www.wikidata.org/wiki/Property:P1793 \"Property:P1793\") in the [wikidata page of the Q-identifier](https://www.wikidata.org/wiki/Q43649390).[^1] \n\n**Wikidata Q Identifier:**\n\n* [format as a regular expression](https://www.wikidata.org/wiki/Property:P1793 \"Property:P1793\") : `Q[1-9]\\d*`\n\n[^1]: To get the regex for other, external, IDs, provided that they're registered in wikidata, you can do the same by checking if the same property is specified in the wikidata page of the ID you're interested in (either the item page or the property page; e.g. you can look for the `format as a regular expression` property in the [VIAF ID property page](https://www.wikidata.org/wiki/Property:P214))\n\nIf needed, the same process can be applied for retrieving the regular expressions for the P-identifier (looking into its wikidata page) and the other [identifiers](https://www.wikidata.org/wiki/Wikidata:Identifiers). The reason why I chose not to do so, is because I want to allow as bibliographic resource or responsible agent in the OC indexes **only** Wikidata's **items** (wikidata properties (P), lexemes (L) and entity schemas (E) seem a very unlikely candidate for being represented in any OC index).\n\n\n\n#### Wiki Universe\nOn the differences between Wikipedia, MediaWiki, Wikimedia, etc. see:\n* [https://www.mediawiki.org/wiki/Differences_between_Wikipedia,_Wikimedia,_MediaWiki,_and_wiki](https://www.mediawiki.org/wiki/Differences_between_Wikipedia,_Wikimedia,_MediaWiki,_and_wiki)\n* [https://meta.wikimedia.org/wiki/Learning_patterns/Wikiblabla_(confusing_Wikimedia_lexicon)](https://meta.wikimedia.org/wiki/Learning_patterns/Wikiblabla_(confusing_Wikimedia_lexicon))\n* [https://www.mediawiki.org/wiki/Manual:What_is_MediaWiki%3F](https://www.mediawiki.org/wiki/Manual:What_is_MediaWiki%3F)\n","lastmodified":"2023-03-19T23:54:38.512579397Z","tags":null},"/notes/duplicates-examples":{"title":"Duplicates examples","content":"|citing                 |cited                                                                                                                                      |\n|-----------------------|-------------------------------------------------------------------------------------------------------------------------------------------|\n|A B C                  |x y z                                                                                                                                      |\n|B D                    |x                                                                                                                                          |\n|D                      |z y                                                                                                                                        |\n|                       |                                                                                                                                           |\n\n\n1. Che `B` cita `x` lo dico sia in riga 0 sia in riga 1 ‚Üí √® un errore perch√© si ripete una citazione tra singoli identificativi.\n```json\n{\n\t0: {\n\t\tciting: [1],\n\t\tcited:[0]\n\t\t},\n\t1: {\n\t\tciting:[0], \n\t\tcited[0]\n\t\t}\n}\n```\n\n2. So che `A`, `B`, `C` e `D` sono tutti la stessa entit√† bibliografica, cos√¨ come `x`, `y` e `z`. ‚Üí √® un errore perch√© si ripete una citazione tra entit√† bibliografiche (rappresentabili con metaID).\n```json\n{\n\t0: {\n\t\tciting: [0,1,2],\n\t\tcited:[0,1,2]\n\t\t},\n\t1: {\n\t\tciting:[0,1], \n\t\tcited[0]\n\t\t}\n\t2: {\n\t\tciting:[0], \n\t\tcited[0,1]\n\t\t}\n}\n```\n\n","lastmodified":"2023-03-19T23:54:38.512579397Z","tags":null},"/notes/meetings/meeting-001":{"title":"Meeting 001","content":"\u003cspan \n\t\tclass=\"ob-timelines\"\n\t\tdata-date=\"2022-08-13-00\"\u003e\n\u003c/span\u003e\nüìë [**Reference session: 001**](notes/sessions/session%20001.md)\n\n\u003e [!abstract]+ Summary\n\u003e \n\u003e In this meeting we talked about:\n\n## **Introduction**\n\n\n\n\n## **Q\u0026A**\n### *Question 1: CSV files syntax*\n\n* Qual √® un esempio sintatticamente corretto entrata **con pi√π di un identificativo**. Nella tabella di esempio c'√® una riga con un doi e un issn separati da \";\" e da uno spazio (o un ritorno a capo????) mentre nel testo dei paper si dice che per separare IDs multipli bisogna mettere solo un \"single space\". √® sbagliato l'esempio? oppure la cosa del single space si applica solo nei casi in cui l'ID multiplo sia dello stesso tipo (sempre che sia possibile avere pi√π di un ID dello stesso tipo)? se cos√¨, come si devono separare ID multipli di tipo diverso? Ma vedi anche tabelle di esempi su repo Github di OC, che sembrano pi√π coerenti con la documentazione. \n\n* Nel csv dei metadati, per quanto riguarda l'**autore**: √® sintatticamente corretto specificare solo il cognome dell'autore, cio√® senza cognome e senza identificativo?\n\tEsempi: \n\t- Peroni, Silvio [orcid:0000-0003-0530-4305] --\u003e OK\n\t- Peroni, [orcid:0000-0003-0530-4305] --\u003e OK\n\t- **Peroni, --\u003e ??????**\n\n**\u003cp align=center\u003eAnswer:\u003c/p\u003e**\n\n\n\n### *Question 2: Sample input csv*\n√® possibile avere un **esempio di tabelle**, sia per le citazioni che per i metadati, che andrebbero validate (= che andrebbero in input nel programma che devo scrivere)?\n\n**\u003cp align=center\u003eAnswer:\u003c/p\u003e**\n\n\n\n## **To do**\n* [ ] Flask overview\n* [ ] \n\n","lastmodified":"2023-03-19T23:54:38.512579397Z","tags":null},"/notes/meetings/meeting-002":{"title":"Meeting 002","content":"\u003cspan \n\t\tclass=\"ob-timelines\"\n\t\tdata-date=\"2022-09-06-00\"\u003e\n\u003c/span\u003e\nüìë [**Reference session: 002**](notes/sessions/session%20002.md)\n\nüîô [**Previous meeting: 001**](notes/meetings/meeting%20001.md)\n\n\n\n## **Q\u0026A**\n### ***Q1: importare packages:***\n*Perch√© devo aprire direttamente index e non oc che √® la cartella che lo contiene?\nE c'√® un modo per importare moduli collocati in una directory con un percorso diverso da quella in cui sto lavorando? ovvero,  devo per forza collocare il file in cui sto lavorando all'interno di oc/index per poter importare i moduli?*\n\n*esiste una versione aggiornata/definitiva e installabile del software/libreria per gli indici?\n√® possibile installare questo software in un percorso tale per cui posso importare le sue parti da qualunque posizione nel mio pc?*\n\n### ***Q2:  isbn manager***\n*Esiste gi√† un isbn manager? √à il caso di crearlo? O meglio, il fatto che non sia presente nel [pacchetto](https://github.com/opencitations/index/tree/master/index/identifier)  allo stato attuale significa che OC non lo gestisce o non lo gestir√†?*\n\n\n\n## **To do**\n* [ ] vedere dataset diversi (CROCI)\n* [ ] (introdurre distinzione su tipo di tabella)\n* [ ] proseguire su verifica id: isbn manager?\n* [ ] introdurre/migliorare condizioni per chiamare funzioni di identifier manager\n\n\n\n\n* quanti e  quali id gestiamo su meta? \n\tvedi meta di arcangelo per capire quali \n isbn, doi, orcid, isnn\n\n\n\n#### Tipi di ID gestiti in meta:\n\n* **Bibliographic resources (br)**:\n\t* 'doi', 'issn', 'isbn', 'pmid', 'pmcid', 'url', 'wikidata', 'wikipedia'\n\n\n* **Responsible Agents (ra)** (authors, editors, publishers):\n\t* 'crossref', 'orcid', 'viaf', 'wikidata', 'ror'[^1] \n\n[^1]: 'ror' might be introduced in the meawhile, since it is becoming very common. UPDATE: i think it has been [introduced by Arcangelo on Sept. 06](https://github.com/opencitations/oc_meta/commit/80b6fd41d7ac679c88fafd1580e03829be8860fe).\n\nDovrai forse creare classi aggiuntive per fare i check degli identificativi per cui le classi non esistono gi√† su meta o su index. \nMa prima devono decidere quali sono le classi definitive per checkare gli id e poi mettere tutto su un unico repo. devono anche fare in modo che index sia installabile con pip. meta √® gi√† installabile con pip. \n\n\n\nRicordati: \n* togliere il \"10\" dopo il prefisso del doi nel match con la regex, perch√© si tratta gi√†, concettualmente, di un altro tipo di validazione\n* √® da introdurre uno step in cui si fa un **minimo** di pulitura della cella, **indipendentemente dal tipo di id\"**, (ad esempio si tolgono gli spazi  e i doppi spazi prima dell'id), per poi fare la validazione sintattica e poi ancora semantica su una stringa che ti consenta di scegliere il processo giusto di validazione, ad es. matchando la regex che hai gi√† nel codice. √à comunque opportuno segnalare \"errori\" o anomalie nel formato gi√† in questa fase di pre-processing molto basilare (es. \"Qui c'√® uno spazio, ma non dovrebbe esserci\").\n* ok che fornisci gi√† ora il feedback, ma devi pensare a localizzarlo non gi√† ora in funzione del feedback, ma in un modo che renda l'istanza pi√π retrievable possibile all'interno degli oggetti che hai salvato (andrebbe bene una specie di dizionionario o lista di dizionario che mappi gli errori, il tipo di errore, la posizione...)","lastmodified":"2023-03-19T23:54:38.512579397Z","tags":null},"/notes/meetings/meeting-003":{"title":"Meeting 003","content":"\u003cspan \n\t\tclass=\"ob-timelines\"\n\t\tdata-date=\"2022-09-13-00\"\u003e\n\u003c/span\u003e\nüìë [**Reference session: 003**](notes/sessions/session%20003.md)\n\nüîô [**Previous meeting: 002**](notes/meetings/meeting%20002.md)\n\n### Arcangelo\nProposta di automatizzare tutto il workflow di ingestione dei dati in OC tramite le issue di GitHub.\n\n### Giuseppe\nPer fare modifiche a oc/index fare un branch/fork (uno dei due??) dal branch `develop` e poi fare la pull a develop. \n## **Q\u0026A**\n### *Question 1: *\nAnswer\n### *Question 2: *\nAnswer\n\n\n\n## **To do**\n* [ ] Task 1\n* [ ] Task 2\n* [ ] Task 3\n\n\n\n# Utenza validatore\n- Chi usa il validatore? Con dati di quale dimensione? Ha senso in base a questi parametri pensare a un'interfaccia interattiva per la correzione diretta del documento inviato?\n- Prefissi wikipedia, wikidata, ror\n- per id che non hanno una api o che la hanno a pagamento (issn e isbn) si pu√≤ anche pensare di ricorrere a api di servizi esterni (es librerie digitali)\n\n\n\n\n* wikidata per rappresentare entit√†, wikipedia per rappresentare documenti (che possono essere a proosto di entita) --\u003e vedi repo su oc/wcw in cui si raccolgono informazioni utili per wikipedia e wikidata, i loro prefissi, etc.\n\n* per controlli di natura semantica si ricorre all'API: negli ID manager, oltre al controllo di esistenza, si pu√≤ controllare che il tipo assegnato dall'utente sia corrispondente a quello menzionato nell'api\n* separata validazione con shacl in quarto step a parte che si chiami qualcosa tipo \"OC Data Model Validation\"\n\n* cambia la dicitura \"note\"  in \"info\" per le classi concettuali degli errori\n* tutti i passaggi della validazione sono sequenziali (se non passa il primo livello di validazione rispetto al formato dati di OC, non acceder√† al secondo, e cos√¨ via). Questo per√≤ significa che devono essere per forza fatti uno alla volta, e che al termine di ognuno c'√® bisogno di una correzione da parte dell'utente? ","lastmodified":"2023-03-19T23:54:38.512579397Z","tags":null},"/notes/meetings/meeting-004":{"title":"Meeting 004","content":"\u003cspan \n\t\tclass=\"ob-timelines\"\n\t\tdata-date=\"2022-09-17-00\"\u003e\n\u003c/span\u003e\nüìë [**Reference session: 004**](notes/sessions/session%20004.md)\n\nüîô [**Previous meeting: 003**](notes/meetings/meeting%20003.md)\n\n\n## **Q\u0026A**\n### .is_valid come primo step di validazione sintattica e semantica per gli ID\n*Una volta che il primo livello della validazione √® stato passato (formato dati OC), ha senso usare direttamente `.is_valid`? Se lo passa, significa che livello sintattico e (gran parte del) livello semantico sono passati, e i dati possono essere ammessi. Se non lo passa, si possono sottoporre  i dati a tutti i controlli sintattici e semantici uno alla volta.*\n\n\n### Cosa considerare come ID valido per wikidata e wikipedia?\n* **Page ID** √® facile da controllare e va bene sia per wikidata che per wikipedia a livello univocit√†, ma non mi sembra che abbia troppo senso dal punto di vista semantico per le entit√† di Wikidata\n* **Page title** √® semanticamente adatto per le entit√† di wikidata (perch√© consiste nel Q-ID e rappresenta l'entit√† stessa), ma sembra un po' \"vago\" per le pagine di Wikipedia, o perlomeno prono ad errori.\n\nPossibili soluzioni:[^1]\n1. Page title sia per gli input id prefissati da `wikidata:` (Q-ID, cio√® cos√¨ come √® ora) che per quelli prefissati da `wikipedia:`. \n2. Page ID sia per `wikidata:` che per `wikipedia:`.\n3. *Solo* Page Title per `wikipedia:`; Page Title *o* Page ID (Q-ID) per `wikidata:` nell'input dell'utente, solo uno dei due nell'output della validazione. \n4. *Solo* Page ID (numero intero positivo) per `wikipedia:`; Page Title *o* Page ID (Q-ID) per `wikidata:` nell'input dell'utente, solo uno dei due nell'output della validazione. .\n\n[^1]: Scarto la possibilit√† di ammettere entrambi i tipi di id per Wikipedia perch√© non sono automaticamente distinguibili. Inoltre, non √® ammissibile avere due possibili identificativi per lo stesso prefisso all'interno di OC (la stessa risorsa, se √® rappresentata con due identificativi diversi per lo stesso prefisso, es. `wikidata:`, risulta come due risorse diverse all'interno degli indici). √à comunque possibile lasciare che l'utente mandi l'identificativo che vuole, per poi cambiarlo noi nel tipo di identificativo che ammettiamo noi, in seguito alla richiesta all'API.\n\n### √à necessario ammettere che l'utente invii come ID per wikidata o wikipedia l'URL completo?\nEs. \"wikipedia://en.wikipedia.org/w/index.php?curid=8091\"  \n\n### .get_extra_info\n\n\n\n# Incontro \n### Arcangelo\nAffinata la proposta di automatizzare il processo di ricezione dei dati per la validazione (con GitHub issues)\n\n### TO DO\n* manda mail a Simone Persiani e metti in Silvio in cc: dobbiamo sapere che cosa √® stato usato come ID delle pagine di Wikipedia nel software di wcw. Usare il Title Page (invece che il Page ID) √® la soluzione che preferiamo per ora, ma resta da capire del tutto come funziona: i redirect? come vengono gestiti gli spazi? etc.\n* il controllo sintattico va ASSOLUTAMENTE  separato dagli altri e fatto passare prima di tutti gli altri metodo dell'ID Manager. Un buon worflow potrebbe essere:\n  1. Controllo sul formato OC\n  2. Controllo sintattico sul dato COS√¨ COME L'HA INVIATO L'UTENTE (\u003cu\u003e**senza normalise**\u003c/u\u003e). **Se non lo passa, l'*utente* deve correggerlo**.\n  3. \u003cu\u003eChiamare direttamente .is_valid\u003c/u\u003e: avendo gi√† passato il controllo sintattico, il normalise cambier√† soltanto delle cose minime, poi ri-controller√† la sintassi sul dato normalizzato, e poi ritorner√† le info semantiche. **Se non passa .is_valid, √®  sicuramente perch√© \"non ha passato\" .exist, dal momento che se ha gi√† passato il controllo sintattico sul dato non normalizzato, non pu√≤ non passarlo su quello normalizzato.** \n  * in generale Silvio √® dell'idea che sia meglio lasciare che siano *gli utenti* a prendere delle decisioni, e quindi andarci cauti con i suggerimenti rispetto a potenziali correzioni. Sicuramente tu non devi cambiare niente! (per questo il normalise va usato soltanto dopo che il dato ha passato il controllo sintattico!).","lastmodified":"2023-03-19T23:54:38.512579397Z","tags":null},"/notes/meetings/meeting-005":{"title":"Meeting 005","content":"\u003cspan \n\t\tclass=\"ob-timelines\"\n\t\tdata-date=\"2022-09-29-00\"\u003e\n\u003c/span\u003e\nüìë [**Reference session: 005**](notes/sessions/session%20005.md)\n\nüîô [**Previous meeting: 004**](notes/meetings/meeting%20004.md)\n\n\n### Wikidata Manager\n1. **Mail con Simone Persiani**:\n\t\u003e Nel progetto ‚ÄúWikipedia Citations in Wikidata‚Äù rappresentavo le pagine di Wikipedia EN come BibliographicResource con identificativo ‚Äúwikipedia:\\\u003cPAGE-ID\u003e‚Äù e con titolo ‚Äú\\\u003cPAGE-TITLE\u003e‚Äù.  \n\t\u003e Per seguire il tuo esempio, la pagina su Tim Berners-Lee verrebbe mappata in un‚Äôentit√† con¬†:hasTitle ‚ÄúTim Berners-Lee‚Äù¬†a cui sarebbe associata un‚Äôentit√† di tipo Identifier con¬†:hasLiteralValue ‚Äú30034‚Äù¬†e¬†:usesIdentifierScheme datacite:wikipedia\n\t\n\t\u003e Se vi dovete riferire alle pagine di Wikipedia intese come risorse bibliografiche, \u003cu\u003evi conviene usare i page id come identificativi (i titoli delle pagine di Wikipedia possono essere modificati, mentre il page id rimane sempre lo stesso\u003c/u\u003e!!!).\n\n2. **Redirect e disambiguation**:\n\t* Ho capito quali parametri usare nella richiesta all'API per sapere se la pagina cercata √® un articolo vero e proprio o se invece √® una pagina di reindirizzamento e/o di disambiguazione (in un'unica richiesta). \u003cu\u003eResta da vedere se √® il caso di escludere tutte le pagine che risultano essere redirect o disambiguation al momento della richiesta\u003c/u\u003e, visto che un articolo potrebbe diventare una di queste due cose in seguito ad uno spostamento (cio√® a un cambio di titolo); ad esempio \"Charles, Prince of Wales\" √® stato il titolo dell'*articolo* che ha page id \"125248\" (https://en.wikipedia.org/wiki/Charles_III); ora che Carlo √® re, per√≤, il titolo della pagina √® cambiato e \"Charles, Prince of Wales\" √® *automaticamente* diventato il titolo di una pagina di reindirizzamento (con un suo proprio e differente page id!).\n\n### Flowchart\n \u003ciframe frameborder=\"0\" style=\"width:100%;height:1213px;\" src=\"https://viewer.diagrams.net/?highlight=0000ff\u0026edit=_blank\u0026layers=1\u0026nav=1\u0026title=validation_flowchart.drawio#R%3Cmxfile%20pages%3D%222%22%3E%3Cdiagram%20id%3D%22C5RBs43oDa-KdzZeNtuy%22%20name%3D%22General_structure%22%3E7Vvbkto4EP0aqnYfhvLd8DgDk%2BtkEzK3ZF9SwgjwRrYcWdzy9SvZEraRGRzAhlCZl7Hakmx19zndUpuW2QuWrwmIph%2FwCKKWoY2WLbPfMgy9Y%2BjsH5esUonlaKlgQvyR6JQJ7v2fUAhlt5k%2FgnGhI8UYUT8qCj0chtCjBRkgBC%2BK3cYYFZ8agQlUBPceQKr02R%2FRaSrtGG4mfwP9yVQ%2BWXe66Z0AyM5iJfEUjPAiJzJvW2aPYEzTq2DZg4grT%2Brl%2Be3qGd19d16%2FG8Q%2FwOPN%2B4d%2Fnq7SyV79ypD1EggM6d5TPz6%2BM%2BaD%2BPHzwO2%2BscPe28Hz4MqUa6MrqTA4YvoTTUzoFE9wCNBtJr0heBaOIJ9WY62szx3GERPqTPgfpHQlnAHMKGaiKQ2QuFtxPWLdMZ4RD76wCF1YjAIygfSFjrwX78iXmPMOoa%2FXEAeQkhXrQCAC1J8XXQgIT5ys%2B2XaZhdC4b%2BgfPnec4Bm4lH3D9efH1STIMTgwlW%2FmPoU3kcg0ceCIfYQxc4hoXD5oiLE3Su7o7V1Kx0miMAWrrPIUKVrQjbNIUr2O0R9tze3PwYjbxk9Lf991zffDxaReXUJris9crfr2mfluvK9c67rh9GMMlHbi%2BecqH2m8E0DMQqN%2BCXTH0AIIjwhIGBajSDx2YtBsnnvU3Zjl%2B%2BP%2FSWU8adeLHQVLOhWCRiMEjA4RwBDOZHrirIbQANc%2BvQLH962Retr7k5%2FKWZOGivRODaC7IoIMo9O%2FmLoJ%2ByHNO8fpuIfprth9%2FRtxcgN069f5QB42go8%2BxxFgR9CnssBCpJcirAkR%2FGbolfsQh0O6SsQ%2BIiv9A1Ec0h9D4gbEo2GaPcwwiR5iKklf0wOkD8Jmcxj7pDAPKYEf4dlXRmloJx8nPw1HPWMMqTXFfbK%2Fdi8gLgnwbgbtW5DqHW69qatrU22rhm1pqWg9sPtw%2FVV7%2F6p1OR3YMg2awUzKWji3s4Aia7FjcAfjVKPgLH%2FEwyT%2BbhPRHxVyTrtm5bdLzX5i%2F6o4Gq9pxNPaeW3TaV4Y2jTtG4xsqatfa0ru%2BDxOIb1GE2l2t7bh%2FutRrtUnDoN4dQ0FE62jIZxqia%2Fz1PfmzLRx16iLO7w6%2FhqvlIcQaIyQfAnHPvUxxydQ0wpDkpgS%2FFG3JWZdLCc8HOb9hjhhTcFhLbjWcDC%2FOTbeBZ66bQXHqRtp20WScM01SBtG227wSjt2JeAfqci%2Bm3r2Og%2FLEVyFIC2DAexFdwM2cWEXzwxn2Z5MAeIod3BeXLsyV5I%2B8vzaSKP%2F26Z13Ice4%2F10PVcREo8HETIB6EHE6ejnAqUJ2ZhoWzKbdn4NqpYB%2FKtEb6ELSKCPRjHW9L6ovvFqZNpba1jFv84IRBPOKGTTp%2BejGoNk016R57r6i%2FQzxQT%2Fyd7IJAqQRv6XD%2BN8Q7t%2BwQK8uwjSuqkL6sknjklewyrZI%2FRqY29nEtgL7cqe2nnxV7uIezF3gEcmbiyTcgf4vpDXJK4XOcMicu6hKKAWbWeJUuVpzjS7HQb3nSpxbKXWREJVjS2kyEIOHuEwzhKDqkZjJjVuYVWDG9LxZOqkVHOL4bA%2Bz5JvOvjjCJ%2B9lpzacLRFDu5p8ekcQGYtOS3C7swaZmNYVI5sNQVI9YMSqmVXwalWRGU3DQwACGLxPFl4FHXjJMD0tzTalZFq5VllR97%2FQ8XYkG9c2oL2p1TUCrTLVl9EeOTxtfWuvbLm1nBN2nJiu%2B6StzKasRZxbiRKrHc4p2g3nSYodWsJ8Sltj%2BPYpB0zKMUgzTLFqnD%2BZZ%2FHDUCrqAaqn6%2FhKcyYpzGEh5XoWKn4cqPVErO2hGIY25wESRLij1kioPhrEJwK7pAbSHNVTdzdseV1ZFcTOuUhLTaPmCy1TrqFqZrKsrp%2B0U5%2FYRRzqoa5Rqr1qq%2B5mzW3LZg9poQsMp1EzFp%2B7MM9UDK0Tv5KSuNsbXCd9TsIn2T44YN41LDRlUXbC5sqBl842FD%2FbDn9wsbpvrZ6xmEDUdV7UmDRi5OfC2EifKgcWT0SVDtDgBHPzk%2BzIplJxIbVqz08UsA2cK%2FYfItppgkvwwqRc85fBBT9LmtVZ39y2i1MYFtu21ng1GtMiawy764sWvyIVfNzS8jpMoqz%2B6jZ%2F2sQO2qOc7vldGfyo7HJ%2Bf9EmpLzZy6xsaPDCuM6TSSUKsHZTzFOkqCVR%2BRqicanZKz5bKEao%2BjZdbMfqya6j37ya95%2Bz8%3D%3C%2Fdiagram%3E%3Cdiagram%20id%3D%22xzgZwGghKsRzE2Puvifx%22%20name%3D%22Level1_OC_table_format%22%3E5Vvbcts2EP0azbQP1vAu6tHxpXloOmmcNklfMjAJUWggggYhS8zXFyAA8QK6pm2RSmjP2MaNALgHu3t2Sc7ci83%2BNwqy9TsSQzxzrHg%2Fcy9njrNcevyvaChkgxdYsiGhKJZNdtVwg75D1aiHbVEM88ZARghmKGs2RiRNYcQabYBSsmsOWxHcXDUDCTQabiKAzdZPKGZr2Ro6i6r9LUTJWq9sB0vZswF6sLqTfA1isqs1uVcz94ISwmRps7%2BAWMhOy2Wb5O%2FudukXQu6KRYo%2F7q4%2F%2B2dysuunXHK4BQpT9uyp88XX%2BNNf3%2F%2B8uPvnw9876wJ%2Fw5me%2Bh7grZLXzcfzDx%2FVDbNCSzFnlHw7CJDf%2Bps122BetHmRCyYT4zb7RByh%2BQqTXbQGlM1zxv9%2BFWN2a8TgTQYiMXDHh%2FE2tTakDO5bYD1yp%2FZB%2FPzYQrKBjBb8OjWLpwArmtVdBb8%2Bw%2Bsa8noYUAcuOcxbCZUXlFyfIGPXkDFKsy0TZz6%2FnzkB5ht4c0t5KRElBm651A0AlIy5aADGEBMu6k0LBgOjDFLE7wHS9oXvq45OZCjZpjGM1cSARkqvbTFrLsvW3HEHBNH2myi6i7lv4GhbXUD6AwHpGUAaMMGYGx9VJZStSUJSgK%2Bq1ppoLV6rxvxOSKbk%2FS9krFASB1tGmjDLNcVCzxA33yzZ0gj%2Bz11qIw1oAtljx9qEj0IMGLpvbu7oUNjhFEXv9xS9vTil7H1DDSgEMW%2BZl%2FbMWiFhv8S6%2FA%2F%2FxSgXxo6sBItAEUNc5hRxTtBGsGl1uuxSDQtwmxO8ZfC8Mk5NU%2BV1msShzJUTtsxVh7FyOoyVP5TXCV6FsXJ7aox%2FSoUJDSh4EcWAwVJbqFCP6xTuWVmFONbawtZihGYL%2FAIwKZ0J2i7%2B1Dpjmx4%2BJVNUm2VfR%2FNSvVGXvicoZRXwfstY2sGB3OlJ5NbUdS1YDxt5PtKOGfgUHR7pFUEt%2FcPRoV7YTaidhTUq0EsD5wzkuYDaUkaY0xED92eGuzGMUC7mGzfeDSr10QrlmKY09E1LGg4VKmnUJ04%2Fwp7KtTwl%2FTjkr0YVPRcwLT6r68vKF1HhB1VVL%2Ff1zsuiXqvlJ8rGoXG0%2B0ZeA1lJv5Wycq1%2BVvKcUlDUhmViQN5%2FHWfpt46XnPGoJtg2A8Yc3Atmi0mk7K8FUsF6WZFBTX4hpYSW9LceNxbGWR6DAa9Iyq7BBmEht7cQ30OGIqA66rkxUb8gmNBybxxG8SNWwCjhbuEy4ue1zLrJNbqG8vAZ19pX5c%2BQ2dI2GfPseRga7qObidtzZzAXspyix7AXPS1NeEqXoXfZyFkjhvgx%2Fi4UFG4yVrTU0uKiFGgRCrX25kql84OCVxo%2FoTjWc1tWtdKKugL5zryDgi2M0Od4jv9HCWfhHrHPtXKNCfBaRQREpahV2jTgwCkOBKMfpxhaqTW5HVypH4ixlm7TgvdkD0cLps1c40SD6d5AOy%2FN0PeLpt3lyEg7pl8Qxh2JPcpsJQb5A3nMaEtLGLgUxGP0a%2BOA%2FGRRt9eOug%2BJyQZt6rD5bdSOZ%2FEnyZmcvpzJtboRO7LW%2BWPbV5ONPfwAYbcm5eM3oWNTIllB0Hqrw%2B5Qtq7XAdzB3ut4NTlkLcLHFXCcJHLQfldnYAV0TYIzzedC%2FYF%2BaUbzgfzUomVp29mFoYE209agDGdBea3kMSmMYJ7LmLekOYIBZRTmJQZj0Zopp6SC9ht8YYet9zps%2FWDEyv2pQ%2BkfNGx2%2B0ZTx%2BF1T02Wh1bL6%2FiNZPmj47XxGjS57prJ9amSkL6nxRuHhCzGJiEPxN5srf7Vou9RA%2BxJeyK%2FGeIHbocnsruejAzliTzbgHVEt1O5mi%2B1nkfczhOfAA9uSPq%2BEvPiaOZllMN8dWUmMq2uLYVUL5afEOQZSBsHI7jbim9T3kRSYc7F1pPbX%2FjJ5Duy9L9fyyksoZxnK6XG5%2BVprjRZ98tX%2F0Wv7WT7eodcVPSkhG4ArvXtlFqITs%2BSO7YwP26QnvE9RyhNzCu5HrMzZRhE38E26D7ED3SqZrX0XsoeRkGar%2FhcetYUyt4doXFzxcOFtyD6lpRactaSFiefUlCOt1QFX8ssRnmGgZIXSjHSK3HbCVhreY2G%2Fs7jRc%2FAJeL8XEnQ5YwPHY8TZIGm7BO8dpBqOaf%2FNMWdIuXzelM%2BbxTKF45M%2BfT911wA2TL1Nnj90fsO8WPnVA%2FdO42KGRW8uo%2FKAqdJ5xYd3wbai1HpnJlYuPrj8ljM%2FTTfX7ZT9WEXae4yj8HTpcyr1Re4Uu%2Bqz5jdq%2F8A%3C%2Fdiagram%3E%3C%2Fmxfile%3E\"\u003e\u003c/iframe\u003e\n\n\n\n\n## Appunti incontro\n+ devono modificare comportamento e valori di default di `exist` in id_manager (deve ritornare True di default)\n+ il metodo check_digits() deve essere tolto dalla classe base (perch√© non tutti gli id manager ce l'hanno) e forse sarebbe anche meglio non metterlo come metodo pubblico, dal momento che tendenzialmente lo si usa solo dentro is_valid (ui secondo me √® da vedere, perch√© forse riesco ad immaginarmi dei casi in cui posso usarlo separatamente nel processo di validazione). \n-----------------------------\n++++++++++++++++++++++\n\n\n\n+ **la validazione √® solo intra-tabella** (per esempio, utente specifica un issn e mi dice che √® un publication type che un issn, *per il fatto di essere un issn*, non pu√≤ essere, tipo journal_article!). Non devi mai controllare le informazioni semantiche estraibili con l'API con i dati inseriti dall'utente, ma fidarti dell'utente:\n\t+ es., se l'utente inserisce un doi sbagliato per la risorsa che ha caricato (quindi inserisce un titolo che non √® quello che corrisponde a quello che otteniamo dall'API per l'identificativo inserito), noi ci fidiamo e prendiamo per buono quello che dice l'utente, senza nemmeno segnalare niente!\n\t+ get_extra_info tu non lo dovresti usare mai! perch√© l'unica cosa che devi vedere con l'api √® se la risorsa esiste, per il resto di fidi dell'utente rispettp ai dati che ha inserito. anche perch√®, silvio fa notare, potrebbe tranquillamente essere che i dati che otteniamo dall'api siano scorretti.  \n\n+ COSA SALVARE NEL REPORT DELLA VALIDAZIONE? SOLO GLI ERRORI O ANCHE I VALORI PER I DATI CHE HANNO PASSATO LA VALIDAZIONE? Silvio dice che il report dovr√† essere un json (quindi prima potr√† essere un dizionario); se salvi tutto quanto, salvi anche dati \"inutili\", per√≤ rendi le cose pi√π facili dopo per la creazione dell'interfaccia; se salvi solo gli errori, risparmi spazio, e comunque puoi localizzare successivamente gli errori sul documento originale (credo?), ma le cose sono pi√π difficili al momento di creare l'interafaccia. Silvio prima osserva che a questo punto conviene salvare direttamente tutto, poi consiglia di **mettere, a monte del processo di validazione un flag (booleano), che potrebbe essere un parametro della funzione principale (??) che regoli che cosa ritornare in output**: es. se true ritorna tutti i dati, se false ritorna solo gli errori. \n+ per wikipedia usa page id che √® sicuro, in quanto non cambia. cos√¨ si risolve anche il \"problema\" delle pagine di redirect (mentre una pagina pu√≤ essere spostata, cio√® cambiare di titolo, e il titolo pu√≤ essere associato ad una pagina di redirect, il page id non cambia). Riguardo alle pagine di disambiguazione Silvio dice che non sono un problema e che anzi vanno mantenute come bibliographic resources valide. \n+ correggi flowchart: se non passa validazione il processo finisce; togli triangolino e metti delle frecce che confluiscono; \n\n## domande\n1. che cosa fare con le extra info? confronto con dati inviati dall'utente pu√≤ andare? risposta: vedi sopra\n\n","lastmodified":"2023-03-19T23:54:38.512579397Z","tags":null},"/notes/meetings/meeting-006":{"title":"Meeting 006","content":"\u003cspan \n\t\tclass=\"ob-timelines\"\n\t\tdata-date=\"2022-10-06-00\"\u003e\n\u003c/span\u003e\nüìë [**Reference session: 006**](notes/sessions/session%20006.md)\n\nüîô [**Previous meeting: 005**](notes/meetings/meeting%20005.md)\n\n- Metti etichette per identificare livelli di validazione, invece che numeri (fai in modo che sia pi√π chiaro)\n\n- Il valore di field deve essere sempre lista che contiene 0 o pi√π componenti e ognuno dei componenti √® descrittivo \n\n\n- Output dev'essere descrittivo, deve dire tutto tutto, compresa la spiegazione dell'errore (non puoi fare elaborazioni successivamente, dev'essere gi√† tutto pronto nel report).\n\n\n- Ricorda flag per mettere sia dei dati in senso attivo, quindi rendere esplicito anche che un dato √® risultato valido, oppure no. In ogni caso, vedi tu se riportare sia le stringhe dei dati che la posizione nel report.\n\n- JSON schema per definire report!\n\n\n- Metti INDICE per la posizione degli elementi all'interno di un field, non (o meglio sicuramente non SOLO) il valore della stringa\n\n\n- Controlla direttamente i singoli elementi all'interno del field 'id' sul controllo del formato OC, invece che chiamare prima il controllo sulla cella: non ha senso, chiami la stessa cosa due volte(?)\n\n- Silvio: un validatore non dice \"forse\", un validatore dice \"s√¨\" o \"no\". Lui sarebbe strict nel validare. Bisogna pensare se ha senso tenere in considerazione warning, nel caso in cui individuassimo dei casi in cui ci viene da dire che warning sarebbe proprio perfetto. Un esempio di warning, in quest'ottica, potrebbe essere per un titolo che venga inserito con tutte le lettere maiuscole: non √® sbagliato rispetto alla sintassi della tabella, quindi non √® un errore, tuttavia √® un po' strano --\u003e warning\n\n- Validazione severa! e valuta se ha senso avere anche degli warning oppure no. DEVI VALIDARE RISPETTO ALLA DEFINIZIONE DELLA SINTASSI, NON A QUELLO CHE FA IL SOFTWARE DI OPEN CITATIONS. NON C'√® SOLO META, C'√® ANCHE CROCI. Non pensare a quello che Meta gestisce o no, considera valido solo quello che √® definito valido nella sintassi delle tabelle di CITS-CSV e META-CSV. \n\n\n- TITOLO MAIUSCOLO --\u003e WARNING NON ERROR, se vogliamo tenere warning\n\n- Nel caso di spazi multipli, ad esempio, tra un ID e l'altro all'interno del field 'id', devi decidere se considerarlo errore (bloccante) o no in base alla definizione della tabella; non importa se il software di OC lo gestisce, se √® sbagliato √® sbagliato. Devi coordinarti con chi √® responsabile della sintassi della tabelle di META-CSV e CITS-CSV.\n\n\n \n\n\n\n","lastmodified":"2023-03-19T23:54:38.512579397Z","tags":null},"/notes/meetings/meeting-007":{"title":"Meeting 007","content":"\u003cspan \n\t\tclass=\"ob-timelines\"\n\t\tdata-date=\"2022-10-13-00\"\u003e\n\u003c/span\u003e\nüìë [**Reference session: 00X**](#insert path)\n\nüîô [**Previous meeting: 00X**](\"#insert path\")\n\n\n### appunti\n\n* warning potrebbe essere quando su meta vengono messe due row con lo stesso identificativo (duplicazione ): non √® sbagliato ma \n* non ci possono essere duplicati della stessa informazione \n* assolutamente da mettere posizione esplicita nel json dell'output della validazione, non lasciare che venga inferita dalla struttura!!\n* non √® un problema che il report del json non sia compatibile con lo schema di JSON Schema per l'output delle validazioni fatte da implementazioni di JSON Schema! Loro hanno il loro schema, tu hai il tuo\n* vedi matrice di silvio per questione dei duplicati da trovare  e unificare (√® semplice!)\n* non ha senso cercare di mappare l'output con lo schema che vuoi tu a delle funzioni di librerie per validare come python-jsonschema\n* il JSON Schema del report serve a te per:\n  1. Avere un'idea pi√π chiara di cosa ti serve nell'output e come deve essere strutturato\n  2. verificare che quello che emette una tua funzione di validazione nel codice che hai scritto sia compatibile con questo schema","lastmodified":"2023-03-19T23:54:38.512579397Z","tags":null},"/notes/meetings/meeting-008":{"title":"Meeting 008","content":"\u003cspan \n\t\tclass=\"ob-timelines\"\n\t\tdata-date=\"2022-10-20-00\"\u003e\n\u003c/span\u003e\nüìë [**Reference session: 008**](notes/sessions/session%20008.md)\n\nüîô [**Previous meeting: 007**](notes/meetings/meeting%20007.md)\n\n+ stringhe di messaggi all'utente vanno messe in un file di configurazione esterno, non nella struttura interna del codice!\n+ correggi il dizionario dell'errore. Deve essere \"ricco\" abbastanza da fare in modo che la macchina possa dedurre automaticamente qual √® l'errore e in quale posizione √® localizzato. Sicuramente √® da aggiungere una key-value che renda esplicito il tipo di localizzazione, qualcosa come:\n```python\n{\n...\n\t\"position\":{\n\t\t...\n\t\t\"localization_category\": 'row' #uno dei seguenti valori: 'row', 'field', 'item'\n\t\t...\n\t}\n}\n```\nInoltre bisogna rendere \"sempre uguale\" il modo in cui la posizione viene espressa, mantenendo *sempre* all'interno del dizionario `position` le chiavi per `idx_in_field` (che dovrebbe diventare `item`) e `field` (cio√® cambiano solo i valori). Vedi figura:\n![Silvio's draft example of the position data expressed in a rich way](images/example_of_rich_position_dictionary.jpg)\n\n\n","lastmodified":"2023-03-19T23:54:38.512579397Z","tags":null},"/notes/meetings/meeting-009":{"title":"Meeting 009","content":"\u003cspan \n\t\tclass=\"ob-timelines\"\n\t\tdata-date=\"2022-10-25-00\"\u003e\n\u003c/span\u003e\nüìë [**Reference session: 009**](notes/sessions/session%20009.md)\n\nüîô [**Previous meeting: 008**](notes/meetings/meeting%20008.md)\n\n\n## Nuove regole per META-CSV\nUpdate di Arcangelo delle regole per META-CSV (requirements in mancanza di un valore per 'id'). Se ho capito bene:\n\t* quando il type specificato √® \"journal volume\", √® obbligatoria almeno una delle due seguenti coppie:\n\t\t* venue AND volume\n\t\t* venue AND title\n\t* quando il type specificato √® journal issue, √® obbligatoria almeno una delle due seguenti coppie:\n\t\t* venue AND issue\n\t\t* venue AND title\nVedi [documentazione in pdf](https://github.com/opencitations/metadata/blob/675dc9cd3cc143542656569547849e0efa3ea5aa/documentation/csv_documentation.pdf) (permalink alla versione) con la modifica spiegata; una tabella ufficiale ancora non c'√®, per ora vedi [questa qui](https://www.notion.so/9ba47ffd44c7423aa11d1f4e57de3879?v=d98080cf7c0f4b31b742fcfc848cb129).\n\n\n## Correggi position \n![](images/2022-10-25.png)\n![](images/2022-10-25%20(4).png)\n![](images/2022-10-25%20(3).png)","lastmodified":"2023-03-19T23:54:38.512579397Z","tags":null},"/notes/meetings/meeting-010":{"title":"Meeting 010","content":"\u003cspan \n\t\tclass=\"ob-timelines\"\n\t\tdata-date=\"2022-10-31-00\"\u003e\n\u003c/span\u003e\nüìë [**Reference session: 010**](notes/sessions/session%20010.md)\n\nüîô [**Previous meeting: 000**](notes/meetings/meeting%20009.md)\n\n\n### Report degli errori: aggiornato il dizionario per la posizione\nHo aggiornato i JSON schema[^1] secondo le indicazioni di [meeting 009](notes/meetings/meeting%20009.md), modificando il dizionario `position` all'interno del report in modo che abbia:\n* una voce `located_in` che fa riferimento al tipo di posizione (se l'errore nasce in un confronto tra rows, `located_in` avr√† valore `row`; se nasce da un confronto tra field di una stessa row, `located_in` avr√† valore `field`; se l'errore √® relativo a un item, `located_in` avr√† valore `item`)\n* una voce `table`, che √® un *albero* rappresentato come dizionario: le leaves sono sempre liste contenenti gli indici degli item interessati dall'errore[^2]; il genitore (chiave) di una lista di indici di items √® un field; il genitore di un field √® una row. \n* Esempio di report per la validazione di **un singolo item**:\n\t```json\n\t{'validation_level': 'csv_wellformedness',\n\t  'error_type': 'error',\n\t  'message': 'The value in this field is not expressed in compliance with the '\n\t             \"syntax of OpenCitations CITS-CSV. The content of 'citing_id' and \"\n\t             \"'cited_id' must be either a single ID or a sequence of IDs, each \"\n\t             'separated by one single space character (Unicode Character '\n\t             '‚ÄúSPACE‚Äù, U+0020). Each ID must not have spaces within  itself, '\n\t             'and must be of the following form: \u003cID abbreviation\u003e + ‚Äú:‚Äù + \u003cID '\n\t             'value\u003e.\\n',\n\t  'position': {'located_in': 'item', 'table': {0: {'citing_id': [1]}}}}\n\t```\n\n\n### Modifiche alla struttura principale per CITS-CSV\n\n^21392f\n\n- [permalink alla versione del file](https://github.com/eliarizzetto/thesis_resources/blob/3e540fd7a9a3b8d8fe741d146608a8e1d90d2566/CITS/validate_cits.py)\n* messaggi all'utente in file di configurazione esterno (‚Üí da chiavi con nomi pi√π espliciti nel file yaml)\n* adattato struttura a nuova forma di `position` (ad es. se il field di una row √® `citing_publication_date` o `citing_publication_date` ‚Üí allora ‚Üí `table = {row: field: [0]}`, dal momento che questi field non vengono \"scomposti\" in items).\n* **√à importante poter distinguere quale specifico errore (cio√® quale funzione di validazione non √® stata passata) a partire soltanto dai dati in `position` e nel resto del report?** ‚Üí Il problema √® che ad un solo report possono corrispondere diversi messaggi e diverse funzione di validazione fallite!\n\t![ambiguous_report](images/ambiguos_report.jpg)\n\n\n### Disperati tentativi di gestire i duplicati delle citazioni\n\nQuando delle citazioni si ripetono nel documento, si tratta di un errore.\n* Quante e quali casistiche di duplicazione sono possibili, e quindi da individuare?\n* Le citazioni devono essere considerate tra *identificativi*  o tra *entit√† bibliografiche*? \n* √à necessario mappare a dei meta-identificativi ciascun ID tra quelli che ci sono nel documento (sulla base della co-occorrenza di alcuni di essi in uno stesso field)? \n* Nel caso di una citazione duplicata, la posizione di quali elementi dovrebbe essere presente nel report dell'errore?\n\nVedi [Duplicates examples](notes/Duplicates%20examples.md).\n\n[^1]: [Branch](https://github.com/eliarizzetto/thesis_resources/tree/1-semantically-richer-error-dictionaries-meeting-008) dedicato. Vedi: JSON Schema [per singolo errore](https://github.com/eliarizzetto/thesis_resources/blob/3e540fd7a9a3b8d8fe741d146608a8e1d90d2566/check_output/single_validation_output_schema.json) e [per tutto il report](https://github.com/eliarizzetto/thesis_resources/blob/3e540fd7a9a3b8d8fe741d146608a8e1d90d2566/check_output/error_report_schema.json); funzione per creare i dizionari in [`create_report.py`](https://github.com/eliarizzetto/thesis_resources/blob/3e540fd7a9a3b8d8fe741d146608a8e1d90d2566/CITS/create_report.py). \n[^2]: Nel caso in cui un field sia una stringa vuota √® opportuno rappresentare questa posizione con None? Se s√¨, all'interno di una lista? Esempio 1: `'table': {0: {'citing_id': [None]}`; esempio 2: `'table': {0: {'citing_id': None}`.\n\n\n## Meeting \n\n1. Per rappresentare la posizione di un errore relativo a un field vuoto (o che coinvolge un field vuoto), il valore di `table[row][field]` deve essere semplicemente `None`, (**non** una lista contenente `None`!). Ad esempio, nel caso in cui l'errore sia il fatto che un field obbligatorio, per un determinato type di pubblicazione non √® specificato, il report potrebbe avere una struttura come questa:\n\n```\n{\n\t'validation_level': 'csv_wellformedness',\n\t  'error_type': 'error',\n\t  'message': 'The value in this field is not expressed in compliance with the '\n\t\t\t\t \"syntax of OpenCitations CITS-CSV. The content of 'citing_id' and \"\n\t\t\t\t \"'cited_id' must be either a single ID or a sequence of IDs, each \"\n\t\t\t\t 'separated by one single space character (Unicode Character '\n\t\t\t\t '‚ÄúSPACE‚Äù, U+0020). Each ID must not have spaces within  itself, '\n\t\t\t\t 'and must be of the following form: \u003cID abbreviation\u003e + ‚Äú:‚Äù + \u003cID '\n\t\t\t\t 'value\u003e.\\n',\n\t  'position': {\n\t\t  'located_in': 'field', \n\t\t  'table': {\n\t\t\t  0: {'title': None,\n\t\t\t\t  'publication_type': [0]\n\t\t\t}\n\t\t  }\n\t  }\n}\n```\nLa lista vuota come valore del field (es. `'table': {0: {'citing_id': []}` ) tienila a mente come possibilit√† futura per rappresentare alcune casistiche, anche se per ora non ci viene in mente nessun caso in cui possa essere utile. \n\n2. Per risolvere il problema sollevato in [Modifiche alla struttura principale per CITS-CSV](#Modifiche%20alla%20struttura%20principale%20per%20CITS-CSV), ovvero che a funzioni di validazione diverse corrispondono error report uguali, rendendo impossibile distinguere la tipologia di errore specifica in modo machine-readable, bisogna **aggiungere una label ulteriore nel report, che specifichi, oltre al validation_level, anche di quale errore specifico si tratta**, all'intero della tassonomia. Ad esempio, per poter distinguere il fatto che un item non √® valido \u003cu\u003eperch√© √® uno spazio\u003c/u\u003e dal fatto che non √® valido \u003cu\u003eperch√© non rispetta la regex  del formato degli identificativi\u003c/u\u003e, si metter√† qualcosa come:\n   \n```\n[\n{'validation_level': 'csv_wellformedness',\n 'error_label': 'csv_wellformedness-space',\n 'error_type': 'error', ‚¨ÖÔ∏è‚¨ÖÔ∏è‚¨ÖÔ∏è\n  'message': 'The value in this field is not expressed in compliance with the '\n             \"syntax of OpenCitations CITS-CSV. The content of 'citing_id' and \"\n             \"'cited_id' must be either a single ID or a sequence of IDs, each \"\n             'separated by one single space character (Unicode Character '\n             '‚ÄúSPACE‚Äù, U+0020). Each ID must not have spaces within  itself, '\n             'and must be of the following form: \u003cID abbreviation\u003e + ‚Äú:‚Äù + \u003cID '\n             'value\u003e.\\n',\n  'position': {'located_in': 'item', 'table': {0: {'citing_id': [1]}}}},\n {'validation_level': 'csv_wellformedness',\n  'error_label': 'id_format', ‚¨ÖÔ∏è‚¨ÖÔ∏è‚¨ÖÔ∏è\n  'error_type': 'error', \n  'message': 'The value in this field is not expressed in compliance with the '\n             'syntax of OpenCitations CITS-CSV.  Each identifier in '\n             \"'citing_id' and/or 'cited_id' must have the following form: ID \"\n             'abbreviation + ‚Äú:‚Äù + ID value. No spaces are admitted within the '\n             'ID. Example: doi:10.48550/arXiv.2206.03971. The accepted '\n             \"prefixes  (ID abbreviations) are the following: 'doi', 'issn', \"\n             \"'isbn', 'pmid', 'pmcid', 'url', 'wikidata', 'wikipedia'.\\n\",\n  'position': {'located_in': 'item', 'table': {0: {'citing_id': [1]}}}}\n]\n\n```\n\nOgni errore (cos√¨ come rilevato da una specifica funzione di validazione) avr√† quindi la sua label, in modo che sia distinguibile del tutto dagli altri errori, non soltanto attraverso il messaggio all'utente (che pu√≤ quindi anche essere ambiguo, nonostante non abbia troppo senso, visto che cos√¨ si pu√≤ spiegare l'errore con un buon grado di specificit√†).\n\nInoltre, **rivedi i messaggi all'utente** anche in relazione a questo. ","lastmodified":"2023-03-19T23:54:38.512579397Z","tags":null},"/notes/meetings/meeting-011":{"title":"Meeting 011","content":"\u003cspan \n\t\tclass=\"ob-timelines\"\n\t\tdata-date=\"2022-11-08-00\"\u003e\n\u003c/span\u003e\nüìë [**Reference session: 011**](notes/sessions/session%20011.md)\n\nüîô [**Previous meeting: 010**](notes/meetings/meeting%20010.md)\n\n## **To do**\n* [x] Duplicates\n* [x] Correggi JSON schemas e `create_report()` in base a indicazioni in [meeting 010](notes/meetings/meeting%20010.md) (`None` fuori dalla lista;  label specifica per ogni tipo di errore nel report)\n* [ ] Completa/rivedi messaggi all'utente\n* [x] Estendi [Errors map](notes/Errors%20map.md)\n* [x] Aggiungi controlli per i **required fields**\n* [ ] Verifica strategia per l'ordine/priorit√† con cui validare la tabella: quali controlli si fanno sempre e quali invece si fanno solo quando altri controlli sono passati?\n\n## Duplicates\nOra si riescono a rilevare gli errori legati alla duplicazione di ID, di bibliographic entities o di citazioni:\n- ripetizione della stringa di un ID nella stessa cella ‚Üí \u003cu\u003ewarning\u003c/u\u003e\n- ripetizione di un entit√† bibliografica nel campo `citing_id` e `cited_id` della stessa riga  ‚Üí \u003cu\u003eerror\u003c/u\u003e\n- ripetizione di una citazione (rapporto tra 2 entit√† bibliografiche) (cio√® quando una stessa citazione √® rappresentata in pi√π di una riga) ‚Üí \u003cu\u003eerror\u003c/u\u003e\n\n\n\n## Incontro\n\n* la ripetizione di uno stesso ID nella stessa cella √® un **errore** e ha **valid = False**, perch√© - per lo meno Arcangelo con META - il campo contenente gli ID viene gestito come lista, non come set. Poi √® una modifica che Arca potrebbe fare, ma il principio √® che se un dato inviato dall'utente richiede delle modifiche al codice per essere integrato, allora √® un dato sbagliato!\n\n* la self-citation √® **valid=True** perch√© √® una cosa in linea di principio possibile! Per√≤ segnalalo comunque come **warning**, perch√© il pi√π delle volte (?) deriva da un uso sbagliato del data model (?) ","lastmodified":"2023-03-19T23:54:38.512579397Z","tags":null},"/notes/meetings/meeting-012":{"title":"Meeting 012","content":"\u003cspan \n\t\tclass=\"ob-timelines\"\n\t\tdata-date=\"2022-11-16-00\"\u003e\n\u003c/span\u003e\nüìë [**Reference session: 012**](notes/sessions/session%20012.md)\n\nüîô [**Previous meeting: 011**](notes/meetings/meeting%20011.md)\n\n\n## META-CSV: domande\nversione: https://github.com/eliarizzetto/thesis_resources/blob/f5d0a5e189b17df71173e1542857e9ae630d4998/CITS/validate_meta.py\n\n\n\n\n### 1. Come suddividere in items i valori dei field dei r.a.?\n* ~~author e editor vogliono obbligatoriamente la virgola~~ {la virgola pu√≤ anche non esserci, come nel caso in cui author non sia una persona ma un azienda, ad esempio}.\n* ~~publisher non ammette la virgola (???)~~ {il publisher ammette la virgola, vedi sotto}\n* le quadre ci sono solo se contengono ID all'interno (mai `[]` vuote!)\n* presto Arcangelo gestir√† anche la possibilit√† di avere solo gli identificativi all'interno delle quadre, senza che siano associati alla stringa di un nome\n\n\nHo bisogno di un modo che suddivida questi field in item garantendo che:\n* \u003cu\u003efunzioni sempre nello stesso modo\u003c/u\u003e, indipendentemente dalla stringa in input (per poter localizzare un errore nel documento in input in maniera coerente)\n* la \u003cu\u003elocalizzazione dell'errore sia quanto pi√π possibile precisa\u003c/u\u003e, ovvero tutto ci√≤ che analizzo come input di una funzione di validazione deve avere la sua posizione in `table`. Idealmente, devono poter essere identificabili come item tutti i seguenti \"tipi\" di stringa:\n\t* spazi ‚Üí per trovare gli spazi extra\n\t* singoli identificativi ‚Üí per controllarne il formato OC, la sintassi, l'esistenza e la coerenza con il tipo specificato\n\t* in generale tutto quello che non pu√≤ essere considerato valido come item all'interno del field (caratteri illegali come `;`, `[`, ecc. \n* allo stesso tempo siano inclusi nella lista degli item anche quelli validi, naturalmente\n\nSono esempi di errori:\n* spazi, quadre, punti-e-virgola *extra*\n* id non ben formati (formato OC o sintassi specifica)\n* sequenze di items errate, come nel caso di virgole mancanti tra un cognome e una `[`, o punti-e-virgola mancanti tra due gruppi `cognome, (nome)`...\n\n#### Esempio\n```\nTostivint, Herv√©; Trabucchi, Michele [orcid:0000-0001-6885-5628 doi:10/1234]; Conlon,; Lihrmann, Isabelle\n```\nUna stringa come questa qui sopra, √® possibile/sensato rappresentarla con la lista di items qui sotto? \n\n```python\n[\n'Tostivint,',\n'Herv√©',\n';',\n'Trabucchi,',\n'Michele',\n'[',\n'orcid:0000-0001-6885-5628',\n'doi:10/1234',\n']',\n';',\n'Conlon',\n';',\n'Lihrmann,',\n'Isabelle'\n]\n\n```\n\nHo dato un'occhiata alle regex di Arcangelo: https://github.com/opencitations/oc_meta/blob/master/oc_meta/lib/master_of_regex.py\n\n##### Il field publisher non ammette virgole nel nome?\nS√¨, anche il field publisher pu√≤ contenere virgole, perch√© pu√≤ tranquillamente essere incluso nel nome della casa editrice. La virgola nel campo publisher viene trattata semplicemente come qualsiasi altro carattere all'interno della stringa, mentre nel caso di author e editor, se c'√®, viene trattata come separatore (tra nome e cognome). \n\n### 2. url e wikipedia sono ID possibili per tutti i responsible agents (authors, publisher, editor)?\n\nRisposta: **\u003cu\u003eNo, n√© url n√© wikipedia sono ammissibili come ID di responsible agents, li teniamo solo per le br!\u003c/u\u003e**\n\n\n# Incontro\n\n### Risposta 1\n\nGli item sono quelli separati dal punto-e-virgola + spazio: `; `. [^1]Non si pu√≤ localizzare pi√π precisamente di cos√¨, quindi la localizzazione di un errore in `table` sar√† sempre relativa alla posizione dell'item in questa lista, anche se l'errore sta in una parte specifica all'interno di quell'item; quello che cambia √® il messaggio human-readable, che deve essere pi√π specifico possibile, e chiaramente un'indicazione √® data anche dal `validation_level` e dall'`error_label`. \n\n[^1]: Il criterio generale con cui un field viene diviso in items deve essere fisso. Il criterio in questione √® che un field che ammette pi√π elementi ha un separatore specifico (gli spazi nel caso del field `id`, ad esempio; il punto e virgola nel caso di `author`); su questa base mi sembra che non abbia molto senso dividere in item anche quei field che per sintassi non contengono pi√π elementi (ovvero non hanno separatori): ad esempio, il field `pub_date` non andrebbe splittato, (nonostante il modo in cui esprimo la posizione di un errore in table), in quanto non ha un separatore. \n\nAd esempio, nel caso della stringa:\n```\nTostivint, Herv√©; Trabucchi, Michele [orcid:0000-0001-6885-5628 doi:10/1234]; Conlon,; Lihrmann, Isabelle\n```\nLa lista di items sarebbe:\n```python\n'Tostivint, Herv√©',\n'Trabucchi, Michele [orcid:0000-0001-6885-5628 doi:10/1234]',\n'Conlon,',\n'Lihrmann, Isabelle'\n```\nNel caso in cui volessi rappresentare il fatto che un doi non pu√≤ essere associato a un author, il report sarebbe localizzato in `position` in questo modo: `table: {0:{'author':[1]}}`, ma avrebbe `'validation_level': 'semantic'`, magari una `error_label` specifica, e conseguentemente un `message` preciso/dettagliato.\n\n\nForse, si pu√≤ anche pensare di usare le formatted strings per localizzare la posizione dell'ID, ad esempio, nel messaggio all'utente, dando qualche indicazione **non** machine readable.\n\n\nInoltre, tieni presente che non solo non √® necessario, ma non sarebbe nemmeno corretto, mappare le stringhe dei nomi a gruppi di identificativi (le stringhe dei nomi, infatti, possono variare, ad esempio con abbreviazioni, secondi nomi, ecc.). --\u003e per META-CSV non bisogna mappare niente, per quanto riguarda i RA. ","lastmodified":"2023-03-19T23:54:38.512579397Z","tags":null},"/notes/meetings/meeting-013":{"title":"Meeting 013","content":"\u003cspan \n\t\tclass=\"ob-timelines\"\n\t\tdata-date=\"2022-11-22-00\"\u003e\n\u003c/span\u003e\nüìë [**Reference session: 013**](notes/sessions/session%20013.md)\n\nüîô [**Previous meeting: 012**](notes/meetings/meeting%20012.md)\n\n### Updates:\n* https://github.com/eliarizzetto/thesis_resources/tree/main/CITS\n* regex per controllare il formato degli ***item*** dei RA (il formato di tutto l'item, \u003cu\u003eindistintamente\u003c/u\u003e rispetto alla posizione degli errori all'interno dell'item stesso: l'errore √® lo stesso se si trova negli ID o nella parte dei nomi).\n\n### Domande:\n* **Ha senso controllare che al di fuori delle quadre in `author`, `editor` e `publisher` non ci siano delle stringhe che potrebbero facilmente essere degli identificativi?** \n\tPer ora trovo con una regex casi in cui c'√® un singolo ID o una serie di IDs senza quadre intorno, ma non funziona sempre (ad esempio, se c'√® uno spazio all'inizio della stringa non trova match). --\u003e se √® utile cerco di sistemarlo (il problema principale √® che non so come includere pi√π casistiche rispetto a quelle rilevabili finora *senza* includere anche quelle che voglio lasciare fuori, ovvero quando l'ID si trova giustamente dentro le quadre).\n\u003cu\u003e**Risposta**\u003c/u\u003e:\nS√¨, molto sensato mettere un **WARNING**: basta soltanto usare una regex generica (anche solo prefisso seguito da due punti) su tutto ci√≤ che √® fuori dalle quadre; solo che invece che fare tutta la gincana di regex per trovare il match sull'item intero, basta soltanto tagliare fuori dall'item tutto quello che non √® tra quadre (con `re.split()` per esempio) e cercare un match con la regex generica su quello che rimane (che quindi verrebbe sicuramente interpretato come nome/cognome) \n\n\n* Mi confermate che se un ID per BR (qualsiasi ID per BR) si trova su pi√π di una riga su META-CSV, allora si tratta certamente di un duplicato?\n\u003cu\u003e**Risposta**\u003c/u\u003e:\nS√¨, non ci sono casi in cui uno stesso ID di una BR pu√≤ comparire su pi√π righe. \n\n\n### Incontro \nTieni presente che publisher e editor/author vanno trattati in maniera leggermente diversa:\n* la regex non pu√≤ essere esattamente la stessa, dal momento che la virgola nel campo `publisher` non ha valore semantico (in Meta non viene processata come per author e editor, in cui separa cognome e nome), e quindi pu√≤ essere presente pi√π di una volta per la stessa entit√† (perch√© tanto la stringa del nome del publisher viene presa cos√¨ com'√®). \n","lastmodified":"2023-03-19T23:54:38.512579397Z","tags":null},"/notes/meetings/meeting-014":{"title":"Meeting 014","content":"\u003cspan \n\t\tclass=\"ob-timelines\"\n\t\tdata-date=\"2022-11-29-00\"\u003e\n\u003c/span\u003e\nüìë [**Reference session: 014**](notes/sessions/session%20014.md)\n\nüîô [**Previous meeting: 013**](notes/meetings/meeting%20013.md)\n\n### Quasi finito il primo livello di validazione\nOra sono gestiti anche: \n* field `venue`, `volume`, `issue`, `page` e `type`\n* duplicate rows\n* required fields\n\n## Domande\n\n### Caratteri legali nelle stringhe dei nomi di persona\nQuali caratteri sono legali nella stringa di un nome (a parte i separatori) per le *people*? In particolare: cifre? segni di punteggiatura che non siano il trattino o l'apostrofo? parentesi? ... Considera la possibilit√† di avere [nomi anagrafici particolarmente strani](https://www.wikidata.org/wiki/Q93418989), degli alias o dei nomi d'arte, ecc.\n\n\u003cu\u003e**Risposta**\u003c/u\u003e:\nNessun controllo ulteriore rispetto a quelli gi√† in atto. \n\n### Caratteri legali e/o obbligatori nei field `volume` e `venue`\nChe controlli devo fare per quanto riguarda il formato dei field 'volume' e 'venue'? ‚Üí per ora l'unica cosa che controllo √® che non ci siano spazi extra all'inizio, alla fine o in mezzo.\n\n\u003cu\u003e**Risposta**\u003c/u\u003e:\nNessun controllo ulteriore rispetto a quelli gi√† in atto. \n\n### Caratteri legali per field `page`\nChe controlli devo fare per il field 'page'? Soprattutto:\n* √à possibile avere una sola pagina (senza intervallo e quindi senza trattino)? Come esprimo l'intervallo di `page` per una risorsa che  non si estende per pi√π di una pagina? Es. \"25-25\" sarebbe corretto?\n* √à possibile avere numeri romani (come per esempio per i capitoli introduttivi)? Per ora li gestisco, ma non tengo presente i casi in cui vengano scritti numeri romani \"sintatticamente\" impossibili, in mancanza di una definizione universale: per esempio, risulta valido anche \"VD\".\n* √à necessario gestire gli intervalli \"impossibili\", tipo \"20-15\"? Se possibile farlo con le regex, penso sia un pattern piuttosto lungo, e d'altro canto trattare le singole parti del field separatamente mi √® sembrato un po' un overkill...\n\n\u003cu\u003e**Risposta**\u003c/u\u003e:\n* Anche per risorse su una pagina sola, la maniera corretta di esprimere √® sempre l'intervallo con il trattino, quindi ad esempio \"25-25\"*\n* Ci sono anche pagine alfanumeriche, es. \"12a-20a\", quindi la regex deve essere ampliata per includere anche quelle\n* Gli intervalli impossibili sono un errore, o per lo meno un warning: devi controllarli, √® rilevante; un workflow sensato sarebbe, **se possibile**, convertire i caratteri non numerici (tipo numeri romani) in integers (anche tranquillamente con una libreria); poi, se la conversione √® riuscita, controllare che il primo carattere sia minore del secondo. Anche se non √® possibile farlo per tutti i tipi di numero di pagina (ad esempio i caratteri alfanumerici rimarrebbero fuori) vale comunque la pena farlo per quelli per cui si riesce. \n\n### Required fields per le righe che hanno specificato un valore in `volume` e/o `issue`:\nNel caso in cui nel campo 'id' non sia specificato alcun valore, si applicano almeno gli stessi requirement che nel caso in cui esso sia specificato, e *\u003cu\u003ein aggiunta\u003c/u\u003e* quelli che si applicano nel caso in cui non sia specificato (in base al tipo)? Ovvero, se non c'√® nessun ID:\n* devono essere specificati 'venue', 'volume' e/o 'issue' e inoltre il type deve essere uno tra 'journal article', 'journal volume' e 'journal issue'\n* in aggiunta si applicano gli eventuali requirement applicati nei casi in cui non sia presente l'id? (di base, solo per 'journal article' che in questo caso vuole anche `title`, `pub_date`, `author` e/o `editor`)\n\n**√à effettivamente cos√¨?**\n\nhttps://github.com/opencitations/metadata/blob/master/documentation/csv_documentation.pdf\n\n![mandatory_fields](images/mandatory_fields.png)\n\n![required_fields_table_updated](images/required_fields_table_updated.png)\n\n\n\u003cu\u003e**Risposta**\u003c/u\u003e:\n\n\ncon id e issue √® oblgoato venue e basta e il tippo deve essere jounral article or journal issue (non journla volume)\n\n\nid e volume: tipo deve essere  jounral ariticle, journla  voluem o journal  issue; il campo venue √® obbligatorio\n\n\t\tse il tipo √® jounral issue allora √® obbligatorio title OR issue\n\n\nPer quanto riguarda le restrizioni/requirements derivanti dalla presenza di un valore per i campi `volume` e/o `issue`, il fatto che `id` sia specificato √® irrilevante. \n\n**Se specifico come tipo `journal volume` allora non posso specificare la `issue`, a prescindere dal fatto che sia specificato `id` oppure no**.\n\nQuindi, indipendentemente dal fatto che sia specificato l'`id` oppure no, se un valore √® specificato per `volume` or `issue`, le regole sono le seguenti:\n*  √® sempre obbligatorio specificare la `venue` \n* √® sempre obbligatorio specificare il type, ma con un valore specifico che dipende da specifiche condizioni, spiegate qui sotto\n\t* se `issue` √® specificato ‚Üí `type` == (`journal article`|`journal issue`)\n\t* se `volume` √® specificato ‚Üí  `type` == (`journal article`|`journal issue`|`journal volume`)\n{ se  `type` == `journal issue` ‚Üí √® obbligatorio specificare (`title`|`issue`)}\n\n\n","lastmodified":"2023-03-19T23:54:38.512579397Z","tags":null},"/notes/meetings/meeting-015":{"title":"Meeting 015","content":"\u003cspan \n\t\tclass=\"ob-timelines\"\n\t\tdata-date=\"2022-12-13-00\"\u003e\n\u003c/span\u003e\nüìë [**Reference session: 015**](notes/sessions/session%20015.md)\n\nüîô [**Previous meeting: 014**](notes/meetings/meeting%20014.md)\n\n## IdentifierManager\nHo fatto Wikipedia, Wikidata e Viaf, ma solo i metodi che uso per validare (manca `get_extra_info()`). Il metodo `normalise` l'ho lasciato uguale o molto simile a quello per i doi.\n\nOra mancano ror e pmcid.\n\n## Page\n* Ho integrato nella funzione `wellformedness_page` i pattern alfanumerici e quelli misti (numeri romani e arabi)\n* Ho creato una funzione `check_interval_page` che ritorna False se l'intervallo √® invalido (integer della start page √® maggiore dell'integers della end page) OR se non √® stato possibile convertire le pagine dell'intervallo (una sola o entrambe) in integers (ad esempio perch√© si tratta di una notazione alfanumerica o perch√© il numero romano non viene convertito dalla libreria che uso, [roman](https://pypi.org/project/roman/)). Se il valore non passa questa funzione viene sollevato un **warning**. \n\n\n","lastmodified":"2023-03-19T23:54:38.512579397Z","tags":null},"/notes/meetings/meeting-016":{"title":"Meeting 016","content":"\u003cspan \n\t\tclass=\"ob-timelines\"\n\t\tdata-date=\"2023-01-05-00\"\u003e\n\u003c/span\u003e\nüìë [**Reference session: 016**](notes/sessions/session%20016.md)\n\nüîô [**Previous meeting: 015**](notes/meetings/meeting%20015.md)\n\n## Identifier Manager\n* finiti tutti gli identificativi, aggiunti quindi pmcid e ror (di quelli che ho fatto io ho integrato solo `syntax_ok` e `exists`, rimane fuori `get_extra_info`)\n* **va bene l'API per pmcid (poche informazioni extra ma senza il limite di richieste)?**\n\n## Allineamento `id` e `type`\nPer verificare la compliance con il data model, devo verificare che id e tipo assegnati ad una stessa risorsa siano compatibili/coerenti.\n\nNella tabella sotto √® riassunta la proposta per le BR:\n* doi, pmid, wikidata, wikipedia e url ‚Üí tutti i tipi\n* issn ‚Üí book series, book set, journal, proceedings series, report series, standard series, series\n* isbn ‚Üí book, dissertation, edited book, monograph, report, reference book, standard\n* **pmcid** ‚Üí dissertation, journal article, peer review, proceedings article, report\n\nIn particolare pmcid √® poco documentato, sappiamo solo che:\n* PubMed Central is an index of full-text papers, while PubMed is an index of abstracts. The PMCID links to full-text papers in PubMed Central, while the PMID links to abstracts in PubMed. https://publicaccess.nih.gov/include-pmcid-citations.htm#Difference\n* Your paper may be included in PubMed Central (PMC) if (https://www.ncbi.nlm.nih.gov/pmc/about/submission-methods/#Determining%20Eligibility):\n\t-   You published in a journal that is fully archived in PMC;\n\t-   You made open access arrangements with a PMC selective deposit journal or publisher program; or\n\t-   Your article was\n\t    -   supported by the National Institutes of Health (NIH), another PMC designated funder, or a member of the Europe PMC funder group;\n\t    -   peer reviewed; and\n\t    -   accepted for publication in a journal.\n* dal 2020 anche preprint sono ammissibili per pmcid, se espongono risultati di ricerche finanziate dal NIH\n\n|type               |doi|isbn|issn|pmid|pmcid|wikidata|wikipedia|url|\n|-------------------|---|----|----|----|-----|--------|---------|---|\n|book               |t  |t   |    |t   |     |t       |t        |t  |\n|dataset/data file  |t  |    |    |t   |     |t       |t        |t  |\n|dissertation       |t  |t   |    |t   |t    |t       |t        |t  |\n|edited book        |t  |t   |    |t   |     |t       |t        |t  |\n|journal article    |t  |    |    |t   |t    |t       |t        |t  |\n|monograph          |t  |t   |    |t   |     |t       |t        |t  |\n|other              |t  |    |    |t   |     |t       |t        |t  |\n|peer review        |t  |    |    |t   |t    |t       |t        |t  |\n|posted content     |t  |    |    |t   |     |t       |t        |t  |\n|proceedings article|t  |    |    |t   |t    |t       |t        |t  |\n|report             |t  |t   |    |t   |t    |t       |t        |t  |\n|reference book     |t  |t   |    |t   |     |t       |t        |t  |\n|reference entry    |t  |    |    |t   |     |t       |t        |t  |\n|book chapter       |t  |    |    |t   |     |t       |t        |t  |\n|book part          |t  |    |    |t   |     |t       |t        |t  |\n|book section       |t  |    |    |t   |     |t       |t        |t  |\n|book track         |t  |    |    |t   |     |t       |t        |t  |\n|component          |t  |    |    |t   |     |t       |t        |t  |\n|book series        |t  |    |t   |t   |     |t       |t        |t  |\n|book set           |t  |    |t   |t   |     |t       |t        |t  |\n|journal            |t  |    |t   |t   |     |t       |t        |t  |\n|proceedings        |t  |    |    |t   |     |t       |t        |t  |\n|proceedings series |t  |    |t   |t   |     |t       |t        |t  |\n|report series      |t  |    |t   |t   |     |t       |t        |t  |\n|series             |t  |    |t   |t   |     |t       |t        |t  |\n|standard           |t  |t   |    |t   |     |t       |t        |t  |\n|standard series    |t  |    |t   |t   |     |t       |t        |t  |\n|journal issue      |t  |    |    |t   |     |t       |t        |t  |\n|journal volume     |t  |    |    |t   |     |t       |t        |t  |\n\n**Dal punto di vista semantico (compliance con il data model), sono necessari altri controlli oltre ai seguenti?**\n* type e id della risorsa\n* id e presenza nei campi dei RA (alcuni ID sono solo per organizzazioni, altri solo per people), che poi in realt√† √® gi√† controllata nel primo livello di validazione\n\n## Prossime mosse e scadenze?\n* Consigli/indicazioni sulla struttura:\n\t* I capitolo: stato dell'arte -\u003e cosa dire? stato dell'arte sui validatori o solo su OpenCitation?\n\t* II capitolo:\n\t* III capitolo:\n* Fonti da cui partire\n* Dovr√≤ finire di scrivere il software mentre sono in fase di scrittura per i primi capitoli\n* scadenze?\n\n\n1. toc esteso per prossimo incontro (titolo sezione con paragrafo di descrizioni)\n2. tesi √® implementativa:\n\t1. introduzione (vedi articolo su framework optimeta https://arxiv.org/abs/2301.01502) e importanza del validatore. qui devi difendere l'utilitit√† e lo scopo del validatore\n\t2. literature review (sui validatori, non su OpenCitations !!!! pyschacl, shex, pydantic, cerberus e le altre cose che abbiamo visto all'inizio vanno tutte bene per questa parte !!! Nel menzionare lo stato dell'arte, giustifica l'esigenza di un nuovo validatore: esigenza legata alla specificit√† dei dati)\n\t3. metodologia (come funziona senza entrare nel merito del codice, deve spiegare il processo ad alto livello); √® abbastanza importante inserire diagramma UML delle classi e come interagiscono tra loro\n\t5. descrizione del codice a basso livello, nel dettaglio\n\t6. capitolo di \"\"evaluation\"\" con la valutazione del costo computazionale: devi creare un dataset pulito e uno con problemi per testare la performance e vedere quanto ci mette il software per andare, sia con i dati \"corretti\" che con i dati contenenti errori. Idealmente tutti i possibili errori devono essere rappresentati. La misura della performance, in questa evaluation, √® data dai tempi che hai computato\n\t7. Conclusioni citando future works e futuri sviluppi del validatore\n\n\n\n* file di configurazione esterno dove la chiave √® il type e il valore √® una lista di ID (un json va bene)\n* per capire quali tipi sono associabili agli ID puoi partire dai dati esistenti (tabelle di Meta -- o crossref? -- che scarichi da Zenodo, c'√® il link sul sito di OC), per poi analizzarli e vedere che cosa viene fuori di inaspettato (rispetto a quello che c'√® scritto nelle singole documentazioni degli identificativi) e poco frequente. Cos√¨ puoi orientarti meglio nel definire l'allineamento. Devi scrivere uno scriptino per creare un dizionario a partire dai csv del dump, che abbia per ogni identificativo tutti i tipi che trova in Meta. In linea generale, √® meglio essere pi√π inclusivi che restrittivi nel definire i tipi ammissibili per ogni identificativo\n* pagina wikipedia rappresenta se stessa (type solo reference entry e other)\n* organizza tutto in classi\n* scrivi i test per gli ID manager","lastmodified":"2023-03-19T23:54:38.512579397Z","tags":null},"/notes/oc_ocdm":{"title":"","content":"","lastmodified":"2023-03-19T23:54:38.512579397Z","tags":null},"/notes/ocdm":{"title":"OpenCitations Data Model","content":"### Sources\n* [OC website](http://opencitations.net/model)\n* [OCDM repository on GitHub](https://github.com/opencitations/metadata/)\n* [OCDM on FIgshare](https://figshare.com/articles/online_resource/Metadata_for_the_OpenCitations_Corpus/3443876/7)\n### Related notes\n* [oc_ocdm](notes/oc_ocdm.md)\n\n### Related readings\n* [@persianiProgrammingInterfaceCreating2022](notes/readings/@persianiProgrammingInterfaceCreating2022.md)\n* \n\n\n\n","lastmodified":"2023-03-19T23:54:38.512579397Z","tags":null},"/notes/readings/heibiCrowdsourcingOpenCitations2019":{"title":"@heibiCrowdsourcingOpenCitations2019","content":"# Notes on *Crowdsourcing open citations with CROCI ‚Äì An analysis of the current status of open citations, and a proposal*\nAuthor(s): **Ivan Heibi, Silvio Peroni, David Shotton**\nYear: **2019**\n\nüîó Go to web version: http://arxiv.org/abs/1902.02534\nüóÉÔ∏è [Open this document in Zotero](zotero://select/items/@heibiCrowdsourcingOpenCitations2019)\n\n\u003e [!abstract]+ Abstract\n\u003e\n\u003e In this paper, we analyse the current availability of open citations data in one particular dataset, namely COCI (the OpenCitations Index of Crossref open DOI-to-DOI citations; http://opencitations.net/index/coci) provided by OpenCitations. The results of these analyses show a persistent gap in the coverage of the currently available open citation data. In order to address this specific issue, we propose a strategy whereby the community (e.g. scholars and publishers) can directly involve themselves in crowdsourcing open citations, by uploading their citation data via the OpenCitations infrastructure into our new index, CROCI, the Crowdsourced Open Citations Index.\n\n## Summary\nIn this paper the authors analyse the state of availability and \"openness\" of the papers included, at Oct. 3rd 2018, in the COCI index. COCI was built from a dump of two datasets from Crossref:\n* a set of **completely open reference lists**\n* and a set of **limited access reference lists**, available only to users of the Crossref Cited-by service and to Metadata Plus members of Crossref, of which OpenCitations is one\n\nThe results of this (comparative) analysis have shown the need for a new index, CROCI (Crowdsourced Open Citations Index), to collect citations directly from institutions and users authenticated users. \n\n------------\n\n\u003e [!QUOTE]\n\u003e \"The availability of **open scholarly citations ‚Äì i.e. citation data that are structured, separate, open, identifiable and available**[^1] ‚Äì is a public good, which is of intrinsic value to the academic world as a whole [...], and is particularly crucial for the scientometrics and infometrics community, since it supports reproducibility [...] and enables fairness in research by removing such citation data from behind commercial paywalls.\"\n\u003e p. 1\n\u003e see [@shottonPublishingOpenCitations2013](notes/readings/@shottonPublishingOpenCitations2013.md)\n\n[^1]: Peroni, S. \u0026 Shotton, D. (2018). Open Citation: Definition. Version 1. Figshare. DOI: 10.6084/m9.figshare.6683855\n\n\nDespite the recent initiatives to free scholarly citations from the restrictions dictated by commercial interests, many citation are still not freely available, and the incomplete coverage of open citation data is one of the major obstacles to open scholarship. \n\nIn this paper the authors analyse [COCI](https://opencitations.net/index/coci), the OpenCitations Index of Crossref open DOI-to-DOI citations. COCI is provided by OpenCitations[^2],  \u003cu\u003e\"a scholarly infrastructure organization dedicated to open scholarship and the publication of open bibliographic and citation data by the use of Semantic Web (Linked Data) technologies\u003c/u\u003e\" (p. 1). \n\n[^2]: Peroni, S., Dutton, A., Gray, T. \u0026 Shotton, D. (2015). Setting our bibliographic references free: towards open citation data. Journal of Documentation, 71: 253-277. DOI: 10.1108/JD-12-20130166\n\nCOCI was launched in July 2018 and it is the first of OpenCitations' indexes to have citations represented as first-class data entries with accompanying properties. \n\n## Findings\nAnalysing COCI, the authors are addressing the following research questions (RQ):\n#### RQ1: What is the ratio between open vs closed citations inside COCI (for each of the five scholarly entities in COCI, i.e. journals, books, proceedings, datasets and others)?\n\n![fig1](images/heibiCrowdsourcingOpenCitations2019-fig1.jpg)\n\n#### RQ2: What are the top 20 *publishers* that has received the highest number of *open* citations for their publications, according to the data in COCI?\n\n![fig2](images/heibiCrowdsourcingOpenCitations2019-fig2.jpg)\n\n#### RQ3: How much do these publishers (that, in a way, are benefiting from the availability of open citations) contribute to the open citation movement be making their references open in Crossref?\n\n| ![fig3](images/heibiCrowdsourcingOpenCitations2019-fig3.jpg) |\n| ---------------|\n| \"Figure 3. The contributions to open citations made by the twenty publishers listed in [Figure 2](images/heibiCrowdsourcingOpenCitations2019-fig2.jpg), as of 24 January 2018, according to the data available through the Crossref API. The counts listed in the first three results columns of this table refers to the number of publications for which each publisher has submitted metadata to Crossref that include the publication‚Äôs reference list, the categories closed, limited and open referring to publications for which the reference lists are not visible to anyone outside the Crossref Cited-by membership, are visible only to them and to Crossref Metadata Plus members, or are visible to all, respectively. [...] The fourth results column in the table shows the total number of publications for which the publisher has submitted metadata to Crossref, whether or not those metadata include the reference lists of those publications, and the fifth results column shows the total number of publications for which the publisher has submitted the reference list with the other metadata. The percentage values given in parentheses show the percentage of publications in each category whose metadata submitted to Crossref includes the reference lists, these percentages being obtained by dividing the values in each column by the total number of publications for which that publisher has submitted metadata to Crossref shown in the fourth results column.\" (p. 4) |\n\n## Observations\n\nThe journal category is the one receiving the highest number of open citations overall; however, the number of *closed* citations to journal articles represents the 43% of the total number of closed citations within Crossref. \n\nThe largest publisher of journal articles, Elsevier, owns the works referenced by 1/3 of the closed citations in Crossref: \"Elsevier‚Äôs present refusal to open its article references is contributing significantly to the invisibility of Elsevier‚Äôs own publications within the corpus of open citation data that is being increasingly used by the scholarly community for discovery, citation network visualization and bibliometric analysis.\" (pag. 5).\n\n### CROCI, the Crowdsourced Open Citations Index\n\nDespite the remarkable results of the I4OC, many citations are still not available to the general public. \n\nIn order to solve this problem, without ending up fighting against publishers like Elsevier, the authors propose a new index for OpenCitations: **CROCI: the Crowdsourced Open Citations Index**. \nAny individual identified by an [ORCiD](https://en.wikipedia.org/wiki/ORCID) identifier can submit the citation data they are legally entitled to submit; the citation data is published under [CC0 license](https://creativecommons.org/share-your-work/public-domain/cc0/) to ensure its free reuse. \n\n\u003cp style=\"background-color: #D0FDEF;\"\u003e\n\"Since citations are statements of fact about relationships between publications (resembling statements of fact about marriages between individual persons), \u003cb\u003ethey are not subject to copyright\u003c/b\u003e, \u003cb\u003ealthough their specific textual arrangements within the reference lists of particular publications may be\u003c/b\u003e. \u003cu\u003eThus, the citations from which the reference list of an author‚Äôs publication has been composed may legally be submitted to CROCI, although the formatted reference list cannot be\u003c/u\u003e. Similarly, citations extracted from within an individual‚Äôs electronic reference management system and presented in the requested format may be legally submitted to CROCI, irrespective of the original sources of these citations.\"(p.6)\n\u003c/p\u003e\n\nResearchers and anyonw who wants to contribute to CROCI by submitting data must provide a CSV file with 4 columns (fields): `citing_id`, `citing_publication_date`, `cited_id` and `cited_publication_date`.[^3]\n\n\n[^3]: For more information on the format, see page 7 of the paper\n\n\nIf submissions include citation already present in CROCI, the duplicates will automatically be ignored. \n\n\n","lastmodified":"2023-03-19T23:54:38.516579322Z","tags":null},"/notes/readings/heibiSoftwareReviewCOCI2019":{"title":"@heibiSoftwareReviewCOCI2019","content":"# Notes on *Software review: COCI, the OpenCitations Index of Crossref open DOI-to-DOI citations*\nAuthor(s): **Ivan Heibi, Silvio Peroni, David Shotton**\nYear: **2019**\n\nüîó Go to web version: https://doi.org/10.1007/s11192-019-03217-6\nüóÉÔ∏è [Open this document in Zotero](zotero://select/items/@heibiSoftwareReviewCOCI2019)\n\n\u003e [!abstract]+ Abstract\n\u003e\n\u003e In this paper, we present COCI, the OpenCitations Index of Crossref open DOI-to-DOI citations (http://opencitations.net/index/coci ). COCI is the first open citation index created by OpenCitations, in which we have applied the concept of citations as first-class data entities, and it contains more than 445 million DOI-to-DOI citation links derived from the data available in Crossref. These citations are described using the resource description framework by means of the newly extended version of the OpenCitations Data Model (OCDM). We introduce the workflow we have developed for creating these data, and also show the additional services that facilitate the access to and querying of these data via different access points: a SPARQL endpoint, a REST API, bulk downloads, Web interfaces, and direct access to the citations via HTTP content negotiation. Finally, we present statistics regarding the use of COCI citation data, and we introduce several projects that have already started to use COCI data for different purposes.\n\n\n\n## Summary\nIn this paper the authors introduce COCI, the representation of citations as [first-class data entities](https://en.wikipedia.org/wiki/First_class_(computing)) and the ingestion workflow implemented to create the index; they also provide details on the data contained in COCI and describe services and resources made available by OpenCitations to access the index; finally, they present some statistics about the use of COCI and list some studies and tools that have made use of COCI up to 2019. \n\n### **COCI**, the OpenCitations Index of Crossref open DOI-to-DOI citations\nLaunched in **2018**, COCI is the first index of OpenCitations to \u003cu\u003erepresent citations as **first-class data entities**\u003c/u\u003e with accompanying properties, i.e. individuals of the class `cito:Citation`[^1] , instead of being defined simply as relationships between two entities (the one representing the papers) through the property `cito:cites`.\n\n[^1]: As defined in [CiTo](http://www.sparontologies.net/ontologies/cito), the Citation Ontology, described in Peroni, S., \u0026 Shotton, D. (2012). FaBiO and CiTO: Ontologies for describing bibliographic resources and citations. Web Semantics, 17, 33‚Äì34. https://doi.org/10.1016/j.websem.2012.08.001.\n\nAt mid-2019, COCI contains +445 millions DOI-to-DOI links represented as entities; all the data is under a CC0 license (public domain) and can be accessed and queried in the following ways:\n* via SPARQL endpoint\n* via dedicated HTTP REST API\n* via searching/browsing Web interfaces\n* by bulk download (CSV and N-Triples formats)\n* by direct access via HTTP content negotiation\n\nWhile citations are normally defined as links between published entities, \u003cu\u003eregarding, instead, each citation as a data entity in its own right lets one  provide a citation with **descriptive properties**\u003c/u\u003e; in the case of COCI the properties that are associated with a citation entity are the following:\n1. **citing entity**\n2. **cited entity**\n3. **citation creation date** (it has the same numerical value of the citing entity's publication date)\n4. **citation timespan** (the temporal characteristic of a citation, i.e. the interval between the publication date of the *citing* entity and the the publication date of the *cited* entity)\n\nTreating citations as first-class data entities brings some advantages:\n* all the information about each citation is available in one place\n* citations are easier to describe, distinguish, count and process; moreover it's possible to keep separate each occurence of a citation, for example we could count the number of times a published entity is cited inside another published entity, or see in which section(s), etc.\n* citations are easier to analyse with bibliometric methods (e.g. to determine how citation time spans vary across different disciplines).\n\n### Data Model\nThe [OCDM (OpenCitations Data Model)](http://opencitations.net/model) (see p. 1218, fig. 2) has been extended according to the new organization: each citation is a member of the `cito:Citation` class.\n\nSo as to identify each citation precisely in the open dataset, a new identifier has been develop for citations: the \u003cu\u003eOpen Citation Identifier (**OCI**)\u003c/u\u003e. An OCI has the following structure: `oci:\u003cciting_entity_identifier\u003e-\u003ccited_entity_identifier\u003e`.\nFor example, `oci:0301-03018` is a valid OCI for a citation defined within the OpenCitations Corpus, while `oci:0200101080636010705066308070202630663050902001010806360107050663080702026305630301` is a valid OCI for a citation included in Crossref. \u003cu\u003eOCIs are *not* opaque identifiers, instead they carry information about the citation and the published entities linked by the citation\u003c/u\u003e[^2]. \n\n[^2]: There is also an [OCI Resolution Service](http://opencitations.net/oci) based on a Python app that returns citation data from a valid OCI in input. \n\n### Ingestion Workflow\n4 Phases (see pp. 1219-1221):\n1. **Global data generation**: the data in Crossref is parsed and processed to extract all the publications having a DOI and their available list of references. 3 datasets are generated in this way: Dates, ISSN and ORCiD.\n2. **CSV generation**: a CSV file is generated where each row represents a citation. \n3. **converting into RDF**: the CSV is converted into RDF according to the N-Triples format, following the OWL data model (see fig. 2).\n4. **updating the triplestore**: the triples generated in phase 3 are the ones that are added to the OpenCitations indexes\n\n\n### Statistics, COCI-related services and impact\n##### Statistics \nSee p. 1221-1222 and [@heibiCrowdsourcingOpenCitations2019](notes/readings/@heibiCrowdsourcingOpenCitations2019.md) for some stats on COCI in mid 2019.\n\n##### Services for accessing and querying COCI\nSee the beginning of [this paragraph](notes/readings/@heibiSoftwareReviewCOCI2019.md#COCI%20the%20OpenCitations%20Index%20of%20Crossref%20open%20DOI-to-DOI%20citations) and pp. 1222-1224 for a list of services and tools made available for accessing and querying the data.\n\n##### Impact and use\nSee p. 1225 for a list of tools and services that have made use of COCI. ","lastmodified":"2023-03-19T23:54:38.516579322Z","tags":null},"/notes/readings/massariHowStructureCitations2022":{"title":"massariHowStructureCitations2022","content":"# Notes on *How to structure citations data and bibliographic metadata in the OpenCitations accepted format*\nAuthor(s): **Arcangelo Massari, Ivan Heibi**\nYear: **2022**\nDOI: **10.48550/arXiv.2206.03971**\n\nüîó [Go to web version](http://arxiv.org/abs/2206.03971)\nüóÉÔ∏è [Open this document in Zotero](zotero://select/items/@massariHowStructureCitations2022)\n\n\u003e [!abstract]+ Abstract\n\u003e\n\u003e The OpenCitations organization is working on ingesting citation data and bibliographic metadata directly provided by the community (e.g., scholars and publishers). The aim is to improve the general coverage of open citations, which is still far from being complete, and use the provided metadata to enrich the characterization of the citing and cited entities. This paper illustrates how the citation data and bibliographic metadata should be structured to comply with the OpenCitations accepted format.\n\n","lastmodified":"2023-03-19T23:54:38.516579322Z","tags":null},"/notes/readings/massariarcangeloHowProduceWellformed2022a":{"title":"massariarcangeloHowProduceWellformed2022a","content":"# Notes on *How to produce well-formed CSV files for OpenCitations*\nAuthor(s): **Arcangelo Massari**\nYear: **2022**\nDOI: **10.5281/ZENODO.6597140**\n\nüîó [Go to web version](https://zenodo.org/record/6597140)\nüóÉÔ∏è [Open this document in Zotero](zotero://select/items/@massariarcangeloHowProduceWellformed2022a)\n\n\u003e [!abstract]+ Abstract\n\u003e\n\u003e OpenCitations processes two types of CSV files, one for metadata and one for citations. This document describes how to structure them.\n\nThis document is the most complete reference for the syntax of the CSV files for sending metadata and citation data to OpenCitations and allow this data to be processed. \n\n## META-CSV: syntax\nThe csv file for the metadata is structured as a table with 11 columns, where each row corresponds to a specific document. If an ID is specified, the other fields are not mandatory; otherwise, certain fields become mandatory, according to the [type](notes/readings/@massariarcangeloHowProduceWellformed2022a.md#type) of resource. \n\n\u003cp align=center style=\"font-weight:bold;color:#0099cc\"\u003e\nFor a complete set of examples of META-CSV data entries (sample table) see \u003ca href=\"https://github.com/opencitations/oc_meta/blob/master/example_metadata.csv\"\u003e\u003cu\u003eoc repo on github\u003c/u\u003e\u003c/a\u003e.\n\u003c/p\u003e\n\n### id\nThere may be one or more IDs, and they are separated by a single space (Unicode Character ‚ÄúSPACE‚Äù, U+0020)\n\nSyntax: \n\n\u003cp align=center style=\"font-weight:bold;\"\u003eID abbreviation + ‚Äú:‚Äù + ID value\u003c/p\u003e\n\n\u003e [!example]- Examples\n\u003e \n\u003e  \"doi:10.3233/ds-170012\" indicates a DOI identifier with value ‚Äú10.3233/ds-170012‚Äù\n\n### title\nText string corresponding to the document's title. \n### author\nAuthor's/authors' full name and, optionally, identifier. An author's ID is indicated with the same syntax as for a [document's id](notes/readings/@massariarcangeloHowProduceWellformed2022a.md#id), but inside square brackets. If there are no IDs, there will be no square brackets at all. **The author's *first name* is optional, but even without the first name, the comma after the last name is still necessary!** **\u003cu\u003eThe separator between the data associated to different authors is a semi-colon, followed by a single space\u003c/u\u003e: `; `.**\n\nSyntax: \n\n\u003cp align=center style=\"font-weight:bold;\"\u003eFamily Name + ‚Äú,‚Äù + ‚Äú ‚Äù + Given Name + ‚Äú ‚Äù + ‚Äú[‚Äù + IDs + ‚Äú]‚Äù\u003c/p\u003e\n\n\u003e [!example]- Examples\n\u003e \n\u003e  * Peroni, Silvio [orcid:0000-0003-0530-4305]\n\u003e  * Peroni, [orcid:0000-0003-0530-4305]\n\u003e  * Shotton, David [0000-0001-5506-523X]; Peroni, [orcid:0000-0003-0530-4305]\n\n\n### pub_date\nThe publication date of the document, expressed according to ISO 86014, the ISO standard for ‚ÄúRepresentation of dates and times‚Äù: \n\n\u003cp align=center style=\"font-weight:bold;\"\u003eYYYY-MM-DD\u003c/p\u003e\n\nYYYY is a value between and including 0000 and 9999, MM between and including 01 and 12, DD between and including 01 and 31.  Year, month and day are separated with a hyphen ‚Äú-‚Äù(Unicode Character ‚ÄúHYPHEN-MINUS‚Äù, U+002D), as required by the standard.\nThe publication ***year*** is **mandatory**; month and day are optional, but **if the day is specified, the month must be specified too**. \n\n\u003e [!example]- Examples\n\u003e \n\u003e  * 1996-05-16\n\u003e  * 2022-08\n\u003e  * 2023\n\n\u003e [!warning]+ Attention!\n\u003e \n\u003e Dates like \"1996-4-14\" or \"1996-4\" are NOT VALID, despite being listed as valid examples on the paper. \n\n### venue\nThe bibliographical resource to which the document belongs. For example, if a row describes the metadata of a journal article, the venue will be the journal to which that article belongs.\n\n\u003cp align=center style=\"font-weight:bold;\"\u003eVenue Title + ‚Äú ‚Äù + ‚Äú[‚Äù + IDs + ‚Äú]‚Äù\u003c/p\u003e\n\n**If there are no identifiers, the square brackets are not necessary.**\n\n\u003e [!example]- Examples\n\u003e \n\u003e  * Archives on Internal Medicine [issn:0003-9626]\n\u003e  * Disaster Medicine and Public Health Preparadness [issn:1935-7893 issn:1938-744X]\n\n\n### volume\nThe `volume` field stores the the identifier (\u003cu\u003ee.g. a number\u003c/u\u003e) of the volume (part of a sequence \"inside\" a journal) containing the described document. \u003cu\u003eOne or more volumes constitute a journal\u003c/u\u003e. \n**Required only if the document is contained in a journal volume**.\n\n### issue\nThe `issue` field stores the the identifier (\u003cu\u003ee.g. a number\u003c/u\u003e) of the issue (part of a sequence \"inside\" a volume) containing the described document. \u003cu\u003eOne or more issues constitute a volume (inside a journal)\u003c/u\u003e. \n**Required only if the document is contained in a journal issue**.\n\n### page\nThe page *range* of the resource described in the row. The value is composed of 2 numbers, first and last page respectively, divided by a hyphen ‚Äú-‚Äù(Unicode Character ‚ÄúHYPHEN-MINUS‚Äù, U+002D).\n\n\u003e [!example]- Examples\n\u003e \n\u003e  * 22-75\n\n### type\nThe type of resource described in the row. Here is a complete list of the currently supported bibliographic resource types: book, book chapter, book part, book section, book series, book set, book track, component, dataset (or data file), dissertation, edited book, journal, journal article, journal issue, journal volume, monograph, other, peer review, posted content (or web content), proceedings, proceedings article, proceedings series, reference book, reference entry, report, report series, standard, and standard series.\n\n### publisher\nThe entity responsible for making the resource available. \n\n\u003cp align=center style=\"font-weight:bold;\"\u003ePublisher name + ‚Äú ‚Äù + ‚Äú[‚Äù + IDs + ‚Äú]‚Äù\u003c/p\u003e\n\nSquare brackets should not be present (i.e. are not necessary???) if there is no ID. \n\n### editor\nDescribed in the same way as the `author` field.\n\n\n#### Mandatory fields\nIf the ID of the document is specified, no other field is mandatory. Otherwise, i.e. if the ID is not specified, certain fields become compulsory, depending on the [type](notes/readings/@massariarcangeloHowProduceWellformed2022a.md#type) of the resource, as described by the table below. \n\n| ![massariarcangeloHowProduceWellformed2022a](images/massariarcangeloHowProduceWellformed2022a-fig2.jpg) |\n| --------------------- |\n| Fig. 2. Summary of mandatory fields in a metadata CSV if no identifier was specified in a specific row. ‚ÄúM‚Äù is an abbreviation for mandatory. Conversely, ‚ÄúO‚Äù stands for OR, is always present in pairs, and means that at least one element of the pair is compulsory. |\n\n## CITS-CSV\n\nThe csv for citations is structured as a 4-column table, where each row corresponds to a citation (remember citations in OC are represented ad first class data entities).\nThe citing_id and cited_id fields are mandatory, while the citing_publication_date and cited_publication_date are optional. \n\n\u003cp align=center style=\"font-weight:bold;color:#0099cc\"\u003e\nFor a complete set of examples of CITS-CSV data entries (sample table) see \u003ca href=\"https://github.com/opencitations/oc_meta/blob/master/example_citations.csv\"\u003e\u003cu\u003eoc repo on github\u003c/u\u003e\u003c/a\u003e.\n\u003c/p\u003e\n\n### citing_id\n**Mandatory**. The ID of the citing entity. Expressed in the same way as the ID in META-CSV.\n\n\u003cp align=center style=\"font-weight:bold;\"\u003eID abbreviation + ‚Äú:‚Äù + ID value\u003c/p\u003e\n\n### citing_publication_date\n**Optional**. Publication date of the citing entity, expressed in the same way as the publication date in META-CSV (ISO 86014 format).\n\n\u003cp align=center style=\"font-weight:bold;\"\u003eYYYY-MM-DD\u003c/p\u003e\n\nWhen specifying a value in this field, it is mandatory to specify at least the publication year. On the other hand, month and day are not required. However, if the day is specified, the month must be specified.\n\n### cited__id\n**Mandatory**. Publication date of the cited entity. Follows the same rules as the citing_id field.\n### cited_publication_date\n**Optional**. Follows the same rule as the citing_publication_date field. \n\n","lastmodified":"2023-03-19T23:54:38.516579322Z","tags":null},"/notes/readings/peroniOpenCitationsInfrastructureOrganization2020":{"title":"@peroniOpenCitationsInfrastructureOrganization2020","content":"# Notes on *OpenCitations, an infrastructure organization for open scholarship*\nAuthor(s): **Silvio Peroni, David Shotton**\nYear: **2020**\n\nüîó Go to web version: https://doi.org/10.1162/qss_a_00023\nüóÉÔ∏è [Open this document in Zotero](zotero://select/items/@peroniOpenCitationsInfrastructureOrganization2020)\n\n\u003e [!abstract]+ Abstract\n\u003e\n\u003e OpenCitations is an infrastructure organization for open scholarship dedicated to the publication of open citation data as Linked Open Data using Semantic Web technologies, thereby providing a disruptive alternative to traditional proprietary citation indexes. Open citation data are valuable for bibliometric analysis, increasing the reproducibility of large-scale analyses by enabling publication of the source data. Following brief introductions to the development and benefits of open scholarship and to Semantic Web technologies, this paper describes OpenCitations and its data sets, tools, services, and activities. These include the OpenCitations Data Model; the SPAR (Semantic Publishing and Referencing) Ontologies; OpenCitations‚Äô open software of generic applicability for searching, browsing, and providing REST APIs over resource description framework (RDF) triplestores; Open Citation Identifiers (OCIs) and the OpenCitations OCI Resolution Service; the OpenCitations Corpus (OCC), a database of open downloadable bibliographic and citation data made available in RDF under a Creative Commons public domain dedication; and the OpenCitations Indexes of open citation data, of which the first and largest is COCI, the OpenCitations Index of Crossref Open DOI-to-DOI Citations, which currently contains over 624 million bibliographic citations and is receiving considerable usage by the scholarly community.\n\n\n\u003e [!IMPORTANT]\n\u003e **This paper is basically the most up-to-date and complete resource about OpenCitations**, its relevance and motivation, its services and Indexes, its technologies (OCI, sw and RDF,...) its forthcoming developments (e.g. OpenCitations Meta), its relationships with stakeholders, institutions, consortia and initiatives for Open Science, etc. \n\u003e In a way, it summarizes and updates all content in [@shottonPublishingOpenCitations2013](notes/readings/@shottonPublishingOpenCitations2013.md), [@heibiSoftwareReviewCOCI2019](notes/readings/@heibiSoftwareReviewCOCI2019.md) and [@heibiCrowdsourcingOpenCitations2019](notes/readings/@heibiCrowdsourcingOpenCitations2019.md).","lastmodified":"2023-03-19T23:54:38.516579322Z","tags":null},"/notes/readings/persianiProgrammingInterfaceCreating2022":{"title":"persianiProgrammingInterfaceCreating2022","content":"# Notes on *A Programming Interface for¬†Creating Data According to¬†the¬†SPAR Ontologies and¬†the¬†OpenCitations Data Model*\nAuthor(s): **Simone Persiani, Marilena Daquino, Silvio Peroni**\nYear: **2022**\nDOI: **10.1007/978-3-031-06981-9_18**\n\nüîó [Go to web version]()\nüóÉÔ∏è [Open this document in Zotero](zotero://select/items/@persianiProgrammingInterfaceCreating2022)\n\n\u003e [!abstract]+ Abstract\n\u003e\n\u003e The OpenCitations Data Model (OCDM) is a data model for bibliographic metadata and citations based on the [SPAR Ontologies](http://www.sparontologies.net/) and developed by OpenCitations to expose all the data of its collections as sets of RDF statements compliant with an ontology named OpenCitations Ontology. In this paper, we introduce oc_ocdm, i.e. a Python library developed for creating OCDM-compliant RDF data even if the programmer has no expertise in Semantic Web technologies. After an introduction of the library and its main characteristics, we show a number of projects within the OpenCitations infrastructure that adopt it as their building block unit.\n\n\n\n\u003e \"Data models are crucial artifacts that datasets suppliers should make available to document data and to enable users to understand and, thus, use appropriately suppliers‚Äô data. \n\u003e \n\u003e Sometimes, data models may be created (re)using terms defined in the same ontologies with different nuances, thereby generating diversity in data representation. Of course, a data model can employ clearly defined ontological terms to ensure data consistency and facilitate integration tasks. However, even if ambiguities are entirely avoided from a terminological perspective, creating datasets compliant with a particular data model can still be a challenge for people who are not experts in the related technologies, such as OWL and RDF. Further challenges can be due to data dynamics (e.g. extensions and modifications) which must be performed accordingly to the data model either to correct possible mistakes in an entity or to introduce new data. \n\u003e \n\u003e Additional complexities in data handling are introduced when the data model asks for tracking entities‚Äô provenance and changes every time an entity is modified. To enable users (e.g. domain experts) to programmatically access the data organised according to a particular data model and to permit their modifications, **applications (visual interfaces, web editors, etc.) must be developed to facilitate human-data interaction**. **\u003cu\u003eHowever, an additional interface layer should be provided to permit programmers to develop such applications\u003c/u\u003e**, since such programmers are experts in coding but not necessarily skilled in the technologies used by an underlying data model. \u003cu\u003eSuch an interface layer would enable creating and manipulating data transparently from the actual technologies used for their representation, such as RDF and, particularly, OWL ontologies\u003c/u\u003e. The situation introduced above describes what happened in OpenCitations in the past few years. [...]. A few years ago, OpenCitations released the OpenCitations Data Model (OCDM), a data model based on SPAR Ontologies, PROVO, and other existing models, for describing all the entities in its collections, keeping track of their provenance and modifications in time. In addition of being reused by OpenCitations, the OCDM has also been recently adopted by other external projects dealing with bibliographic metadata and citations. The more the OCDM is adopted, the more it is necessary to have a library to simplify the creation of applications dealing with OCDM-compliant data.\n\u003e \n\u003e In this paper, we introduce a Python library, i.e. **oc_ocdm**, for enabling data owners and publishers to develop applications using OCDM-based data and provenance information. This library has already been used by OpenCitations in several components and projects, and it is the building block for all the future applications dealing with RDF data in OpenCitations‚Äô collections.\"\n\u003e (Introduction, pp. 1-2).\n\n\n![Data model 2022](images/persianiProgrammingInterfaceCreating2022-fig2-datamodel.jpg)\n\n\n\u003e #### Shape Validation\n\u003e When using the methods `import_entities_from_graph` and `import_entity_from_triplestore`, the user can specify to perform shape validation on the imported graph, in order to filter out all the entities that do not respect the shape constraints described in the OCDM (constraints on a given property regarding its range datatype/class, the minimum/maximum amount of attributes associated to an entity, etc.). This operation is currently handled via the `PyShEx` library.\n\u003e \n\u003e The shapes described in the OCDM were formalised into a proper ShExC file, that is the required input of `PyShEx`. Such a resource is included within the *oc_ocdm* package. `ShEx` was a design choice that we inherited from the initial phase of the development, which started a few years ago. We chose the ShExC format because of its simplicity and compactness, which makes it easy to be written and read also by non-expert users.\n\u003e \n\u003e(p. 8)\n\n\n\n\u003e[!important]+ Important!\n\u003e\n\u003eMy task here is to create a new validation procedure using SHACL and pySHACL instead of ShEx and PyShEx, due to the fact that the development of the latter has been gradually slowed down since 2021 and currently has efficency problems. The validation process in SHACL should later be integrated in the broader *oc_ocdm* library.\n\n\n\n\n\u003e In this paper, we have introduced oc ocdm, a Python library for enabling the development of applications using OCDM-based data and provenance information. After showing the main requirements for the development, we have introduced its organisation in terms of Python modules and classes and we have presented its current and future uses in the context of several components and projects related to OpenCitations, being the main building block for all the applications dealing with creating and modifying RDF data in OpenCitations‚Äô collections.\n\u003e \n\u003e (Conclusions, p. 15)","lastmodified":"2023-03-19T23:54:38.516579322Z","tags":null},"/notes/readings/shottonPublishingOpenCitations2013":{"title":"@shottonPublishingOpenCitations2013","content":"# Notes on *Publishing: Open citations*\nAuthor(s): **David Shotton**\nYear: **2013**\n\nüîó Go to web version: https://www.nature.com/articles/502295a\nüóÉÔ∏è [Open this document in Zotero](zotero://select/items/@shottonPublishingOpenCitations2013)\n\n\u003e [!abstract]+ Abstract\n\u003e\n\u003e Make bibliographic citation data freely available and substantial benefits will flow, says David Shotton, director of the Open Citations Corpus.\n\n## Summary\nIn this article from 2013, David Shotton presents the Open Citations Corpus (OCC).\n\n### Citation data: its relevance and the collections\n\nGiven that reference lists and citation data are core elements of scholarly communication, as they allow the attribution of credit and the integration of independent research endeavours, these data must be readily and freely available for use by all scholars (p. 296). Although alternative metrics for impact and esteem are being developed for the significance of a research output, direct citation is still the fundamental indicator, making possible to analyse changes in the network over time, revealing patterns of communication between scholars, the development and demise of academic disciplines, etc. (p. 296)\n\n##### Private citation collections accessible via subscription\n\nThe most authoritative sources of scholarly citation data are two commercial rivals; they are often seen as complementary, as, despite their wide coverage, neither of them is complete They are:\n1.  the **Thomson Reuters Web of Science**, which grew from the Science Citation Index created by US scientist Eugene Garfield in 1964, and which was originally published by the Institute for Scientific Information (ISI)\n2. **Elsevier's Scopus**, born in 2004\n\nAccess to these resources costs to universities and institutions tens of thousands of pounds a year (but pricing is industrial secret and  confidential agreements makes it impossible to have certain data). Such costs represent a major obstacle for less wealthy institutions, who simply can't afford to access these data. \n\n##### Private citation collections accessible without subscription\nOther significant sources of citation information, also run by commercial companies but accessible without subscriptions, are:\n1. **Google Scholar**, released in 2004, with the widest coverage\n2. **Microsoft Academic Search**, released in 2009.\n\n\u003e \"All these sources have licence restrictions that prevent the re-publication of their citation data. For this reason, bibliometrics papers are rarely permitted to publish the data on which their conclusions are based ‚Äî hampering reuse, validation of findings and other advantages of open data. Worse, the available citation data are not accurate.\"\n\u003e p. 296\n\n### The Open Citations Corpus (OCC)\nGiven the lack of availability of citation data, the OCC was created. Shotton et al. started building it in 2010, and the first release is in mid-2011. \n\n\u003e \"The OCC is an **open** repository of scholarly citation data made available under a Creative Commons **public domain** dedication [...].  It aims to provide \u003cu\u003eaccurate citation data that others may freely build upon, enhance and reuse for any purpose, without restriction under copyright or database law\"\u003c/u\u003e.\n\u003e p. 297\n\nUp to the time of Shotton's article, the OCC provided \"open access to reference lists from the 204,637¬†articles that then comprised the Open Access Subset of PubMed Central (OA‚ÄìPMC), containing 6,325,178 individual references to 3,373,961 unique papers.\" (p. 297)\n\nThe data are encoded as Linked Open Data using the [**SPAR** (Semantic Publishing and Referencing) **Ontologies**](http://www.sparontologies.net/) and Semantic Web standards. \n\nIdeally, references will come directly from publishers at the time of article publication (and most publishers are well-inclined to the idea of putting reference lists paywall-free).\n\n\n\u003e \u003cu\u003e\"References will be harvested centrally from [**CrossRef**](https://www.crossref.org/)\u003c/u\u003e, the organization that provides digital object identifiers (DOI) for journal articles, to which these publishers already submit article reference lists as participants in its CitedBy Linking service. Publishers will just need to indicate their consent in the article metadata for the article‚Äôs references to be made open.\"\n\u003e p. 297\n\n\n \n\u003e \"The long-term aim of the OCC is to **host citation information for most of the world‚Äôs scholarly literature**, in the arts and humanities as well as the sciences.\" \n\u003e p. 297\n\n\nIn the initial idea exposed in this article, the OCC would have the potential of:\n* revealing shared authorship and institutional membership, common funding and semantic relationships between articles\n* providing analytical services such as search and browse tools, recommendation services, timeline visualizations, etc.\n* providing a reference correction service, useful also for publishers","lastmodified":"2023-03-19T23:54:38.516579322Z","tags":null},"/notes/sessions/session-001":{"title":"session 001","content":"\u003cspan \n\t\tclass=\"ob-timelines\"\n\t\tdata-date=\"2022-08-11-00\"\u003e\n\u003c/span\u003e\n\nüë• [**Reference meeting: 001**](notes/meetings/meeting%20001.md)\n\n\u003e [!info]+ My goals for this session\n\u003e \n\u003e * Start reading relevant bibliography and taking notes\n\u003e * Getting more familiar with what concerns the note-taking and notes organization processes, as well as the publication of this diary\n\n## Readings \nThe following are the readings I am starting off from, in order to get an overview of [OpenCitations](https://opencitations.net/), bibliometrics and other topics related to [Open Science](https://en.wikipedia.org/wiki/Open_science).\n\n**Each reading has its own dedicated page, linked below**, containing simple bibliographic information and notes on the content of the document. The page is referenced via `citekey`, a unique, ready-to-use identifier relative to my bibliographic collection in Zotero, which I will use for the writing phase. \n\nYou can visit [this section](https://eliarizzetto.github.io/quartz/tags/reading) of the website to see all the readings for which a page has been created so far.\n\n#### [@shottonPublishingOpenCitations2013](notes/readings/@shottonPublishingOpenCitations2013.md)\n\nIn this article Shotton presents the OCC and its expected development, after a brief overview on other providers of reference lists and the scientific relevance of citation data.\n\n#### [@heibiCrowdsourcingOpenCitations2019](notes/readings/@heibiCrowdsourcingOpenCitations2019.md)\n\nAfter an analysis of the data in COCI, guided by 3 research questions revolving around the openness of citations and the publisher's role, the authors propose a new, crowdsourced index, for OpenCitations: CROCI. \n\n#### [@heibiSoftwareReviewCOCI2019](notes/readings/@heibiSoftwareReviewCOCI2019.md)\n\nThe authors present COCI and its features (citations as first-class data entities, OCI identifier), the extended OpenCitations Data Model, the ingestion workflow for COCI and some statistics, use cases and tools related to this Index. \n\n#### [@peroniOpenCitationsInfrastructureOrganization2020](notes/readings/@peroniOpenCitationsInfrastructureOrganization2020.md)\n\nThe most complete and up-to-date resource on the OpenCitations infrastructure, summarizing the other readings on the topic. This paper describes OpenCitations and its data sets, tools, services, and activities. These include the Data Model; the SPAR Ontologies; OpenCitations‚Äô open software of generic applicability for searching, browsing, and providing REST APIs over RDF triplestores; OCIs and the OCI Resolution Service; the OpenCitations Corpus (OCC), a database of open downloadable bibliographic and citation data (in RDF and under CC0); and the OpenCitations Indexes of open citation data, of which the first and largest is COCI.\n\n#### [@massariHowStructureCitations2022](notes/readings/@massariHowStructureCitations2022.md)\n\nThis paper describes the syntax of the CSV files for crowdsourced metadata (META-CSV) and citation data (CITS-CSV), providing examples (see appendix). A more exhaustive documentation of the aforementioned syntax is provided at [@massariarcangeloHowProduceWellformed2022a](notes/readings/@massariarcangeloHowProduceWellformed2022a.md).\n\n#### [@massariarcangeloHowProduceWellformed2022a](notes/readings/@massariarcangeloHowProduceWellformed2022a.md)\n\nThe main resource for the documentation of the **syntax of** crowdsourced **CSV files** in OpenCitations (META-CSV) and (CITS-CSV).\n\n#### [@persianiProgrammingInterfaceCreating2022](notes/readings/@persianiProgrammingInterfaceCreating2022.md)\n\n\u003cp align=center\u003e!!Difficult, read again later!!\u003c/p\u003e\n\nThis paper introduces oc_ocdm, a Python library developed for creating OCDM-compliant RDF data.\n","lastmodified":"2023-03-19T23:54:38.516579322Z","tags":null},"/notes/sessions/session-002":{"title":"Session 002","content":"\u003cspan \n\t\tclass='ob-timelines'\n\t\tdata-date=\"2022-09-06-00\"\u003e\n\u003c/span\u003e\n\nüë• [**Reference meeting: 002**](notes/meetings/meeting%20002.md)\n\nüîô [**Previous work session: 001**](notes/sessions/session%20001.md)\n\n\u003e [!info]+ My goals for this session\n\u003e \n\u003e * prima lettura del dataset per capire cosa contiene\n\u003e * primi esperimenti con il codice\n\n\n## Dataset \nHo iniziato a farmi un'idea dei dati che il software dovr√† validare a partire dai dati di Crossref trasformati in CSV di input per OC Meta([dataset online su cartella onedrive](https://liveunibo-my.sharepoint.com/personal/arcangelo_massari_unibo_it/_layouts/15/onedrive.aspx?id=%2Fpersonal%2Farcangelo%5Fmassari%5Funibo%5Fit%2FDocuments%2FDocuments%2Fmeta%5Finput%2Ezip\u0026parent=%2Fpersonal%2Farcangelo%5Fmassari%5Funibo%5Fit%2FDocuments%2FDocuments\u0026ga=1)).\n\nSono partito dall'esaminare gli identificativi degli autori; finora emerge che sono presenti *almeno* tre tipi di identificativi: `doi`, `isbn` e `issn`, dal pi√π frequente al meno frequente.\n\n\n\n## Codice\n\nEsiste gi√† tra i lavori di OC (https://github.com/opencitations/index/tree/master/index/identifier) il codice per verificare la correttezza sintattica di un identificativo e la sua esistenza, e se necessario normalizzarlo, *almeno* per `doi`, `issn` e `orcid`. \nSe non esiste gi√†, andrebbe quindi fatto un programma, sul modello di quelli per `doi`, `issn` e `orcid`,  che gestisca gli `isbn`.\n\nHo riutilizzato questo codice all'interno del file [session002.py](https://github.com/eliarizzetto/index/blob/master/index/validation/session002.py) che per ora permette di:\n* accedere a e leggere tutti i file .csv all'interno di una cartella di input e all'interno di sue sottocartelle\n* leggere i file come dizionari\n* verificare la validit√† del valore/dei valori del field `\"id\"` con una richiesta alla relativa API, per `doi` e `issn`, sfruttando il codice preesistente\n* nel caso in cui l'id non sia valido, mandare a schermo un messaggio con la posizione dell'errore\n\n√à da definire meglio la *condizione* attraverso cui si sceglie quale funzione chiamare per analizzare ciascun valore di id: per ora c'√® solo una regex minimale che controlla l'inizio del valore (ammette solo i casi in cui non ci sono anomalie nel prefisso).\n\nQuesto il codice aggiornato a 06/09 (e qui la [versione online](https://github.com/eliarizzetto/index/commit/e5967776e216b0c993fce368b5475c3b611d6c2c#diff-ce0a579d2aa9204ad6e68331df3f331c9e515cfb7ba3a98b43fb7b7e1c0e48c5)):\n\n```python {title=\"session002.py\"}\n# ----accessing and reading files  \nimport glob  \nfrom csv import DictReader  \nfrom os import sep, makedirs, walk  \nfrom os.path import exists, basename, isdir  \nimport tarfile  \n  \n# ----managing identifiers  \n  \nfrom index.identifier.doimanager import DOIManager  \nfrom index.identifier.issnmanager import ISSNManager  \nfrom index.identifier.orcidmanager import ORCIDManager  \nfrom re import sub, match  \n  \n  \nsource_paths = 'C:/Users/media/Desktop/thesis23/meta_input'  \n#source_paths= \"C:/Users/media/Desktop/thesis23/oc/index/index/validation/test_files\"  \n  \n  \ndef get_all_files(i_dir_or_targz_file):  \n    \"\"\"  \n    Modified version of index.coci.glob.get_all_files() in order to access .csv files. If compressed files are found,    it automatically decompress and read them. Returns 2 variables: a list of file paths of raw .csv files; and the    list of decompressed files if any is found (otherwise None).    \"\"\"    result = []  \n    targz_fd = None  \n  \n    if isdir(i_dir_or_targz_file):  \n        for cur_dir, cur_subdir, cur_files in walk(i_dir_or_targz_file):  \n            for cur_file in cur_files:  \n                if cur_file.endswith(\".csv\") and not basename(cur_file).startswith(\".\"):  \n                    result.append(cur_dir + sep + cur_file)  \n    elif i_dir_or_targz_file.endswith(\"tar.gz\"):  \n        targz_fd = tarfile.open(i_dir_or_targz_file, \"r:gz\", encoding=\"utf-8\")  \n        for cur_file in targz_fd:  \n            if cur_file.name.endswith(\".csv\") and not basename(cur_file.name).startswith(\".\"):  \n                result.append(cur_file)  \n    else:  \n        print(\"It is not possible to process the input path.\")  \n    return result, targz_fd  \n  \n  \n  \n  \ndef access_csv(source_dir):  \n  \n    \"\"\"Accesses the input directory and its relative subdirectories  \n    and returns a list of all the .csv file paths therein\"\"\"  \n    source_data = glob.glob(f'{source_dir}/**/*.csv', recursive=True)  \n    return source_data  \n  \n  \n  \n# ----------------parametri da mettere in input: source_paths,  \n  \ndoi_mngr = DOIManager()  \nissn_mngr = ISSNManager()  \n  \n  \nfor file in access_csv(source_paths):  \n    with open(file, 'r', encoding='utf-8') as source_file:  \n        data_dict = DictReader(source_file)  \n  \n        for position_in_table, row in enumerate(data_dict):  \n  \n            field_id = row['id']  \n            #print(field_id)  \n  \n            for position_in_field, id_instance in enumerate(field_id.split()):  \n                print(id_instance)  \n  \n                if match(\"^doi:10\", id_instance):  \n                    normalized_id_instance = doi_mngr.normalise(id_instance)  \n  \n                    if doi_mngr.is_valid(normalized_id_instance) is None:  \n                        print(f'Take a look at id no. {position_in_field} at row no. {position_in_table} in file {file}')  \n  \n                if match(\"^issn:\", id_instance):  \n                    normalized_id_instance = issn_mngr.normalise(id_instance)  \n                    if issn_mngr.is_valid(normalized_id_instance) is None:  \n                        print(f'Take a look at id no. {position_in_field} at row no. {position_in_table} in file {file}')  \n  \n                if match(\"^isbn:\", id_instance):  \n                    print(f'Take a look at id no. {position_in_field} at row no. {position_in_table} in file {file}')  \n                    print(\"A ISBN manager is yet to be developed\")\n```\n","lastmodified":"2023-03-19T23:54:38.516579322Z","tags":null},"/notes/sessions/session-003":{"title":"Session 003","content":"\u003cspan \n\t\tclass='ob-timelines'\n\t\tdata-date=\"2022-09-13-00\"\u003e\n\u003c/span\u003e\n\nüë• [**Reference meeting: 003**](notes/meetings/meeting%20003.md)\n\nüîô [**Previous work session: 002**](notes/sessions/session%20002.md)\n\n## Librerie per validazione\n* [Cerberus](https://docs.python-cerberus.org/en/stable/)\n* [Json Schema](https://json-schema.org/)\nHo provato a capire la documentazione di cerberus, ma mi √® sembrato meno vantaggioso di quanto mi aspettassi: ci metto pi√π tempo a capire come funzionano le \"validation rules\" -ed ad adattarle alle mie esigenze - che non a scriverle da me.\n\n√à stato comunque utile per capire quanto e come, in generale, possano essere utili dei software pronti all'uso per la validazione, e ad avere un esempio di riferimento come framework. Eventualmente posso ritornarci sopra quando avr√≤ definito meglio il workflow per la validazione, anche se ne dubito. \n\n\n## Framework per il processo di validazione\nDal tentativo di capire Cerberus sono emerse alcune riflessioni, che ho provato a generalizzare qui sotto. In particolare, mi sembra rilevante la necessit√† di **definire uno schema** che rappresenti dati corretti. √à una cosa che - se effettivamente necessaria - spero di poter fare in itinere, vale a dire una volta che ho avr√≤ del codice funzionante da poter \"astrarre\" in uno schema formale. \n\n\n\u003ch3 style=\"text-align:center;\"\u003eSoftware general structure\u003c/h3\u003e\n\nValidation consists in checking an input document against a schema: any document that matches the schema is said to ‚Äúvalidate‚Äù against the schema specified in input.\n\n* **Input**: document, schema, set of error types\n* **Output**: boolean value for a specified type of error; error position in document; suggested correction/action.\n\n\n#### 3 types/levels of validation:\n\n1. **Against OC accepted format** (table structure; string format):\n    * problems regarding the OC _table structure_ (CITS-CSV, META-CSV) may occur while checking if, e.g.:\n        * all fields are present (header)\n        * the values for any required fields are specified coherently with the constraints listed in [@massariHowStructureCitations2022](notes/readings/@massariHowStructureCitations2022.md)\n        * etc.\n    * problems regarding the string format may be, e.g.:\n        * no incorrect spaces in the cell\n        * correct use of square brackets in the `id` or `author `fields\n        * lowercase in the id prefix\n        * etc.\n2. **Against ID-specific syntax**\n\tValidate according to the syntax defined by an external schema, one for each type of accepted ID. The accepted ID in OpenCitations are the following:\n\t* **Bibliographic resources (br)**: 'doi', 'issn', 'isbn', 'pmid', 'pmcid', 'url', 'wikidata', 'wikipedia'\n\t* **Responsible Agents (ra)** (authors, editors, publishers): 'crossref', 'orcid', 'viaf', 'wikidata', 'ror'\n3. **Semantic Validation**\n\tInvolves:\n\t* Checking the actual existence of the input entities, represented in the table by their identifier, via request to the ID-specific API\n\t* (?)Checking the coherence of the information contained in other fields (e.g. type or author) with the information of the entity as it is represented by its identifier in the OC database or in the relative API\n\t* (?)Checking the conformity of the table with the OC data model (pySHACL)\n\n\n#### 3 types of ‚Äúerror‚Äù\n\nAn error type is assigned to an ‚Äúerror‚Äù instance (i.e. anything raising any error at any of the validation layers) according to its gravity level, and consequently to its level of ‚Äúacceptability‚Äù:\n* **note**\n* **warning**\n* **error**\n\n\n\n\n\n## Proposta di impostazione del codice per validare IDs\n```python {title=\"ID_validation_structure1.py\"}\nimport re\n\nid_field = {'id': 'doi:10.1007/978-3-540-88851-2 isbn:9783540888505 isbn:9783540888512'}\n\nid_field_content = id_field['id'].split()\n\nfor i in id_field_content:\n¬† ¬† if re.match(id, '^doi'):\n¬† ¬† ¬† ¬† #oc-format validation for DOIs\n¬† ¬† ¬† ¬† #syntax validation for DOIs\n¬† ¬† ¬† ¬† #semantic validation for DOIs\n¬† ¬† ¬† ¬† pass\n\n¬† ¬† elif re.match(id, '^issn'):\n¬† ¬† ¬† ¬† #oc-format validation for ISSNs\n¬† ¬† ¬† ¬† #syntax validation for ISSNs\n¬† ¬† ¬† ¬† #semantic validation for ISSNs\n¬† ¬† ¬† ¬† pass\n¬† ¬† elif re.match(id, '^isbn'):\n¬† ¬† ¬† ¬† #oc-format validation for ISBNs\n¬† ¬† ¬† ¬† #syntax validation for ISBNs\n¬† ¬† ¬† ¬† #semantic validation for ISBNs\n¬† ¬† ¬† ¬† pass\n¬† ¬† elif re.match(id, '^pmid'):\n¬† ¬† ¬† ¬† #oc-format validation for PMIDs\n¬† ¬† ¬† ¬† #syntax validation for PMIDs\n¬† ¬† ¬† ¬† #semantic validation for PMIDs\n¬† ¬† ¬† ¬† pass\n¬† ¬† elif re.match(id, '^pmcid'):\n¬† ¬† ¬† ¬† #oc-format validation for PMCIDs\n¬† ¬† ¬† ¬† #syntax validation for PMCIDs\n¬† ¬† ¬† ¬† #semantic validation for PMCIDs\n¬† ¬† ¬† ¬† pass\n¬† ¬† elif re.match(id, '^url'):\n¬† ¬† ¬† ¬† #oc-format validation for URLs\n¬† ¬† ¬† ¬† #syntax validation for URLs\n¬† ¬† ¬† ¬† #semantic validation for URLs\n¬† ¬† ¬† ¬† pass\n\n¬† ¬† elif re.match(id, '^wikidata'):\n¬† ¬† ¬† ¬† #oc-format validation for wikidata\n¬† ¬† ¬† ¬† #syntax validation for wikidata\n¬† ¬† ¬† ¬† #semantic validation for wikidata\n¬† ¬† ¬† ¬† pass\n¬† ¬† elif re.match(id, '^wikipedia'):\n ¬† ¬† ¬† #oc-format validation for wikipedia\n¬† ¬† ¬† ¬† #syntax validation for wikipedia\n¬† ¬† ¬† ¬† #semantic validation for wikipedia\n¬† ¬† ¬† ¬† pass\n\n¬† ¬† else:\n¬† ¬† ¬† ¬† #ritorna l'errore del tipo giusto, con il messaggio giusto, con la posizione giusta\n```\n\n## Test e revisione di IdentifierManager\n* Ho iniziato a capire come eseguire dei test con la libreria unittest\n* Ho capito la struttura generale delle varie classi di Identifier Manager e dei relativi metodi, in preparazione della scrittura di classi che estendano IdentifierManager consentendo la gestione degli ID finora mancanti.","lastmodified":"2023-03-19T23:54:38.516579322Z","tags":null},"/notes/sessions/session-004":{"title":"Session 004","content":"\u003cspan \n\t\tclass='ob-timelines'\n\t\tdata-date=\"2022-09-17-00\"\u003e\n\u003c/span\u003e\n\nüë• [**Reference meeting: 004**](notes/meetings/meeting%20004.md)\n\nüîô [**Previous work session: 003**](notes/sessions/session%20003.md)\n\n## Identifiers: wikidata e wikipedia\n\n\u003cu\u003e**Per info complete vedi [Managing Wiki Identifiers](notes/Managing%20Wiki%20Identifiers.md)**\u003c/u\u003e\n\n### Accesso ai dati: MediaWiki Action API e Linked Data Interface\nI servizi di Wikimedia sono consultabili attraverso un'unica API, con un URL specifico per ogni servizio: la [**MediaWiki Action API**](https://www.mediawiki.org/wiki/API:Main_page). \n\n###### Wikidata\nSeguendo i consigli della pagina di aiuto per l'accesso a Wikidata, per questo identificativo ho per√≤ deciso di ricorrere a un altro tool (disponibile solo per Wikidata), la cosiddetta [**Linked Data Interface**](https://www.wikidata.org/wiki/Wikidata:Data_access/en#Linked_Data_Interface_(URI)); funziona come un'API, nel senso che posso specificare i parametri che mi interessano, come ad esempio l'output format in json, ma √® pi√π veloce, oltre che pi√π indicata per l'accesso a risorse precise e gi√† note (come quelle inviate dall'utente).\n\n###### Wikipedia\nPer Wikipedia, invece, √® necessario usare la [MediaWiki Action API]https://www.mediawiki.org/wiki/API:Main_page), perch√© non c'√® nessun altro tool in cui si possano specificare i parametri nella richiesta. Per altro, bisogna per forza specificare un URL per la lingua di riferimento, quindi l'endpoint dell'API sarebbe quello di Wikipedia in inglese.\n\n### Quali identificativi considerare?\n\n#### Page ID\n\u003cu\u003eTutte le pagine dei servizi che sfruttano il software MediaWiki[^1] hanno un identificativo ***della pagina*** (!!)\u003c/u\u003e: il **page id**. Tramite questo identificativo si pu√≤ accedere a una pagina specifica, sia che si utilizzi l'API sia senza, usando specifici parametri a seconda della soluzione scelta per accedere ai dati.\n\n\u003e [!examples]- Esempi\n\u003e \n\u003e * **Con API** (parametro `pageid` o `pageids`, a seconda del valore del parametro `action`, rispettivamente `query` e `parse`):\n\u003e \n\u003e https://en.wikipedia.org/w/api.php?action=parse\u0026format=json\u0026pageid=8091\n\u003e\n\u003e https://en.wikipedia.org/w/api.php?action=query\u0026format=json\u0026pageids=8091\n\u003e \n\u003e * **Senza API** (parametro `curid`)\n\u003e\n\u003e https://en.wikipedia.org/w/index.php?curid=8091\n\n\n1. Il Page ID √® univoco, e lo √® relativamente a **tutte** le pagine create con MediaWiki prese nella loro totalit√† (il Page ID assegnato a una pagina Wikipedia non solo non potr√† essere assegnato ad un'altra pagina Wikipedia, ma nemmeno a una pagina Wikidata).\n\n2. \u003cu\u003eIl Page ID √® una propriet√† **della pagina**\u003c/u\u003e appunto, non dell'entit√† che essa descrive. Ovvero, se l'entit√† Douglas Adams ha un identificativo, quello √® \"Q42\", *non* \"138\", che √® il Page ID della sua pagina all'interno di Wiki*data*.\n\nPer la ragione menzionata al punto 2), \u003cu\u003enon mi sembra appropriato usare il Page ID per rappresentare dei concetti o delle entit√†, come si cercherebbe di fare nel rappresentare delle risorse provenienti da Wikidata\u003c/u\u003e --\u003e per gli id prefissati da `wikidata:` posso usare il **Q-ID** (vedi [Managing Wiki Identifiers](notes/Managing%20Wiki%20Identifiers.md)).\n**\u003cu\u003eMa per le pagine di Wikipedia?\u003c/u\u003e** (vedi sotto).\n\n#### Page title\nIl Page title √® un identificativo univoco che rappresenta ci√≤ che la pagina descrive, o meglio il suo contenuto. √à relativo a ciascuno dei due servizi, Wikipedia e Wikidata. **Nel caso di Wikidata**, consiste nel Q-ID - ed ha quindi una sintassi precisa -  e rappresenta l'entit√† che la pagina descrive (o almeno cos√¨ l'ho inteso). **Nel caso di Wikipedia**, √® comunque univoco (due pagine, entrambe di Wikipedia, non avranno mai lo stesso titolo), ma √® un semplice literal (\"teoricamente\" senza spazi, da quanto capisco). √à visibile nell'ultima parte dell'URL, formattato con degli underscore al posto degli spazi.\n\n#### Altri identificativi\nEsiste (un) altro/altri identificativo/i, con una sintassi uguale a quella del Page ID, ma associato/i a versioni specifiche della pagina. Non √® quindi distinguibile automaticamente dal Page ID ma ha bisogno di un suo parametro specifico nella richiesta.\n\n#### Wikipedia\n\n[^1]: **MediaWiki**¬†is a particular wiki engine software developed for and used by Wikipedia and the other Wikimedia projects. MediaWiki is freely available for others to use (and improve), and it is in use by all sorts of projects and organizations around the world. This site, mediawiki.org, is intended for information about MediaWiki and related software. *from [https://www.mediawiki.org/wiki/Differences_between_Wikipedia,_Wikimedia,_MediaWiki,_and_wiki](https://www.mediawiki.org/wiki/Differences_between_Wikipedia,_Wikimedia,_MediaWiki,_and_wiki)*.\n\n## WikidataManager\nHo aggiunto agli IdentifierManager la classe `WikidataManager`, in [**wikidata.py**](https://github.com/opencitations/identifier_manager/blob/main/oc_idmanager/wikidata.py). √à stata costruita sul modello di `DOIManager`; cos√¨ com'√® funziona e **passa i test, gi√† caricati su Github**. Non dovrebbero esserci correzioni da fare, ma **se si vogliono aggiungere le funzionalit√† di get_extra_info** (vedi sotto) **√® ovviamente da estendere**.\n\n\n## get_extra_info: un parametro (o un metodo) per ritornare informazioni ulteriori ottenute dall'API\nCon Arianna si pensava di aggiungere un metodo, che chiameremo `.get_extra_info`, che con un chiamata all'API non solo verifica che l'id esista e sia registrato (facendo cio√® quello che gi√† fa `.exist`) ma in pi√π estrae dal json in risposta altre informazioni utili (es. publisher, tipo di pubblicazione, ecc.). Questo metodo va aggiunto tra i parametri di `.is_valid` ed √® in default **False**, lasciando che `.is_valid` chiami e ritorni `.exist`, esattamente come ora; se per√≤   `.get_extra_info` √® specificato come True, viene chiamato e, di conseguenza, `.is_valid` ritorna sia il valore booleano del controllo di esistenza, sia un dizionario con le informazioni extra estratte dalla risposta dell'API. Vedi codice sotto. Ovviamente il metodo andr√† aggiunto anche su Su Base Manager.\n\n\n```python {title=\"Proposta per modifiche di .is_valid; es. da wikidata.py\"}\n\n\ndef is_valid(self, wikidata_id, get_extra_info=False): #default False tra i params \n  \n    wikidata_id = self.normalise(wikidata_id, include_prefix=True)\n    if wikidata_id is None or not self.syntax_ok(wikidata_id):  \n        return False  \n    elif get_extra_info=False:  # se get_extra_info==False chiama e ritorna exist oppure il valore all'interno di data\n        if not wikidata_id in self._data or self._data[wikidata_id] is None:  \n            return self.exists(wikidata_id)  \n        return self._data[wikidata_id].get(\"valid\")\n    else: #se get_extra_info==True chiama e ritorna get_extra_info\n\t    return self.get_extra_data(wikidata_id)\n\n\n...\n\ndef get_extra_info(self, wikidata_id_full):\n\t... #richiesta all'API (vedi .exist())\n\t... #estrazione delle info extra (se possibile, cio√® dipendentemente dalla risposta che d√† l'API)\n\t\n\treturn bool, dict # se la chiamata va a buon fine e la risorsa esiste, ritorna True e un dizionario con le info aggiuntive\n\n```\n\n\n**Update**: vedi [notebook di Arianna](https://github.com/ariannamorettj/OC_notebook_n/blob/main/OC_AM_notebook.ipynb), sezione 13/09 - 20/09:\n\n\u003e \"Confronto¬†con Elia: **Proposta di aggiungere un parametro tipo get_extra_info=False a is_valid**, che viene¬†**poi passato a exist**. Il vantaggio di mettere questo parametro inizializzato a False gi√† in is_valid (e non solo in exist) permette, su richiesta, di ottenere informazioni aggiuntive (es. publisher, tipo di pubblicazione, ecc.). senza dover fare una seconda chiamata alle API, e di ottenere, insieme al booleano relativo alla validazione, anche un dizionario con i dati aggiuntivi recuperati. In alternativa, il parametro get_extra_info=False si potrebbe aggiungere solo ad exists, ma il vantaggio sarebbe limitato alle occasioni in cui si pu√≤ chiamare exists da solo: nella maggior parte dei casi resterebbe la doppia chiamata alle API, dal momento che non si potrebbero recuperare le informazioni gi√† nel corso della prima validazione.\"\n\n`get_extra_info` dovrebbe per forza essere inizializzato a False, perch√© normalemente dove poter ritornare un booleano. Per il processo di validazione ci sarebbe un altra funzione, esterna agli ID managers, per confrontare i risultati ottenuti dall'API con i dati forniti dagli utenti.\n\n\n\u003cu\u003e**Per info complete vedi [Managing Wiki Identifiers](notes/Managing%20Wiki%20Identifiers.md)**\u003c/u\u003e","lastmodified":"2023-03-19T23:54:38.516579322Z","tags":null},"/notes/sessions/session-005":{"title":"Session 005","content":"\u003cspan \n\t\tclass='ob-timelines'\n\t\tdata-date=\"2022-09-28-00\"\u003e\n\u003c/span\u003e\n\nüë• [**Reference meeting: 005**](notes/meetings/meeting%20005.md)\n\nüîô [**Previous work session: 004**](notes/sessions/session%20004.md)\n\n\u003e [!info]+ My goals for this session\n\u003e \n\u003e The description of your goal goes here\n\n\n\n### Redirects e Disambiguation\n##### Redirect\nvedi https://www.mediawiki.org/wiki/Help:Redirects#Viewing_a_redirect (fondamentale per capire i redirect). soprattutto tieni presente che \"**When a page is¬†[moved](https://www.mediawiki.org/wiki/Special:MyLanguage/Help:Moving_a_page \"Special:MyLanguage/Help:Moving a page\"), a redirect from the old to the new pagename is automatically created**.\"!\n\n\n## Soluzione mega importante!\nQuesta richiesta sembra fornire le informazioni di cui abbiamo bisogno per capire se la/ pagina/e che cerco sono redirect e/o disambiguation: https://en.wikipedia.org/w/api.php?action=query\u0026format=json\u0026prop=redirects%7Cpageprops\u0026titles=Elizabeth%20II%7CQueen%20Elizabeth%7CPrince%20Charles%7CCharles%20III\u0026redirects=1\u0026rdprop=pageid%7Ctitle\u0026ppprop=disambiguation. Qui ho praticamente cercato tutte insieme delle pagine \"normali\" (Elizabeth II e Charles III), delle pagine di disambiguazione (Queen Elizabeth), delle pagine di redirect (Prince Charles). C'√® un parametro che in teoria non serve, ovvero `prop=redirects` (che elenca le pagine *che reindirizzano* alla pagina che si sta cercando), mentre invece va lasciato il parametro `redirects` (il cui valore √® un booleano, quindi se viene specificato nella richiesta ha valore True, indipendentemente da il valore effettivamente inserito; se invece si vuole che `redirects` sia false di deve semplicemente NON metterlo nella richiesta!), che in teoria dice a quale pagina la pagina che sto cercando reindirizza (quindi se nella risposta non c'√® niente, ovvero nessuna voce `\"redirects\": {...}`, allora significa che quella pagina **non** √® una pagina di reindirizzamento). Lo stesso vale per `ppprop=disambiguation`: se la pagina che cerco √® una pagina di disambiguazione nella risposta ci sar√† una coppia key-value `\"disambiguation\": \"\"`, se non lo √® allora non ci sar√† niente. \n\nQuesta √® la risposta in json della richiesta menzionata sopra:\n+ [sandbox con i parametri gi√† inseriti nell'interfaccia](https://en.wikipedia.org/wiki/Special:ApiSandbox#action=query\u0026format=json\u0026prop=redirects%7Cpageprops\u0026titles=Elizabeth%20II%7CQueen%20Elizabeth%7CPrince%20Charles%7CCharles%20III\u0026redirects=1\u0026rdprop=pageid%7Ctitle\u0026ppprop=disambiguation)\n+ url (richiesta) generato dalla sandbox: https://en.wikipedia.org/w/api.php?action=query\u0026format=json\u0026prop=redirects%7Cpageprops\u0026titles=Elizabeth%20II%7CQueen%20Elizabeth%7CPrince%20Charles%7CCharles%20III\u0026redirects=1\u0026rdprop=pageid%7Ctitle\u0026ppprop=disambiguation\n+ risposta alla richiesta (sempre generata dalla sandbox):\n```json\n{\n    \"continue\": {\n        \"rdcontinue\": \"Charles_III|1720180\",\n        \"continue\": \"||pageprops\"\n    },\n    \"query\": {\n        \"redirects\": [\n            {\n                \"from\": \"Prince Charles\",\n                \"to\": \"Charles III\"\n            }\n        ],\n        \"pages\": {\n            \"125248\": {\n                \"pageid\": 125248,\n                \"ns\": 0,\n                \"title\": \"Charles III\",\n                \"redirects\": [\n                    {\n                        \"pageid\": 160475,\n                        \"ns\": 0,\n                        \"title\": \"Charles Windsor, Prince of Wales\"\n                    },\n                    {\n                        \"pageid\": 247754,\n                        \"ns\": 0,\n                        \"title\": \"Charles Philip Arthur George Windsor-Mountbatten\"\n                    },\n                    {\n                        \"pageid\": 247755,\n                        \"ns\": 0,\n                        \"title\": \"Charles Philip Arthur George Mountbatten-Windsor\"\n                    },\n                    {\n                        \"pageid\": 411507,\n                        \"ns\": 0,\n                        \"title\": \"Charles, the Prince of Wales\"\n                    },\n                    {\n                        \"pageid\": 672479,\n                        \"ns\": 0,\n                        \"title\": \"Charles, prince of Wales\"\n                    },\n                    {\n                        \"pageid\": 962107,\n                        \"ns\": 0,\n                        \"title\": \"HRH Prince Charles\"\n                    },\n                    {\n                        \"pageid\": 1145872,\n                        \"ns\": 0,\n                        \"title\": \"Charles Windsor\"\n                    },\n                    {\n                        \"pageid\": 1238910,\n                        \"ns\": 0,\n                        \"title\": \"Charles, prince of wales\"\n                    },\n                    {\n                        \"pageid\": 1449884,\n                        \"ns\": 0,\n                        \"title\": \"Charles Mountbatten-Windsor\"\n                    },\n                    {\n                        \"pageid\": 1648561,\n                        \"ns\": 0,\n                        \"title\": \"Prince Charles of Wales\"\n                    }\n                ]\n            },\n            \"12153654\": {\n                \"pageid\": 12153654,\n                \"ns\": 0,\n                \"title\": \"Elizabeth II\"\n            },\n            \"165355\": {\n                \"pageid\": 165355,\n                \"ns\": 0,\n                \"title\": \"Queen Elizabeth\",\n                \"pageprops\": {\n                    \"disambiguation\": \"\"\n                }\n            }\n        }\n    }\n}\n```\n\n\n# Raffiniamo la richiesta\nTogliamo il valore redirects al parametro prop, e lasciamo soltanto redirects *come parametro* (oltre agli altri parametri e valori, ovviamente).\nConcentriamoci sugli effetti del parametro `redirects`.\n**Questa √® la risposta alla richiesta con il parametro `redirects`**, ovvero: https://en.wikipedia.org/w/api.php?action=query\u0026format=json\u0026prop=pageprops\u0026titles=Elizabeth%20II%7CQueen%20Elizabeth%7CPrince%20Charles%7CCharles%20III\u0026redirects=1\u0026ppprop=disambiguation\n\n```json\n{\n    \"batchcomplete\": \"\",\n    \"query\": {\n        \"redirects\": [\n            {\n                \"from\": \"Prince Charles\",\n                \"to\": \"Charles III\"\n            }\n        ],\n        \"pages\": {\n            \"125248\": {\n                \"pageid\": 125248,\n                \"ns\": 0,\n                \"title\": \"Charles III\"\n            },\n            \"12153654\": {\n                \"pageid\": 12153654,\n                \"ns\": 0,\n                \"title\": \"Elizabeth II\"\n            },\n            \"165355\": {\n                \"pageid\": 165355,\n                \"ns\": 0,\n                \"title\": \"Queen Elizabeth\",\n                \"pageprops\": {\n                    \"disambiguation\": \"\"\n                }\n            }\n        }\n    }\n}\n```\n\nFai attenzione soprattuto al fatto che della pagina \"Prince Charles\", avendo io specificato il parametro `redirects`, l'API non restituisce i dati relativi alla pagina di reindirizzamento (cio√® quella con nome \"Prince Charles\"), ma soltanto quelli relativi alla pagina a cui mi ha automaticamente reindirizzato. Questo, per√≤, √® il solo modo che abbia trovato finora per segnalare che la pagina che sto cercando non √® una pagina \"normale\", ma una pagina di reindirizzamento. Qui sotto la risposta alla richiesta formulata senza specificare il parametro `redirects`: della pagina con titolo Prince Charles (che √® una pagina di disambiguazione) vengono restituiti gli stessi dati che per le pagine normali!!\n**richiesta**: https://en.wikipedia.org/w/api.php?action=query\u0026format=json\u0026prop=pageprops\u0026titles=Elizabeth%20II%7CQueen%20Elizabeth%7CPrince%20Charles%7CCharles%20III\u0026ppprop=disambiguation\n\n**risposta**:\n\n```json\n{\n    \"batchcomplete\": \"\",\n    \"query\": {\n        \"pages\": {\n            \"125248\": {\n                \"pageid\": 125248,\n                \"ns\": 0,\n                \"title\": \"Charles III\"\n            },\n            \"12153654\": {\n                \"pageid\": 12153654,\n                \"ns\": 0,\n                \"title\": \"Elizabeth II\"\n            },\n            \"20756878\": {\n                \"pageid\": 20756878,\n                \"ns\": 0,\n                \"title\": \"Prince Charles\"\n            },\n            \"165355\": {\n                \"pageid\": 165355,\n                \"ns\": 0,\n                \"title\": \"Queen Elizabeth\",\n                \"pageprops\": {\n                    \"disambiguation\": \"\"\n                }\n            }\n        }\n    }\n}\n```\n\n\n### Domande\n1. Cosa succede se cerco un titolo che prima era quello di articolo normale, ma poi, essendo stato la pagina *spostata* (ovvero essendo stato cambiato il titolo dell'articolo, che pur mantenendo lo stesso page id ha assunto un titolo diverso), √® diventato il titolo di una pagina di reindirizzamento? Ad esempio, \"Charles, Prince of Wales\" probabilmente era il titolo dell'articolo nel 2003, ma ora √® il titolo di una pagina di reindirizzamento (con un suo proprio pag id!): vedi la schermata informativa che appare se specifichi redirects=no nell'URL adatto con il browser: https://en.wikipedia.org/w/index.php?title=Charles,_Prince%20of%20Wales\u0026redirect=no. ![redirect_page](images/redirect_page.jpg).\n\tIn un caso come questo possiamo escludere che il dato inviato dall'utente venga considerato buono, solo perch√© la pagina reindirizza a qualcos'altro, quando magari era effettivamente il titolo della pagina che lui aveva consultato, al tempo in cui l'ha consultata? D'altro canto, non c'√® un altro modo di sapere se la pagina √® un reindirizzamento o no, da quanto ne so. **NB: questo problema non si porrebbe con i page id, che rimangono fissi per tutta la vita della pagina, anche quanto essa viene spostata (cio√® le viene cambiato il titolo)**\n\n2. Le pagine di reindirizzamento possono reindirizzare a pagine inesistenti o, immagino, a pagine di disambiguzione.\n3. Pu√≤ il titolo di una pagina normale divenire, una volta spostata la pagina, il titolo di una pagina di disambiguazione?\n\n","lastmodified":"2023-03-19T23:54:38.516579322Z","tags":null},"/notes/sessions/session-006":{"title":"Session 006","content":"\u003cspan \n\t\tclass='ob-timelines'\n\t\tdata-date=\"2022-10-06-00\"\u003e\n\u003c/span\u003e\n\nüë• [**Reference meeting: 006**](notes/meetings/meeting%20006.md)\n\nüîô [**Previous work session: 005**](notes/sessions/session%20005.md)\n\n## Report degli errori\nNell'ottica di dover validare quanti pi√π dati possibile ad ogni esecuzione, √® necessario che l'output del processo di controllo sia un report completo, cio√® i risultati che √® stato possibile ottenere per ciascun dato da **tutta** la tabella. \nL'idea, per ora, √® innanzitutto di costruire un **report** (dizionario) che contenga le informazioni **minime**, ovvero:\n1. la *posizione* di un errore all'interno del .csv (implicita, in base alla \u003cu\u003estruttura\u003c/u\u003e del dizionario)\n2. il *livello* di validazione a cui l'errore √® stato riscontrato (conformit√† al modello OC, sintassi esterna, validit√† semantica)\n3. il *tipo di errore* che √® stato riscontrato (error, warning, info)\n\nLa posizione di un errore √® implicita nella struttura del dizionario, cio√® non √® necessario aggiungere una chiave all'interno del dizionario, ma basta fare in modo che questo sia strutturato in maniera coerente; da qui poi si potr√† dedurre come mappare queste informazioni localizzandole nel .csv inviato dall'utente. \n\nDal livello di validazione e del tipo di errore (entrambi resi espliciti con le rispettive coppie key-value nel dizionario, ma resi espliciti solo in caso di errore) si potr√† poi:\n* mappare l'errore rispetto alla posizione del dato in cui √® stato riscontrato, localizzandolo nel .csv in input\n* dedurre, insieme alle informazioni sulla posizione, quale sia il messaggio da dare all'utente e renderlo il pi√π preciso possibile in base alla combinazione di queste tre informazioni. \n\n\n```python {title=\"General minimal schema for the error report\"}\nreport = {  \n    row_position : {  \n        field: {  \n            element_in_field: {  \n                'validation_level' : ['1', '2', '3'],#1 solo valore di questi\n                'error_type': ['error', 'warning', 'info']#1 solo valore di questi\n            }  \n        }  \n        'row_format': {  \n            'validation_level' : '1',  \n            'error_type': ['error']  \n        }  \n    }  \n}\n```\n\n\nL'esempio del report di un csv con 2 soli errori,  uno in uno degli ID, diciamo `doi:10/1234567`, nel campo 'id' della terza riga, e l'altro nel campo autore - preso nel complesso - della sesta riga, potrebbe essere:\n```python (title=\"Report example\")\nreport = {\n\t\t  2:{\n\t\t\t 'id':{\n\t\t\t 'doi:10/1234567':{\n\t\t\t\t 'validation_level': '2', \n\t\t\t\t 'error_type': 'error'\n\t\t\t\t }\n\t\t\t }\n\t\t }\n\t\t  \n\t\t  5:{\n\t\t  'author':{\n\t\t\t  'validation_level': '1', \n\t\t\t  'error_type': 'error'\n\t\t\t  }\n\t\t  }\n}\n```\n\n## Struttura del codice\nL'idea per ora √® che ci sia una **funzione centrale** che richiama delle **funzioni che si occupano ciascuna di uno specifico controllo**.\n\n#### Funzioni di controllo\nLe funzioni di controllo idealmente funzionano tutte allo stesso modo:\n* restituiscono `True` se il controllo non d√† errori di alcun tipo\n* altrimenti, se viene rilevato uno dei tre tipi di errori, restituiscono un dizionario contenente soltanto le chiavi `'validation_level'` e  `'error_type'` con il relativo valore (uno solo per chiave).\n\nPer tutti e tre i \"contenitori\" interni al .csv che vengono iterati (quindi lista di rows, row e field, ma non l'eventuale singolo elemento all'interno di alcuni field, che costituisce l'elemento minimo)  **solo se nell'elemento pi√π interno ci sono degli errori**, viene creato un dizionario con delle chiavi che corrispondono a un *pointer* dell'elemento interno che contiene l'errore (cio√® la posizione della riga all'interno della lista di righe, la chiave del field all'interno della riga, la stringa dell'elemento all'interno del field); a queste chiavi sono associati come valori dei dizionari che contengono le informazioni relative all'errore (ovvero i dizionari con le chiavi  `'validation_level'` e  `'error_type'`).\n\nQuindi:\n1. Apro il .csv\n2. Itero il contenitore lista di dizionari (rows):\n\t+ se una delle row contiene errori a livello del contenitore riga, aggiungo il dizionario con la chiave che  √® la posizione della riga e il valore che √® il dizionario degli errori\n\t+ altrimenti, se non ci sono errori a livello di riga, il dizionario non viene creato\n\t3. Itero il contenitore row:\n\t\t+ se uno dei field contiene errori a livello del contenitore field, aggiungo il dizionario con la chiave che √® il nome del field e il valore che √® il dizionario degli errori\n\t\t+ altrimenti, se non ci sono errori a livello di field, il dizionario non viene creato\n\t\t4. Itero il contenitore field (se si tratta di un field per cui ha senso farlo):\n\t\t\t+ se uno degli elementi all'interno del field (laddove √® possibile suddividerlo) contiene errori, aggiungo il dizionario con la chiave che √® la stringa all'interno del field e il valore che √® il dizionario degli errori. \n\t\t\t+ altrimenti, se non ci sono errori a livello di elemento interno al field, il dizionario non viene creato.\n\n#### Funzione principale\n\nNella funzione principale gestisco il salvataggio degli errori per ogni livello e l'ordine in cui vanno chiamate le varie funzioni di controllo.\n\n\n### Codice finora\n\nStruttura funzione: https://github.com/eliarizzetto/thesis_resources/blob/402233889133d016023eddec3d5ac72c9ba5a6aa/validation_process/validation/validate_main.py\n\nReport errori: https://github.com/eliarizzetto/thesis_resources/blob/402233889133d016023eddec3d5ac72c9ba5a6aa/validation_process/validation/report_schema.py\n\n------------------\n1. Ha senso la struttura, in particolare l'idea di creare dei dizionari **nel contenitore pi√π esterno**\u003cu\u003e a condizione che\u003c/u\u003e ci sia un certo output dalla funzione che  controlla un elemento interno? √à possibile fare questa cosa\n\t+ Se creo un dizionario *prima* di verificare se ogni elemento dell'iterable passa il controllo, sto chiaramente creando un dizionario che potenzialmente potrebbe rimanere vuoto (nel caso in cui non ci siano errori), e lo sto facendo per ogni elemento che sia all'interno di un contenitore/iterable! Come nel codice qui sotto.\n\t+ D'altra parte, altrimenti come posso creare un dizionario unico per tutti gli elementi all'interno dell'iterable senza metterlo al di fuori del for loop?\n\n```python \ndef id_lev1(whole_id_field):\nid_field_pattern_oc_prefixes = r'...'\n\nif match(id_field_pattern_oc_prefixes, whole_id_field):  \n\treturn True\nelse:  \n\tresult = dict()  # \u003c----- {} per ogni elemento in field, a prescindere!\n\tfor item in whole_id_field.split():  \n\t\tif id_items_lev1(item) != True: \n\t\t\tresult[item] = id_items_lev1(item)# \u003c--lo popolo solo se ci sono errori\n\treturn result\n```\n\n2. Ha senso che io mi preoccupi di dividere gli elementi interni a un field?\n3. Ha senso preoccuparmi di verificare aspetti diversi di uno stesso livello di validazione, per sperare di riuscire a fornire un feedback preciso; ovvero, ha senso che faccia controlli separati con le regex con i prefissi specifici e quelle senza. \n4. Ha senso pensare di salvare prima tutti gli errori e poi condizionare in base ai risultati nel report (anche in base al tipo di errore) il passaggio ai successivi livelli di validazione?\n5. Software di Arcangelo gestisce casi in cui ci sono pi√π spazi tra un'ID e l'altro: posso permettermi di evitare di segnalare come errore una cosa tipo \"doi:10/123456       doi:10/6789019\", e semplicemente fare il controllo sugli elementi della lista dopo .split?","lastmodified":"2023-03-19T23:54:38.516579322Z","tags":null},"/notes/sessions/session-007":{"title":"Session 007","content":"\u003cspan \n\t\tclass='ob-timelines'\n\t\tdata-date=\"2022-10-13-00\"\u003e\n\u003c/span\u003e\n\nüë• [**Reference meeting: 007**](notes/meetings/meeting%20007.md)\n\nüîô [**Previous work session: 006**](notes/sessions/session%20006.md)\n\n### [JSON Schema](https://json-schema.org/) per l'output del processo di validazione\n\n```json {title=\"C:\\Users\\media\\Desktop\\report\\report.json\"}\n{  \n  \"$schema\": \"https://json-schema.org/draft/2020-12/schema\",  \n  \"$id\": \"http://example.com/example.json\",  \n  \"type\": \"object\",  \n  \"required\": [  \n    \"validation_level\",  \n    \"error_type\",  \n    \"message\"  \n  ],  \n  \"properties\": {  \n    \"validation_level\": {  \n      \"type\": \"string\",  \n      \"enum\": [\"oc_format\", \"external_syntax\", \"semantic\"]  \n    },  \n    \"error_type\": {  \n      \"type\": \"string\",  \n      \"enum\": [\"error\", \"warning\"]  \n    },  \n    \"message\": {  \n      \"type\": \"string\"  \n    },  \n    \"valid\": {  \n      \"type\": \"boolean\"  \n    }  \n  },  \n  \"if\": {  \n    \"properties\": {\"error_type\": {\"const\":\"error\"}}  \n    },  \n  \"then\": {  \n    \"properties\": {\"valid\": {\"const\": false}}  \n  }  \n}\n```\n\n√à possibile che non sia utilizzabile in una libreria, non passando la valid\n\ncompatibile con lo schema di una validazione. \n### Domande\n1. Rendere esplicita la posizione dell'errore, ovvero inserire una propriet√† come \"position\" sia per le rows che per gli elementi interni a un field? suppongo sia necessario...\n2. A proposito di JSON Schema: ha senso pensare di utilizzare una libreria basata su JSON Schema per validare il .csv? Ora che sto iniziando a capire la logica di JSON Schema, mi sembra meno difficile di quando ho iniziato a dare un'occhiata a Cerberus e python-jsonschema. Suppongo che entrambe le librerie ammettano di integrare l'utilizzo di funzioni esterne alla libreria, ma il problema maggiore resta la difficolt√† (l'impossibilit√†?) di personalizzare l'output della validazione.\n\t1. python-jsonschema\n\t2. pydantic","lastmodified":"2023-03-19T23:54:38.516579322Z","tags":null},"/notes/sessions/session-008":{"title":"Session 008","content":"\u003cspan \n\t\tclass='ob-timelines'\n\t\tdata-date=\"2022-10-20-00\"\u003e\n\u003c/span\u003e\n\nüë• [**Reference meeting: 008**](notes/meetings/meeting%20008.md)\n\nüîô [**Previous work session: 007**](notes/sessions/session%20007.md)\n\n## JSON Schema del report di errori e funzione di controllo\n\n**Folder nella repo GH**: https://github.com/eliarizzetto/thesis_resources/tree/main/check_output\n\nHo prodotto **2 schemi** per rappresentare l'output della validazione:\n* uno per l'output completo, cio√® una lista di dizionari (o un array di oggetti in JSON), in cui ciascun dizionario rappresenta l'errore con i relativi dettagli\n* uno per l'output di un qualsiasi \"step\" del processo di validazione, preso isolatamente, ovvero un dizionario che √® esso stesso la rappresentazione dell'errore con i relativi dettagli.\n\nNella stessa cartella c'√® anche uno **script** che usa python-jsonschema per validare contro uno di questi due JSON schemas uno qualsiasi dei dizionari prodotti in una fase del processo di validazione, cos√¨ da poter controllare, ogni volta che creo un nuovo dizionario corrispondente a un errore, di farlo secondo il JSON schema che ho definito. \n\nN.B. Ho cambiato idea radicalmente su come strutturare il report degli errori. Ora si configura come una lista (piatta!!) di dizionari, in cui ogni dizionario rappresenta un'errore. Ciascuno di questi dizionari contiene coppie key-value che rappresentano:\n* il tipo di errore (error, warning)\n* il livello di validazione in cui √® emerso l'errore (csv_wellformedness, external_syntax, semantic)\n* il messaggio (costruito in base a quale funzione di validazione √® stata \"fallita\")\n* la posizione, ovvero una chiave che ha come valore a sua volta un dizionario con key-values che indicano row, field e posizione all'interno del field in cui l'errore √® collocato. Ci√≤ che cambia √® come/dove si ottiene l'informazione della posizione dell'errore; non pi√π implicitamente dalla struttura, ma direttamente a partire dal dizionario corrispondente.\n\n\u003e [!example] Esempio di singolo dizionario, rappresentante un errore\n\n```python {title=\"Un esempio di dizionario per un errore\"}\nerror =  {\n  'error_type': 'error',\n  'message': 'The value in this field is not expressed in compliance with the '\n             \"syntax of OpenCitation CITS-CSV. Each identifier in 'citing_id' \"\n             \"and/or 'cited_id' must have the following form: ID abbreviation \"\n             '+ ‚Äú:‚Äù + ID value. No spaces are admitted within the ID. Example: '\n             'doi:10.48550/arXiv.2206.03971. The accepted prefixes (ID '\n             \"abbreviations) are the following: 'doi', 'issn', 'isbn', 'pmid', \"\n             \"'pmcid', 'url', 'wikidata', 'wikipedia'. \",\n  'position': {\n\t  'field': 'citing_id', \n\t  'idx_in_field': 0, \n\t  'row': 0\n  },\n  'validation_level': 'csv_wellformedness'\n}\n```\n\n## Funzione base per creare i dizionari dei singoli errori\n\nVedi [script](https://github.com/eliarizzetto/thesis_resources/blob/17c4967d10395f15a98d4c23677587443d72e534/CITS/create_report.py) su GH. **MANCA CHIAVE VALID E RELATIVO FLAG: AGGIUNGI!!**\n\n\n## Prime funzioni per controllare conformit√† a sintassi per CITS-CSV\nVedi [script](https://github.com/eliarizzetto/thesis_resources/blob/17c4967d10395f15a98d4c23677587443d72e534/CITS/validation_functions.py) su GH. \n\n## Bozza per la struttura del processo di validazione principale\n\nVedi [script](https://github.com/eliarizzetto/thesis_resources/blob/17c4967d10395f15a98d4c23677587443d72e534/CITS/validate_cits.py) su GH. Mancano naturalmente delle parti ma il criterio si capisce: per ogni cosa che voglio controllare ho una funzione specifica (che ritorna un booleano) e un messaggio specifico. Itero tutti gli elemento iterabili del csv e per ognuno di questi passo le/a funzioni/e rilevanti; se la funzione di controllo ritorna False, allora viene chiamata la funzione per la creazione del dizionario d'errore, con gli argomenti corretti: le key-values di  `position`  si deducono dalla posizione nell'iterazione, `validation_level` dal tipo di funzione che √® stata mandata, `error` si decide in base a che peso si vuol dare a quello specifico errore, ecc.\n\n\n```python {title=\"La bozza della struttura per il processo di validazione (CITS-CSV)\"}\n\n#assumiamo che stiamo iterando tutte le row nel csv, letto come lista di dizionari (le rows)\nfor field, value in row.items():  \n    if content(value):  \n  \n        if field == 'citing_id' or field == 'cited_id':  \n            if not wellformedness_id_field(value):  \n                message = \"The value in this field is not expressed in compliance with the syntax of OpenCitation \" \\  \n                          \"CITS-CSV. The content of 'citing_id' and 'cited_id' must be either a single ID or a sequence\" \\  \n                          \" of IDs, each separated by one single space character (Unicode Character ‚ÄúSPACE‚Äù, U+0020). \" \\  \n                          \"Each ID must not have spaces within itself, and must be of the following form: \" \\  \n                          \"ID abbreviation + ‚Äú:‚Äù + ID value. \"  \n  \n                error_final_report.append(create_error_dict(validation_level='csv_wellformedness', error_type='error', message=message,  \n                                          row=0, field=field))  \n  \n            for id_idx, id in enumerate(value.split()):  \n  \n                if not wellformedness_single_id(id):  \n                    message = \"The value in this field is not expressed in compliance with the syntax of OpenCitation \" \\  \n                              \"CITS-CSV. Each identifier in 'citing_id' and/or 'cited_id' must have the following \" \\  \n                              \"form: ID abbreviation + ‚Äú:‚Äù + ID value. No spaces are admitted within the ID. Example: \" \\  \n                              \"doi:10.48550/arXiv.2206.03971. The accepted prefixes (ID abbreviations) are the \" \\  \n                              \"following: 'doi', 'issn', 'isbn', 'pmid', 'pmcid', 'url', 'wikidata', 'wikipedia'. \"  \n  \n                    error_final_report.append(create_error_dict(validation_level='csv_wellformedness', error_type='error',  \n                                              message=message, row=0, field=field, idx_in_field=id_idx))  \n  \n                    # -------------ADD CHECK ON LEVEL 2 (EXTERNAL SYNTAX) AND 3 (SEMANTICS) FOR THE SINGLE IDs  \n  \n        if field == 'citing_publication_date' or field == 'cited_publication_date':  \n            if not wellformedness_date(value):  \n                message = \"The value in this field is not expressed in compliance with the syntax of OpenCitation \" \\  \n                          \"CITS-CSV. The content of 'citing_publication_date' and/or 'cited_publication_date' must be \" \\  \n                          \"of one of the following forms (according to standard ISO 86014): YYYY-MM-DD, YYYY-MM, \" \\  \n                          \"YYYY. If year is required, month and day are optional. If the day is expressed, \" \\  \n                          \"the day must also be expressed. Examples: '2000'; '2000-04'; '2000-04-27'.\"  \n  \n                error_final_report.append(create_error_dict(validation_level='csv_wellformedness', error_type='error',  \n                                          message=message, row=0, field=field))\n```\n\n","lastmodified":"2023-03-19T23:54:38.516579322Z","tags":null},"/notes/sessions/session-009":{"title":"Session 009","content":"\u003cspan \n\t\tclass='ob-timelines'\n\t\tdata-date=\"2022-10-25-00\"\u003e\n\u003c/span\u003e\n\nüë• [**Reference meeting: 009**](notes/meetings/meeting%20009.md)\n\nüîô [**Previous work session: 008**](notes/sessions/session%20008.md)\n\n\n## Modifiche al dizionario degli errori\nViste le [indicazioni dell'altra volta](notes/meetings/meeting%20008.md), ho creato un [branch specifico](https://github.com/eliarizzetto/thesis_resources.git) per modificare il dizionario dell'errore in modo che abbia una struttura fissa e coerente e che sia semanticamente ricco e interpretabile (nello specifico, √® ideale che sia indicata nel dizionario la posizione precisa e quale errore √® emerso):\n+ i 2 JSON Schema per il report (dizionario che rappresenta un errore): https://github.com/eliarizzetto/thesis_resources/blob/033002e63ca6a2e38e58aaf14ec17503afd6dd5b/check_output/error_report_schema.json\n+ la funzione che crea il report https://github.com/eliarizzetto/thesis_resources/blob/033002e63ca6a2e38e58aaf14ec17503afd6dd5b/CITS/create_report.py\n+ la bozza della struttura principale, in cui vengono chiamate le altre funzioni (quelle di validazione e quella che crea il report, *ogni volta* che una funzione di validazione non viene passata. https://github.com/eliarizzetto/thesis_resources/blob/033002e63ca6a2e38e58aaf14ec17503afd6dd5b/CITS/validate_cits.py\n\n### [Errors map](notes/Errors%20map.md)\nHo iniziato a compilare un .csv in cui elencare tutti i possibili errori, associandovi le funzioni che li rilevano e quali valori sono da specificare nel relativo report. \n\n\n## Domande\nCon la [struttura](https://github.com/eliarizzetto/thesis_resources/blob/033002e63ca6a2e38e58aaf14ec17503afd6dd5b/CITS/validate_cits.py) cos√¨ com'√® in questo momento, ogni elemento che si trova all'interno di un iterable, se possibile, viene considerato per s√©, poi viene passato in input a una funzione di validazione, e infine se non passa questa funzione viene prodotto un dizionario per rappresentare l'errore specifico (della funzione) che quell'elemento del .csv non ha passato. \n\nQuindi, all'interno di un field di cui si considerino gli item singolarmente (es. `id`), ogni item viene controllato con la stessa funzione, **cio√® per lo stesso errore**, e se non passa viene creato un dizionario che ripete le stesse informazioni per ciascun item (es. `error_type`, `validation_level`, `row`, ecc.). L'unica cosa che cambia √® il valore di `position[item]`, che cos√¨ come le cose stanno ora, in casi come questo ha necessariamente **sempre** una lista con un integer solo, perch√© la funzione che crea il dizionario viene chiamata **all'interno** del loop. \n\nSe non √® troppo caotico, si potrebbe fare in modo che **tutti** gli item all'interno di una *stessa* cella (cio√® stessa row stesso field) che hanno uno *stesso* errore (cio√® hanno fallito la stessa funzione) vengano aggiunti a un lista *ad hoc* che viene poi aggiunta al dizionario come valore di `position[item]`. \n\nAd esempio, per **uno stesso errore di formato su due diversi item di `citing_id`**, invece che:\n\n```json\n {'error_type': 'error',\n  'message': '',\n  'position': {'field': ['citing_id'],\n               'item': [0],\n               'located_in': 'item',\n               'row': [0]},\n  'validation_level': 'csv_wellformedness'},\n {'error_type': 'error',\n  'message': '',\n  'position': {'field': ['citing_id'],\n               'item': [2],\n               'located_in': 'item',\n               'row': [0]},\n  'validation_level': 'csv_wellformedness'},\n\n```\n\n\nsi avrebbe:\n\n```json\n {'error_type': 'error',\n  'message': '',\n  'position': {'field': ['citing_id'],\n               'item': [0,2],\n               'located_in': 'item',\n               'row': [0]},\n  'validation_level': 'csv_wellformedness'},\n```\n\n","lastmodified":"2023-03-19T23:54:38.516579322Z","tags":null},"/notes/sessions/session-010":{"title":"Session 010","content":"\u003cspan \n\t\tclass='ob-timelines'\n\t\tdata-date=\"2022-10-31-00\"\u003e\n\u003c/span\u003e\n\nüë• [**Reference meeting: 010**](notes/meetings/meeting%20010.md)\n\nüîô [**Previous work session: 009**](notes/sessions/session%20009.md)\n\n- [x] represent the position of an error as a tree, not as lists\n- [x] update the JSON schemas of the error reports\n- [x] config file for messages\n- [ ] re-think main structure\n- [x] update calls of `create_error_dict` inside main structure\n- [ ] duplicates on CITS-CSV\n\n\n\n\n* All'interno di `error_dict[position][table]`, `None` √® un valore possibile ***solo*** per la chiave `item`, che a questo punto pu√≤ avere come valori:\n\t* o una \u003cu\u003e**lista di integers**\u003c/u\u003e, che sono gli indici degli item interessati dall'errore\n\t* o **None**, ma MAI all'interno di una lista\n\t`None` si usa solo quando un field √® una stringa vuota o contenente solo \"null\", \"nan\" o \"none\" (ma questa cosa √® da vedere meglio[^1]); invece, se una cella contiene solo spazi, quegli spazi costituiscono a tutti gli effetti degli item, e vanno quindi rappresentati come item all'interno di una lista. La ragione per cui `None` non va dentro ad una lista √® che se la stringa √® vuota, all'interno di quella stringa non ci entro proprio. \u003cu\u003eTieni comunque presente che se splitti una stringa vuota, il risultato √® una lista contenente una sola stringa vuota, quindi il comportamento della struttura di base potrebbe essere semplicemente che per ogni field la lista si crea comunque, e i controlli si passano per tutti gli elementi di quella lista (se c'√® una stringa vuota all'interno di un field in cui non dovrebbe esserci, la validazione fallir√† comunque!). **Se per√≤ il field √® tra quelli che contengono un solo item \"semantico\", ad esempio titolo o data, la lista non puoi farla con .split(), ma devi invece considerare la stringa come lista con un solo elemento.**\u003c/u\u003e\n\n\n[^1]: Probabilmente √® il caso di considerare come contenuto vuoto solo il caso in cui la stringa sia *effettivamente* vuota. Nel caso in cui una cella contenga \"null\", \"nan\" o \"none\", quella cella, pi√π che non avere contenuto, ha un contenuto sbagliato, il che √® diverso! --\u003e bisognerebbe cambiare la funzione `content()`. Questo perch√© \"null\", \"nan\" o \"none\" costituiscono comunque dei dati che nella maggior parte dei casi non si possono prendere come buoni (anche se non possiamo saperlo a priori), e che comunque fallirebbero la validazione in altri controlli. ","lastmodified":"2023-03-19T23:54:38.516579322Z","tags":null},"/notes/sessions/session-011":{"title":"Session 011","content":"\u003cspan \n\t\tclass='ob-timelines'\n\t\tdata-date=\"2022-11-08-00\"\u003e\n\u003c/span\u003e\n\nüë• [**Reference meeting: 011**](notes/meetings/meeting%20011.md)\n\nüîô [**Previous work session: 010**](notes/sessions/session%20010.md)\n\n# Duplicates\n\n* Ho fatto in modo di creare, nella struttura principale, una lista che viene appositamente aggiornata ogni volta che si incontra un field rilevante (`citing_id`,`cited_id` o `id`) in una data `row`, aggiungendovi un set con tutti gli item che sono risultati validi per una specifica cella contente `'id'`.\n* Seguendo le indicazioni di Silvio in [meeting 010](notes/meetings/meeting%20010.md), usando le informazioni nella lista sopra (cio√® il fatto che 2 o pi√π ID siano presenti insieme nella stessa cella), ho costruito una lista in cui ogni set corrisponde NON al contenuto di una cella, ma a una entit√† bibliografica (appunto rappresentata come set contenente gli identificativi con cui essa √® rappresentata nel documento).\n\t* vedi `group_ids()` in [helper_functions.py](https://github.com/eliarizzetto/thesis_resources/blob/1f8c325eb96eabb5261e7004df458eecab107ee8/CITS/helper_functions.py) nel branch dedicato ai duplicates\n\t* **FONTE FONDAMENTALE**: https://stackoverflow.com/a/51739608/20184608\n\t\t* Avevo anche pensato, considerando le altre soluzioni proposte su SO, di leggere la tabella come un grafo, ma le cose si facevano complesse. Questa soluzione funziona e non √® troppo difficile da capire, ma potrebbe non essere molto efficiente. Ho anche provato a ristrutturarla e scriverla come una funzione ricorsiva, per tentare di renderla pi√π elegante (?), poi ho lasciato stare. \n* Ho creato una funzione ([get_duplicates.py](https://github.com/eliarizzetto/thesis_resources/blob/1f8c325eb96eabb5261e7004df458eecab107ee8/CITS/get_duplicates.py)) che legge la tabella alla luce della \"mappatura\" tra ID e entit√† bibligrafiche \"implicite\", e ritorna un dizionario con gli errori relativi. Gli errori sono di due tipi:\n\t* self-citation: quando la stessa bibliographic entity √® presente sia in citing_id che in cited_id nella stessa row\n\t* duplicate citation o duplicate row: quando la stessa citazione (collegamento tra entit√† bibliografiche) √® rappresentata in pi√π di una riga.\n\t\n\tGli errori nel dizionario in output da `get_duplicates_cits()` hanno gi√† tutte le informazioni che servono per essere aggiunti al final_report.\n\n","lastmodified":"2023-03-19T23:54:38.516579322Z","tags":null},"/notes/sessions/session-012":{"title":"Session 012","content":"\u003cspan \n\t\tclass='ob-timelines'\n\t\tdata-date=\"2022-11-16-00\"\u003e\n\u003c/span\u003e\n\nüë• [**Reference meeting: 012**](notes/meetings/meeting%20012.md)\n\nüîô [**Previous work session: 011**](notes/sessions/session%20011.md)\n\n\u003e [!info]+ My goals for this session\n\u003e \n\u003e The description of your goal goes here\n\n","lastmodified":"2023-03-19T23:54:38.516579322Z","tags":null},"/notes/sessions/session-013":{"title":"Session 013","content":"\u003cspan \n\t\tclass='ob-timelines'\n\t\tdata-date=\"2022-11-22-00\"\u003e\n\u003c/span\u003e\n\nüë• [**Reference meeting: 013**](notes/meetings/meeting%20013.md)\n\nüîô [**Previous work session: 012**](notes/sessions/session%20012.md)\n\n\n","lastmodified":"2023-03-19T23:54:38.516579322Z","tags":null},"/notes/sessions/session-014":{"title":"Session 014","content":"\u003cspan \n\t\tclass='ob-timelines'\n\t\tdata-date=\"2022-11-29-00\"\u003e\n\u003c/span\u003e\n\nüë• [**Reference meeting: 014**](notes/meetings/meeting%20014.md)\n\nüîô [**Previous work session: 013**](notes/sessions/session%20013.md)\n\n### Field `author`, `editor` e `publisher`\nHo applicato le correzioni secondo [meeting 013](notes/meetings/meeting%20013.md). Ora le particolarit√† di `publisher` sono gestite separatamente. Inoltre, √® presente una funzione, `orphan_ra_id()`, che individua possibili identificativi al di fuori delle quadre nei campi  `author`, `editor` e `publisher`: viene creato un *warning*.\n\n### Funzione duplicates in META-CSV e correzione della funzione duplicates per CITS-CSV\nHo creato la funzione per individuare le righe duplicate all'interno delle tabelle di Meta e ho aggiunto la chiamata e tutto il resto all'interno della funzione principale. Dopo una prima fase, ho individuato dei bugs, che erano presenti anche nella funzione per CITS-CSV: corretto entrambe le funzioni.\n\n### Field `venue`, `volume`, `issue`, `page` e `type`\nHo creato le funzioni per validare il formato OC per i campi `venue`, `volume`, `issue`, `page` e `type`, le cui chiamata e creazione del report sono gi√† aggiunte nella funzione principale. Funzionano, ma ci sono probabilmente delle modifiche/aggiunte da fare, che discuter√≤ in [meeting 014](notes/meetings/meeting%20014.md), relative a quanto devono essere restrittive le regex ‚Üí cosa considerare errore nei field `venue`, `volume` e `page`?\nPer ora, funziona cos√¨:\n* per `venue` e `volume`: l'unica cosa che controllo √® che non ci siano spazi all'inizio o alla fine della stringa, e che non ci siano doppi spazi in mezzo\n* per `page`: ho deciso di ammettere due formati, quello con le cifre e quello con i numeri romani (ma qui la sintassi di META-CSV non √® chiara). Devono sempre esserci due numeri (espressi entrambi nello stesso formato, cio√® cifre XOR numeri romani) separati da un trattino (cio√® mai un numero solo, nemmeno nell'ipotesi che la risorsa descritta non sia pi√π lunga di una pagina ‚Üí questo potrebbe essere un punto da cambiare, se √® compatibile con il software che processa Meta...). Per ora, sono ammessi anche intervalli impossibili (in cui la pagina di fine √® minore della pagina di inizio, es. 20-15)[^1] e numeri romani 'impossibili' (es. VD), in mancanza di una sintassi universale e precisa per questo tipo di numerazione. \n\n### Ipotesi di dover rivedere i caratteri legali nelle stringhe dei nomi di persona\nVedi domande in [meeting 014](notes/meetings/meeting%20014.md)\n\n### Meta required fields\nHo creato la funzione per controllare che tutti i fields obbligatori, in base agli altri field, siano presenti in ciascuna riga. Ci sono sicuramente delle modifiche da fare, discusse in [meeting 014](notes/meetings/meeting%20014.md), perch√© la definizione della sintassi di META-CSV contiene delle incoerenze e dei punti poco chiari per quanto riguarda i campi obbligatori e i valori richiesti per il field `type` in determinati casi vedi [meeting 014](notes/meetings/meeting%20014.md).\n\n\n## N.B.: Quasi finito il primo livello!\nQuando saranno fatte le necessarie correzioni/integrazioni, il primo livello, quello relativo al formato di OC, dovrebbe essere concluso (rimarr√† soltanto da definire pi√π chiaramente i messaggi).\n\n\n\n[^1]: Non controllo questa cosa perch√© non credo sia possibile farlo con le regex, e fare controlli sulle singole parti dell'intervallo mi sembrava un po' un overkill... ","lastmodified":"2023-03-19T23:54:38.516579322Z","tags":null},"/notes/sessions/session-015":{"title":"Session 015","content":"\u003cspan \n\t\tclass='ob-timelines'\n\t\tdata-date=\"2022-12-13-00\"\u003e\n\u003c/span\u003e\n\nüë• [**Reference meeting: 015**](notes/sessions/session%20015.md)\n\nüîô [**Previous work session: 014**](notes/sessions/session%20014.md)\n\n\u003e [!info]+ My goals for this session\n\u003e \n\u003e The description of your goal goes here\n\n","lastmodified":"2023-03-19T23:54:38.516579322Z","tags":null},"/notes/sessions/session-016":{"title":"Session 016","content":"\u003cspan \n\t\tclass='ob-timelines'\n\t\tdata-date=\"2023-01-05-00\"\u003e\n\u003c/span\u003e\n\nüë• [**Reference meeting: 016**](notes/meetings/meeting%20016.md)\n\nüîô [**Previous work session: 015**](notes/sessions/session%20015.md)\n\n\n## IDManager\n\n### PMCID\n* √® un'identificativo associato a ciascuno degli articoli presenti in PubMed Central\n* pu√≤ essere cercato tramite almeno due API:\n\t* **Entrez Programming Utilities** (aka E-utilities o e-util), la API tramite cui √® possibile accedere a ***tutti*** i server, database e serivizi del National Center for Biotechnology Information (NCBI) (a sua volta parte del NIH), \u003cu\u003enon\u003c/u\u003e solo a PubMed Central . \n\t* **ID Converter di PMC**, il tool per la conversione ID, specifico per records che alloggiano in PubMed Central (pmc), che consente di risalire dall'identificativo di un lavoro agli altri suoi identificativi, se questo lavoro √® presente in pmc.\n\n#### Il limite di 3 richieste al secondo\nIl problema con Entrez √® che ammette fino a 3 richieste al secondo: se si sfora questo limite, dopo un po' ti bloccano (√® possibile che ti contattino prima di bloccarti, se nella richiesta http hai scritto l'indirizzo e-mail). Si pu√≤ richiedere via mail una API key per prevenire il problema dell'essere bloccati. Per quanto riguarda la API dell'ID Converter, non trovo scritto da nessuna parte di limiti al numero di richieste, che √® verosimile visto che viene usata per un servizio molto pi√π specifico e rischia di meno di essere sovraccaricata di richieste. \n\n#### L'uso dell'API in base alla funzione\nSe devo solo verificare che un PMCID sia registrato, posso usare anche ID Converter: non √® pensato per questo, ma funziona; mi d√† gli altri identificativi associati, come il doi o il pmid; soprattutto non ha limiti al numero di richieste.\nInvece, se voglio ulteriori informazioni, come titolo, autore, data di pubblicazione, ecc., allora senz'altro devo usare Entrez, con azione e parametri appropriati, in base a quante/quali extra info voglio ottenere. \nPer tutte le API legate PubMed Central, vedi https://www.ncbi.nlm.nih.gov/pmc/tools/developers/.\n\n\n**Documentazione Entrez**: https://www.ncbi.nlm.nih.gov/books/NBK25500/\n\n**Documentazione ID Converter**: https://www.ncbi.nlm.nih.gov/pmc/tools/id-converter-api/\n\nVideo spiegazione Entrez + altre API, tra cui ID Converter: https://youtu.be/0pRvEDS6Afw\n\n**Ho deciso di usare l'API di ID Converter** per non avere il problema del limite alle richieste. In `oc_idmanager.pmcid.py`, sia in `syntax_ok` che in `exists`, ammetto la possibilit√† di avere il PMCID in due formati, visto che la documentazione non √® chiara:\n* con \"PMC\" a precedere il numero reale di 7(?) cifre\n* solo il numero, senza \"PMC\"\nPraticamente, \"PMC\" √® un prefisso interno che serve a specificare che quell'ID non √® un PMID (o altro?), ma un PMCID. Comunque, quando si trova citato un PMCID nella maggior parte dei casi lo si trova citato *con* \"PMC\" incluso.\nNell'API di ID Converter, purch√© sia specificato il parametro `idtype=pmcid`, questo identificativo si pu√≤ scrivere con o senza \"PMC\"; se non si specifica il parametro `idtype` e l'id viene scritto senza \"PMC\", allora verr√† interpretato come un PMID!! --\u003e ho specificato  `idtype=pmcid` tra i parametri della richiesta, in modo che un pmcid possa essere cercato sia con il prefisso \"PMC\" sia senza.\n\nSe si vogliono ottenere pi√π informazioni, conviene usare E-Utilities, ma bisogna chiaramente cambiare come viene formulata la richiesta √® il modo in cui viene interpretata dal metodo `esists` la risposta.[1] \n\n[1]: Una cosa da tenere presente √® che E-Utilities, se ho capito bene , richiede che venga specificato il servizio a cui si vuole mandare la richiesta con il parametro `db`, quindi non credo sia possibile scrivere un PMCID con il prefisso \"PMC\" incluso (perch√© lo abbiamo gi√† specificato in `db=pmc`). In ogni caso sarebbero tutte cose da studiare con pi√π calma se si decidesse di usare E-Utilities perch√© consente di avere pi√π informazioni aggiuntive.\n\n#### Nessuna documentazione sulla sintassi dell'identificativo\nNon c'√® una pagina che spieghi qualcosa sul formato/sintassi dei PMCID, se non appunto che PMC pu√≤ esserci o no (almeno per quanto riguarda le richieste alle API). Dagli esempi trovati vediamo che:\n* un PMCID √® tendenzialmente citato con il prefisso PMC, anche nella *risposta* dell'API\n* non ho mai trovato pi√π di 7 cifre (dopo l'eventuale prefisso) e ho trovato solo numeri reali (alla sequenza di cifre anche le fonti ufficiali si riferiscono con \"number\")\n* non ho mai trovato lettere\n* un PMCID pu√≤ essere esteso con un punto e delle cifre che indicano il numero della versione del lavoro a cui √® associato il PMCID. Es. PMC1234324.1\n* la pagina wikidata d√† questa regular expression (nota che √® senza prefisso \"PMC\"): `[1-9]\\d{0,6}` . Vedi [propriet√†](https://www.wikidata.org/wiki/Property:P932) e [Q entity](https://www.wikidata.org/wiki/Q11801904).\n\nIn mancanza di una documentazione specifica, ufficiale e dettagliata, mi sono tenuto largo nel definire cosa √® sintatticamente corretto: il prefisso \"PMC\" √® ammesso ma non obbligatorio; deve esserci almeno una cifra, ma senza un limite (anche pi√π di sette); pu√≤ esserci un punto seguito da massimo due cifre (perch√© si suppone che nessun lavoro abbia pi√π di 99 versioni registrate). Questa tolleranza √® mantenuta solo per principio, appunto perch√© non ho trovato una fonte ufficiale da poter citare, per√≤ nella realt√† dei fatti forse sarebbe meglio essere pi√π restrittivi ed usare ad esempio la regex di wikidata (magari con il solo adattamento del prefisso).\n\n\n\n### ROR\n#### Che cos'√® ROR\n\nDa https://ror.org/about/#what-is-ror:\n\n\u003eThe Research Organization Registry (ROR) is a global, community-led registry of open persistent identifiers for research organizations. ROR makes it easy for anyone or any system to disambiguate institution names and connect research organizations to researchers and research outputs.\n\n\u003eOrganizations are not static entities. They change their names, merge, split, shut down, and re-emerge, and this makes it difficult to connect research organizations to research outputs and researchers. A persistent identifier for research organizations makes this easier.\n\n\u003eROR is the first and only organization identifier that is openly available (CC0 data available via an open REST API and public data dump), specifically focused on identifying affiliations in scholarly metadata, developed as a community initiative to meet community use cases, and designed to be integrated into open scholarly infrastructure. It is the default identifier supported in Crossref DOI metadata, DataCite DOI metadata, and ORCID.\n\n\u003eROR is operated as a collaborative initiative by¬†[California Digital Library](https://cdlib.org/),¬†[Crossref](https://crossref.org/), and¬†[DataCite](https://datacite.org/).\n\n\n\"ROR is more than just an identifier: each record associated with a ROR ID contains useful information about the organization‚Äôs name in multiple languages, acronyms, aliases, location, website, Wikipedia page, and other persistent identifiers\". \u003cu\u003eQueste informazioni, comunque, non sono codificate nell'identificativo, ma soltanto contenute nel record a cui l'identificativo √® associato\u003c/u\u003e. \n\n#### Sintassi\n\nDa https://ror.org/about/faqs/:\n\n\u003eROR identifiers have a¬†[predictable pattern](https://ror.readme.io/docs/ror-identifier-pattern)¬†and can be validated with the regular expression ÔªøÔªø`^https://ror.org/^0[a-z|0-9]{6}[0-9]{2}$`. The canonical form of a ROR identifier value is the entire URL.\n\nLa regex che uso √®: `^ror:((https:\\/\\/)?ror\\.org\\/)?0[a-hj-km-np-tv-z|0-9]{6}[0-9]{2}$`. Include sia i casi in cui si usi l'URL completo (come sarebbe giusto), sia quelli in cui si usi l'URL senza \"https\" e \"www\", sia quelli in cui si usi solo l'identificativo, senza l'URL. **Forse bisognerebbe essere pi√π restrittivi, ammettendo solo l'URL completo come forma valida?**\n\n#### API\n\nDocumentazione: https://ror.readme.io/docs/rest-api\n* rate limit is a maximum of 2000 requests in a 5-minute period, and API traffic can be quite heavy\n* per cercare un singolo identificativo (come nel nostro caso), √® sufficiente aggiungerlo a questo base URL: `https://api.ror.org/organizations/`. Vengono accettati tutti i tre formati dell'identificativo che sono ammessi anche dalla mia regex, cio√® al base URL pu√≤ essere attaccato un ID in uno qualsiasi di questi tre formati:\n\t* **Full ROR ID URL:**¬†`https://ror.org/015w2mp89`\n\t* **Domain and ID:**¬†only `ror.org/015w2mp89`\n\t* **ID only :**¬†`015w2mp89`\n* la risposta viene data direttamente in json, senza bisogno di specificare alcun parametro. Per la data structure della risposta vedi https://ror.readme.io/docs/ror-data-structure, anche se √® abbastanza human-readable.\n\n\n\n## Funzioni per livello 2 e 3 (solo `exists`)\n\nLe funzioni sono scritte, ma devi ancora integrarle nella funzione principale (+ fare messaggi e aggiungere in errors_map)","lastmodified":"2023-03-19T23:54:38.516579322Z","tags":null}}